1: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
1:   import pynvml  # type: ignore[import]
0: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
0:   import pynvml  # type: ignore[import]
1: A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-R1:
1: - configuration_deepseek.py
1: . Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.
1: `torch_dtype` is deprecated! Use `dtype` instead!
1: WARNING:sglang.srt.server_args:DP attention is enabled. The chunked prefill size is adjusted to 2048 to avoid MoE kernel issues. 
1: WARNING:sglang.srt.server_args:Pipeline parallelism is incompatible with overlap schedule.
0: A new version of the following files was downloaded from https://huggingface.co/deepseek-ai/DeepSeek-R1:
0: - configuration_deepseek.py
0: . Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.
1: WARNING:sglang.srt.server_args:DP attention is enabled. The chunked prefill size is adjusted to 512 to avoid MoE kernel issues. 
1: WARNING:sglang.srt.server_args:Pipeline parallelism is incompatible with overlap schedule.
0: `torch_dtype` is deprecated! Use `dtype` instead!
0: WARNING:sglang.srt.server_args:DP attention is enabled. The chunked prefill size is adjusted to 2048 to avoid MoE kernel issues. 
0: WARNING:sglang.srt.server_args:Pipeline parallelism is incompatible with overlap schedule.
0: WARNING:sglang.srt.server_args:DP attention is enabled. The chunked prefill size is adjusted to 512 to avoid MoE kernel issues. 
0: WARNING:sglang.srt.server_args:Pipeline parallelism is incompatible with overlap schedule.
1: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
1:   import pynvml  # type: ignore[import]
0: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
0:   import pynvml  # type: ignore[import]
0: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
0:   import pynvml  # type: ignore[import]
0: [2025-10-29 08:09:18] Using default HuggingFace chat template with detected content format: string
1: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
1:   import pynvml  # type: ignore[import]
0: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
0:   import pynvml  # type: ignore[import]
1: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
1:   import pynvml  # type: ignore[import]
1: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
1:   import pynvml  # type: ignore[import]
1: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
1:   import pynvml  # type: ignore[import]
1: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
1:   import pynvml  # type: ignore[import]
0: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
0:   import pynvml  # type: ignore[import]
0: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
0:   import pynvml  # type: ignore[import]
0: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
0:   import pynvml  # type: ignore[import]
0: /usr/local/lib/python3.12/dist-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.
0:   import pynvml  # type: ignore[import]
1: `torch_dtype` is deprecated! Use `dtype` instead!
1: `torch_dtype` is deprecated! Use `dtype` instead!
1: `torch_dtype` is deprecated! Use `dtype` instead!
1: `torch_dtype` is deprecated! Use `dtype` instead!
0: `torch_dtype` is deprecated! Use `dtype` instead!
0: `torch_dtype` is deprecated! Use `dtype` instead!
0: `torch_dtype` is deprecated! Use `dtype` instead!
0: `torch_dtype` is deprecated! Use `dtype` instead!
1: [2025-10-29 20:09:38 DP0 TP0 PP1] Attention backend not explicitly specified. Use fa3 backend by default.
1: [2025-10-29 20:09:38 DP0 TP0 PP1] Chunked prefix cache is turned on.
1: [2025-10-29 20:09:38 DP0 TP0 PP1] Init torch distributed begin.
0: [2025-10-29 08:09:38 DP0 TP0 PP0] Attention backend not explicitly specified. Use fa3 backend by default.
0: [2025-10-29 08:09:38 DP0 TP0 PP0] Chunked prefix cache is turned on.
0: [2025-10-29 08:09:38 DP0 TP0 PP0] Init torch distributed begin.
0: [2025-10-29 08:09:39 DP0 TP0 PP0] sglang is using nccl==2.27.3
1: [2025-10-29 20:09:39 DP0 TP0 PP1] sglang is using nccl==2.27.3
0: [2025-10-29 08:09:41 DP0 TP0 PP0] sglang is using nccl==2.27.3
0: [2025-10-29 08:09:41 DP2 TP2 PP0] sglang is using nccl==2.27.3
0: [2025-10-29 08:09:41 DP3 TP3 PP0] sglang is using nccl==2.27.3
0: [2025-10-29 08:09:41 DP1 TP1 PP0] sglang is using nccl==2.27.3
0: [2025-10-29 08:09:41 DP0 TP0 PP0] Init torch distributed ends. mem usage=1.33 GB
1: [2025-10-29 20:09:41 DP0 TP0 PP1] Init torch distributed ends. mem usage=1.33 GB
1: [2025-10-29 20:09:42 DP0 TP0 PP1] Load weight begin. avail mem=137.92 GB
1: [2025-10-29 20:09:42 DP0 TP0 PP1] Detected fp8 checkpoint.
0: [2025-10-29 08:09:42 DP0 TP0 PP0] Load weight begin. avail mem=137.92 GB
0: [2025-10-29 08:09:42 DP0 TP0 PP0] Detected fp8 checkpoint.
0: [2025-10-29 08:09:43 DP0 TP0 PP0] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=56.63 GB, mem usage=81.29 GB.
0: [2025-10-29 08:09:43 DP0 TP0 PP0] Using KV cache dtype: torch.bfloat16
1: [2025-10-29 20:09:43 DP0 TP0 PP1] Load weight end. type=DeepseekV3ForCausalLM, dtype=torch.bfloat16, avail mem=47.90 GB, mem usage=90.03 GB.
1: [2025-10-29 20:09:43 DP0 TP0 PP1] Using KV cache dtype: torch.bfloat16
0: [2025-10-29 08:09:43 DP3 TP3 PP0] KV Cache is allocated. #tokens: 849865, KV size: 27.35 GB
1: [2025-10-29 20:09:43 DP0 TP0 PP1] KV Cache is allocated. #tokens: 849865, KV size: 28.27 GB
0: [2025-10-29 08:09:43 DP2 TP2 PP0] KV Cache is allocated. #tokens: 849865, KV size: 27.35 GB
1: [2025-10-29 20:09:43 DP0 TP0 PP1] Memory pool end. avail mem=18.91 GB
0: [2025-10-29 08:09:43 DP1 TP1 PP0] KV Cache is allocated. #tokens: 849865, KV size: 27.35 GB
0: [2025-10-29 08:09:43 DP0 TP0 PP0] KV Cache is allocated. #tokens: 849865, KV size: 27.35 GB
0: [2025-10-29 08:09:43 DP0 TP0 PP0] Memory pool end. avail mem=28.50 GB
1: [2025-10-29 20:09:43 DP3 TP3 PP1] KV Cache is allocated. #tokens: 849865, KV size: 28.27 GB
1: [2025-10-29 20:09:43 DP1 TP1 PP1] KV Cache is allocated. #tokens: 849865, KV size: 28.27 GB
1: [2025-10-29 20:09:43 DP2 TP2 PP1] KV Cache is allocated. #tokens: 849865, KV size: 28.27 GB
0: [2025-10-29 08:09:44 DP0 TP0 PP0] Capture cuda graph begin. This can take up to several minutes. avail mem=28.44 GB
1: [2025-10-29 20:09:44 DP0 TP0 PP1] Capture cuda graph begin. This can take up to several minutes. avail mem=18.85 GB
1: [2025-10-29 20:09:44 DP0 TP0 PP1] Capture cuda graph bs [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256]
0: [2025-10-29 08:09:44 DP0 TP0 PP0] Capture cuda graph bs [1, 2, 4, 8, 16, 24, 32, 40, 48, 56, 64, 72, 80, 88, 96, 104, 112, 120, 128, 136, 144, 152, 160, 168, 176, 184, 192, 200, 208, 216, 224, 232, 240, 248, 256]
0:   0%|          | 0/35 [00:00<?, ?it/s]Capturing batches (bs=256 avail_mem=28.28 GB):   0%|          | 0/35 [00:00<?, ?it/s][2025-10-29 08:09:44 DP0 TP0 PP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
0: [2025-10-29 08:09:44 DP0 TP0 PP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
0: 
0: DeepGEMM warmup:   0%|          | 0/16384 [00:00<?, ?it/s][A
0: DeepGEMM warmup:   5%|â–         | 786/16384 [00:00<00:01, 7858.85it/s][A
0: DeepGEMM warmup:  18%|â–ˆâ–Š        | 2903/16384 [00:00<00:00, 15685.99it/s][A
0: DeepGEMM warmup:  32%|â–ˆâ–ˆâ–ˆâ–      | 5291/16384 [00:00<00:00, 19426.41it/s][A
0: DeepGEMM warmup:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 8183/16384 [00:00<00:00, 23173.57it/s][A
0: DeepGEMM warmup:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 11352/16384 [00:00<00:00, 26244.27it/s][A
0: DeepGEMM warmup:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 14801/16384 [00:00<00:00, 29045.19it/s][ADeepGEMM warmup: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16384/16384 [00:00<00:00, 25411.22it/s]
0: [2025-10-29 08:09:45 DP0 TP0 PP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
0: [2025-10-29 08:09:45 DP0 TP0 PP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=24576, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
0: 
0: DeepGEMM warmup:   0%|          | 0/16384 [00:00<?, ?it/s][A
0: DeepGEMM warmup:  15%|â–ˆâ–        | 2392/16384 [00:00<00:00, 23918.71it/s][A
0: DeepGEMM warmup:  34%|â–ˆâ–ˆâ–ˆâ–      | 5633/16384 [00:00<00:00, 28905.87it/s][A
0: DeepGEMM warmup:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 9186/16384 [00:00<00:00, 31926.69it/s][A
0: DeepGEMM warmup:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 12749/16384 [00:00<00:00, 33388.09it/s][A
0: DeepGEMM warmup: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 16326/16384 [00:00<00:00, 34243.59it/s][ADeepGEMM warmup: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16384/16384 [00:00<00:00, 32646.11it/s]
0: [2025-10-29 08:09:46 DP0 TP0 PP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
0: [2025-10-29 08:09:46 DP0 TP0 PP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=16384, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
0: 
0: DeepGEMM warmup:   0%|          | 0/16384 [00:00<?, ?it/s][A
0: DeepGEMM warmup:  11%|â–ˆâ–        | 1854/16384 [00:00<00:00, 18537.19it/s][A
0: DeepGEMM warmup:  28%|â–ˆâ–ˆâ–Š       | 4654/16384 [00:00<00:00, 24102.20it/s][A
0: DeepGEMM warmup:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 8074/16384 [00:00<00:00, 28711.91it/s][A
0: DeepGEMM warmup:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 11642/16384 [00:00<00:00, 31460.19it/s][A
0: DeepGEMM warmup:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž| 15213/16384 [00:00<00:00, 32990.40it/s][ADeepGEMM warmup: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16384/16384 [00:00<00:00, 30742.14it/s]
0: [2025-10-29 08:09:46 DP0 TP0 PP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
0: [2025-10-29 08:09:46 DP0 TP0 PP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=9216, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
0: 
0: DeepGEMM warmup:   0%|          | 0/16384 [00:00<?, ?it/s][A
0: DeepGEMM warmup:  11%|â–ˆ         | 1822/16384 [00:00<00:00, 18218.63it/s][A
0: DeepGEMM warmup:  28%|â–ˆâ–ˆâ–Š       | 4661/16384 [00:00<00:00, 24197.61it/s][A
0: DeepGEMM warmup:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 8230/16384 [00:00<00:00, 29441.21it/s][A
0: DeepGEMM warmup:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 11808/16384 [00:00<00:00, 31942.55it/s][A
0: DeepGEMM warmup:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 15373/16384 [00:00<00:00, 33278.73it/s][ADeepGEMM warmup: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16384/16384 [00:00<00:00, 30999.84it/s]
0: [2025-10-29 08:09:47 DP0 TP0 PP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
0: [2025-10-29 08:09:47 DP0 TP0 PP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=4608, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
0: 
0: DeepGEMM warmup:   0%|          | 0/16384 [00:00<?, ?it/s][A
0: DeepGEMM warmup:  13%|â–ˆâ–Ž        | 2049/16384 [00:00<00:00, 20055.61it/s][A
0: DeepGEMM warmup:  31%|â–ˆâ–ˆâ–ˆ       | 5087/16384 [00:00<00:00, 26074.35it/s][A
0: DeepGEMM warmup:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 8526/16384 [00:00<00:00, 29851.54it/s][A
0: DeepGEMM warmup:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 12089/16384 [00:00<00:00, 32124.19it/s][A
0: DeepGEMM warmup:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 15675/16384 [00:00<00:00, 33466.20it/s][ADeepGEMM warmup: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16384/16384 [00:00<00:00, 31379.20it/s]
1:   0%|          | 0/35 [00:00<?, ?it/s]Capturing batches (bs=256 avail_mem=18.57 GB):   0%|          | 0/35 [00:00<?, ?it/s][2025-10-29 20:09:57 DP0 TP0 PP1] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
1: [2025-10-29 20:09:57 DP0 TP0 PP1] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=2112, K=7168, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
1: 
1: DeepGEMM warmup:   0%|          | 0/16384 [00:00<?, ?it/s][A
1: DeepGEMM warmup:   9%|â–Š         | 1409/16384 [00:00<00:01, 13940.58it/s][A
1: DeepGEMM warmup:  24%|â–ˆâ–ˆâ–       | 3961/16384 [00:00<00:00, 20720.55it/s][A
1: DeepGEMM warmup:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 6540/16384 [00:00<00:00, 23027.75it/s][A
1: DeepGEMM warmup:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 9637/16384 [00:00<00:00, 26156.59it/s][A
1: DeepGEMM warmup:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 12933/16384 [00:00<00:00, 28605.14it/s][ADeepGEMM warmup: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16384/16384 [00:00<00:00, 27404.10it/s]
1: [2025-10-29 20:09:58 DP0 TP0 PP1] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
1: [2025-10-29 20:09:58 DP0 TP0 PP1] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=24576, K=1536, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
1: 
1: DeepGEMM warmup:   0%|          | 0/16384 [00:00<?, ?it/s][A
1: DeepGEMM warmup:  16%|â–ˆâ–Œ        | 2556/16384 [00:00<00:00, 25554.42it/s][A
1: DeepGEMM warmup:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 5857/16384 [00:00<00:00, 29934.64it/s][A
1: DeepGEMM warmup:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 9450/16384 [00:00<00:00, 32669.07it/s][A
1: DeepGEMM warmup:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 13050/16384 [00:00<00:00, 33981.07it/s][ADeepGEMM warmup: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16384/16384 [00:00<00:00, 33229.26it/s]
1: [2025-10-29 20:09:59 DP0 TP0 PP1] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
1: [2025-10-29 20:09:59 DP0 TP0 PP1] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=7168, K=16384, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
1: 
1: DeepGEMM warmup:   0%|          | 0/16384 [00:00<?, ?it/s][A
1: DeepGEMM warmup:  13%|â–ˆâ–Ž        | 2108/16384 [00:00<00:00, 21074.04it/s][A
1: DeepGEMM warmup:  32%|â–ˆâ–ˆâ–ˆâ–      | 5205/16384 [00:00<00:00, 26893.70it/s][A
1: DeepGEMM warmup:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž    | 8640/16384 [00:00<00:00, 30296.23it/s][A
1: DeepGEMM warmup:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 12187/16384 [00:00<00:00, 32337.76it/s][A
1: DeepGEMM warmup:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 15751/16384 [00:00<00:00, 33525.70it/s][ADeepGEMM warmup: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16384/16384 [00:00<00:00, 31630.25it/s]
1: [2025-10-29 20:09:59 DP0 TP0 PP1] Using default MoE kernel config. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
1: [2025-10-29 20:09:59 DP1 TP1 PP1] Using default MoE kernel config. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
1: [2025-10-29 20:09:59 DP3 TP3 PP1] Using default MoE kernel config. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
1: [2025-10-29 20:09:59 DP2 TP2 PP1] Using default MoE kernel config. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
0: [2025-10-29 08:10:00 DP0 TP0 PP0] Using default MoE kernel config. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
0: [2025-10-29 08:10:00 DP1 TP1 PP0] Using default MoE kernel config. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
0: [2025-10-29 08:10:00 DP2 TP2 PP0] Using default MoE kernel config. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
0: [2025-10-29 08:10:00 DP3 TP3 PP0] Using default MoE kernel config. Performance might be sub-optimal! Config file not found at /sgl-workspace/sglang/python/sglang/srt/layers/moe/fused_moe_triton/configs/triton_3_4_0/E=257,N=512,device_name=NVIDIA_H200,dtype=fp8_w8a8,block_shape=[128, 128].json, you can create them with https://github.com/sgl-project/sglang/tree/main/benchmark/kernels/fused_moe_triton
1: Capturing batches (bs=256 avail_mem=18.57 GB):   3%|â–Ž         | 1/35 [00:16<09:31, 16.81s/it]Capturing batches (bs=248 avail_mem=10.53 GB):   3%|â–Ž         | 1/35 [00:16<09:31, 16.81s/it]Capturing batches (bs=248 avail_mem=10.53 GB):   6%|â–Œ         | 2/35 [00:16<03:51,  7.02s/it]Capturing batches (bs=240 avail_mem=10.51 GB):   6%|â–Œ         | 2/35 [00:16<03:51,  7.02s/it]Capturing batches (bs=240 avail_mem=10.51 GB):   9%|â–Š         | 3/35 [00:17<02:04,  3.90s/it]Capturing batches (bs=232 avail_mem=10.50 GB):   9%|â–Š         | 3/35 [00:17<02:04,  3.90s/it]Capturing batches (bs=232 avail_mem=10.50 GB):  11%|â–ˆâ–        | 4/35 [00:17<01:15,  2.43s/it]Capturing batches (bs=224 avail_mem=10.49 GB):  11%|â–ˆâ–        | 4/35 [00:17<01:15,  2.43s/it]Capturing batches (bs=224 avail_mem=10.49 GB):  14%|â–ˆâ–        | 5/35 [00:17<00:48,  1.61s/it]Capturing batches (bs=216 avail_mem=10.47 GB):  14%|â–ˆâ–        | 5/35 [00:17<00:48,  1.61s/it]Capturing batches (bs=216 avail_mem=10.47 GB):  17%|â–ˆ
1: â–‹        | 6/35 [00:17<00:32,  1.12s/it]Capturing batches (bs=208 avail_mem=10.46 GB):  17%|â–ˆâ–‹        | 6/35 [00:17<00:32,  1.12s/it]Capturing batches (bs=208 avail_mem=10.46 GB):  20%|â–ˆâ–ˆ        | 7/35 [00:17<00:22,  1.24it/s]Capturing batches (bs=200 avail_mem=10.44 GB):  20%|â–ˆâ–ˆ        | 7/35 [00:17<00:22,  1.24it/s]Capturing batches (bs=200 avail_mem=10.44 GB):  23%|â–ˆâ–ˆâ–Ž       | 8/35 [00:17<00:16,  1.67it/s]Capturing batches (bs=192 avail_mem=10.43 GB):  23%|â–ˆâ–ˆâ–Ž       | 8/35 [00:17<00:16,  1.67it/s]Capturing batches (bs=192 avail_mem=10.43 GB):  26%|â–ˆâ–ˆâ–Œ       | 9/35 [00:18<00:12,  2.16it/s]Capturing batches (bs=184 avail_mem=10.42 GB):  26%|â–ˆâ–ˆâ–Œ       | 9/35 [00:18<00:12,  2.16it/s]Capturing batches (bs=184 avail_mem=10.42 GB):  29%|â–ˆâ–ˆâ–Š       | 10/35 [00:18<00:09,  2.69it/s]Capturing batches (bs=176 avail_mem=10.40 GB):  29%|â–ˆâ–ˆâ–Š       | 10/35 [00:18<00:09,  2.69it/s]Capturing batches (bs=176 avail_mem=10.40 GB):  31%|â–ˆâ–ˆâ–ˆâ–      | 11/35 [00:18<
0: Capturing batches (bs=256 avail_mem=28.28 GB):   3%|â–Ž         | 1/35 [00:17<10:02, 17.71s/it]Capturing batches (bs=248 avail_mem=23.78 GB):   3%|â–Ž         | 1/35 [00:17<10:02, 17.71s/it]Capturing batches (bs=248 avail_mem=23.78 GB):   6%|â–Œ         | 2/35 [00:17<04:03,  7.38s/it]Capturing batches (bs=240 avail_mem=23.77 GB):   6%|â–Œ         | 2/35 [00:17<04:03,  7.38s/it]Capturing batches (bs=240 avail_mem=23.77 GB):   9%|â–Š         | 3/35 [00:18<02:10,  4.08s/it]Capturing batches (bs=232 avail_mem=23.76 GB):   9%|â–Š         | 3/35 [00:18<02:10,  4.08s/it]Capturing batches (bs=232 avail_mem=23.76 GB):  11%|â–ˆâ–        | 4/35 [00:18<01:18,  2.53s/it]Capturing batches (bs=224 avail_mem=23.74 GB):  11%|â–ˆâ–        | 4/35 [00:18<01:18,  2.53s/it]Capturing batches (bs=224 avail_mem=23.74 GB):  14%|â–ˆâ–        | 5/35 [00:18<00:50,  1.68s/it]Capturing batches (bs=216 avail_mem=23.73 GB):  14%|â–ˆâ–        | 5/35 [00:18<00:50,  1.68s/it]Capturing batches (bs=216 avail_mem=23.73 GB):  17%|â–ˆ
1: 00:07,  3.24it/s]Capturing batches (bs=168 avail_mem=10.39 GB):  31%|â–ˆâ–ˆâ–ˆâ–      | 11/35 [00:18<00:07,  3.24it/s]Capturing batches (bs=168 avail_mem=10.39 GB):  34%|â–ˆâ–ˆâ–ˆâ–      | 12/35 [00:18<00:06,  3.80it/s]Capturing batches (bs=160 avail_mem=10.37 GB):  34%|â–ˆâ–ˆâ–ˆâ–      | 12/35 [00:18<00:06,  3.80it/s]Capturing batches (bs=160 avail_mem=10.37 GB):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 13/35 [00:18<00:05,  4.29it/s]Capturing batches (bs=152 avail_mem=10.37 GB):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 13/35 [00:18<00:05,  4.29it/s]Capturing batches (bs=152 avail_mem=10.37 GB):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 14/35 [00:18<00:04,  4.76it/s]Capturing batches (bs=144 avail_mem=10.36 GB):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 14/35 [00:18<00:04,  4.76it/s]Capturing batches (bs=144 avail_mem=10.36 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 15/35 [00:19<00:03,  5.14it/s]Capturing batches (bs=136 avail_mem=10.36 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 15/35 [00:19<00:03,  5.14it/s]Capturing batches (bs=136 avail_mem=10.36 GB):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1
0: â–‹        | 6/35 [00:18<00:33,  1.16s/it]Capturing batches (bs=208 avail_mem=23.72 GB):  17%|â–ˆâ–‹        | 6/35 [00:18<00:33,  1.16s/it]Capturing batches (bs=208 avail_mem=23.72 GB):  20%|â–ˆâ–ˆ        | 7/35 [00:18<00:23,  1.21it/s]Capturing batches (bs=200 avail_mem=23.70 GB):  20%|â–ˆâ–ˆ        | 7/35 [00:18<00:23,  1.21it/s]Capturing batches (bs=200 avail_mem=23.70 GB):  23%|â–ˆâ–ˆâ–Ž       | 8/35 [00:18<00:16,  1.64it/s]Capturing batches (bs=192 avail_mem=23.69 GB):  23%|â–ˆâ–ˆâ–Ž       | 8/35 [00:18<00:16,  1.64it/s]Capturing batches (bs=192 avail_mem=23.69 GB):  26%|â–ˆâ–ˆâ–Œ       | 9/35 [00:18<00:12,  2.12it/s]Capturing batches (bs=184 avail_mem=23.68 GB):  26%|â–ˆâ–ˆâ–Œ       | 9/35 [00:18<00:12,  2.12it/s]Capturing batches (bs=184 avail_mem=23.68 GB):  29%|â–ˆâ–ˆâ–Š       | 10/35 [00:19<00:09,  2.69it/s]Capturing batches (bs=176 avail_mem=23.66 GB):  29%|â–ˆâ–ˆâ–Š       | 10/35 [00:19<00:09,  2.69it/s]Capturing batches (bs=176 avail_mem=23.66 GB):  31%|â–ˆâ–ˆâ–ˆâ–      | 11/35 [00:19<
0: 00:07,  3.30it/s]Capturing batches (bs=168 avail_mem=23.65 GB):  31%|â–ˆâ–ˆâ–ˆâ–      | 11/35 [00:19<00:07,  3.30it/s]Capturing batches (bs=168 avail_mem=23.65 GB):  34%|â–ˆâ–ˆâ–ˆâ–      | 12/35 [00:19<00:05,  3.91it/s]Capturing batches (bs=160 avail_mem=23.64 GB):  34%|â–ˆâ–ˆâ–ˆâ–      | 12/35 [00:19<00:05,  3.91it/s]Capturing batches (bs=160 avail_mem=23.64 GB):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 13/35 [00:19<00:04,  4.47it/s]Capturing batches (bs=152 avail_mem=23.63 GB):  37%|â–ˆâ–ˆâ–ˆâ–‹      | 13/35 [00:19<00:04,  4.47it/s]Capturing batches (bs=152 avail_mem=23.63 GB):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 14/35 [00:19<00:04,  4.97it/s]Capturing batches (bs=144 avail_mem=23.63 GB):  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 14/35 [00:19<00:04,  4.97it/s]Capturing batches (bs=144 avail_mem=23.63 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 15/35 [00:19<00:03,  5.41it/s]Capturing batches (bs=136 avail_mem=23.62 GB):  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–Ž     | 15/35 [00:19<00:03,  5.41it/s]Capturing batches (bs=136 avail_mem=23.62 GB):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 1
1: 6/35 [00:19<00:03,  5.45it/s]Capturing batches (bs=128 avail_mem=10.36 GB):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 16/35 [00:19<00:03,  5.45it/s]Capturing batches (bs=128 avail_mem=10.36 GB):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 17/35 [00:19<00:03,  5.66it/s]Capturing batches (bs=120 avail_mem=10.35 GB):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 17/35 [00:19<00:03,  5.66it/s]Capturing batches (bs=120 avail_mem=10.35 GB):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 18/35 [00:19<00:02,  5.89it/s]Capturing batches (bs=112 avail_mem=10.35 GB):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 18/35 [00:19<00:02,  5.89it/s]Capturing batches (bs=112 avail_mem=10.35 GB):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/35 [00:19<00:02,  6.01it/s]Capturing batches (bs=104 avail_mem=10.34 GB):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/35 [00:19<00:02,  6.01it/s]Capturing batches (bs=104 avail_mem=10.34 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 20/35 [00:19<00:02,  6.19it/s]Capturing batches (bs=96 avail_mem=10.34 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 20/35 [00:19<00:02,  6.19it/s] Capturing batches (bs=96 avail_mem=10
1: .34 GB):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 21/35 [00:20<00:02,  6.30it/s]Capturing batches (bs=88 avail_mem=10.34 GB):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 21/35 [00:20<00:02,  6.30it/s]Capturing batches (bs=88 avail_mem=10.34 GB):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 22/35 [00:20<00:02,  6.36it/s]Capturing batches (bs=80 avail_mem=10.33 GB):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 22/35 [00:20<00:02,  6.36it/s]Capturing batches (bs=80 avail_mem=10.33 GB):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 23/35 [00:20<00:01,  6.43it/s]Capturing batches (bs=72 avail_mem=10.32 GB):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 23/35 [00:20<00:01,  6.43it/s]Capturing batches (bs=72 avail_mem=10.32 GB):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 24/35 [00:20<00:01,  6.44it/s]Capturing batches (bs=64 avail_mem=10.32 GB):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 24/35 [00:20<00:01,  6.44it/s]Capturing batches (bs=64 avail_mem=10.32 GB):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 25/35 [00:20<00:01,  6.30it/s]Capturing batches (bs=56 avail_mem=10.31 GB):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 25/35 [00:20
0: 6/35 [00:19<00:03,  5.77it/s]Capturing batches (bs=128 avail_mem=23.62 GB):  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 16/35 [00:19<00:03,  5.77it/s]Capturing batches (bs=128 avail_mem=23.62 GB):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 17/35 [00:20<00:03,  5.93it/s]Capturing batches (bs=120 avail_mem=23.62 GB):  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 17/35 [00:20<00:03,  5.93it/s]Capturing batches (bs=120 avail_mem=23.62 GB):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 18/35 [00:20<00:02,  6.07it/s]Capturing batches (bs=112 avail_mem=23.61 GB):  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 18/35 [00:20<00:02,  6.07it/s]Capturing batches (bs=112 avail_mem=23.61 GB):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/35 [00:20<00:02,  6.27it/s]Capturing batches (bs=104 avail_mem=23.61 GB):  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 19/35 [00:20<00:02,  6.27it/s]Capturing batches (bs=104 avail_mem=23.61 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 20/35 [00:20<00:02,  6.46it/s]Capturing batches (bs=96 avail_mem=23.60 GB):  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 20/35 [00:20<00:02,  6.46it/s] Capturing batches (bs=96 avail_mem=23
0: .60 GB):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 21/35 [00:20<00:02,  6.59it/s]Capturing batches (bs=88 avail_mem=23.60 GB):  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 21/35 [00:20<00:02,  6.59it/s]Capturing batches (bs=88 avail_mem=23.60 GB):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 22/35 [00:20<00:01,  6.72it/s]Capturing batches (bs=80 avail_mem=23.60 GB):  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž   | 22/35 [00:20<00:01,  6.72it/s]Capturing batches (bs=80 avail_mem=23.60 GB):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 23/35 [00:21<00:01,  6.84it/s]Capturing batches (bs=72 avail_mem=23.59 GB):  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 23/35 [00:21<00:01,  6.84it/s]Capturing batches (bs=72 avail_mem=23.59 GB):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 24/35 [00:21<00:01,  6.86it/s]Capturing batches (bs=64 avail_mem=23.59 GB):  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 24/35 [00:21<00:01,  6.86it/s]Capturing batches (bs=64 avail_mem=23.59 GB):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 25/35 [00:21<00:01,  6.61it/s]Capturing batches (bs=56 avail_mem=23.58 GB):  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 25/35 [00:21
1: <00:01,  6.30it/s]Capturing batches (bs=56 avail_mem=10.31 GB):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/35 [00:20<00:01,  6.41it/s]Capturing batches (bs=48 avail_mem=10.31 GB):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/35 [00:20<00:01,  6.41it/s]Capturing batches (bs=48 avail_mem=10.31 GB):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 27/35 [00:20<00:01,  6.52it/s]Capturing batches (bs=40 avail_mem=10.30 GB):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 27/35 [00:20<00:01,  6.52it/s]Capturing batches (bs=40 avail_mem=10.30 GB):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 28/35 [00:21<00:01,  6.53it/s]Capturing batches (bs=32 avail_mem=10.30 GB):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 28/35 [00:21<00:01,  6.53it/s][rank4]:W1029 20:10:05.909000 1008487 torch/_inductor/triton_bundler.py:401] [3/0] Directory /tmp/triton/4651/node1/rank1/tmp.a4094f2c-2de7-4b3b-b97c-b73bcf2b9562 is not empty - skipping!
1: [rank5]:W1029 20:10:05.909000 1008488 torch/_inductor/triton_bundler.py:401] [3/0] Directory /tmp/triton/4651/node1/rank1/tmp.b5f58bf9-e6a2-40ab-a62a-81ba093eb22a is not empty - skipping!
1: [rank7]:W1029 20:10:05.909000 1008490 torch/_inductor/triton_bundler.py:401] [3/0] Directory /tmp/triton/4651/node1/rank1/tmp.30605b41-86e6-4ecb-a833-2b0f15d7c808 is not empty - skipping!
0: <00:01,  6.61it/s]Capturing batches (bs=56 avail_mem=23.58 GB):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/35 [00:21<00:01,  6.73it/s]Capturing batches (bs=48 avail_mem=23.57 GB):  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 26/35 [00:21<00:01,  6.73it/s]Capturing batches (bs=48 avail_mem=23.57 GB):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 27/35 [00:21<00:01,  6.88it/s]Capturing batches (bs=40 avail_mem=23.57 GB):  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 27/35 [00:21<00:01,  6.88it/s]Capturing batches (bs=40 avail_mem=23.57 GB):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 28/35 [00:21<00:01,  6.94it/s]Capturing batches (bs=32 avail_mem=23.56 GB):  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 28/35 [00:21<00:01,  6.94it/s][rank2]:W1029 08:10:06.587000 1153291 torch/_inductor/triton_bundler.py:401] [2/0_1] Directory /tmp/triton/4651/node0/rank0/tmp.da63a149-5102-4185-ae9c-f0f8681952c0 is not empty - skipping!
1: [rank4]:W1029 20:10:06.921000 1008487 torch/_inductor/triton_bundler.py:401] [17/0_1] Directory /tmp/triton/4651/node1/rank1/tmp.e2ee05ea-86d5-4c9d-a22a-07cea0713880 is not empty - skipping!
1: [rank4]:W1029 20:10:06.921000 1008487 torch/_inductor/triton_bundler.py:401] [17/0_1] Directory /tmp/triton/4651/node1/rank1/tmp.69569fa9-c97d-4fbd-9673-c488ef300943 is not empty - skipping!
1: [rank7]:W1029 20:10:07.572000 1008490 torch/_inductor/triton_bundler.py:401] [20/0] Directory /tmp/triton/4651/node1/rank1/tmp.fd2ddee6-bcbf-40e0-a4d2-6d58b9fd71a2 is not empty - skipping!
1: [rank7]:W1029 20:10:07.572000 1008490 torch/_inductor/triton_bundler.py:401] [20/0] Directory /tmp/triton/4651/node1/rank1/tmp.0ecf610a-c718-494a-922d-2c639972cefc is not empty - skipping!
1: [rank7]:W1029 20:10:07.573000 1008490 torch/_inductor/triton_bundler.py:401] [20/0] Directory /tmp/triton/4651/node1/rank1/tmp.ee8f8efe-b09c-4603-b25f-a0f0fce08b70 is not empty - skipping!
1: [rank7]:W1029 20:10:07.574000 1008490 torch/_inductor/triton_bundler.py:401] [20/0] Directory /tmp/triton/4651/node1/rank1/tmp.851c7b73-75b9-4ad5-b095-55d3b3d90d9c is not empty - skipping!
1: [rank7]:W1029 20:10:07.574000 1008490 torch/_inductor/triton_bundler.py:401] [20/0] Directory /tmp/triton/4651/node1/rank1/tmp.b4d8ecae-8244-4e33-bbc1-82ebfe91faeb is not empty - skipping!
1: [rank4]:W1029 20:10:07.575000 1008487 torch/_inductor/triton_bundler.py:401] [20/0] Directory /tmp/triton/4651/node1/rank1/tmp.3018d15e-ef71-4930-a704-22b3f6d0490d is not empty - skipping!
1: [rank4]:W1029 20:10:07.575000 1008487 torch/_inductor/triton_bundler.py:401] [20/0] Directory /tmp/triton/4651/node1/rank1/tmp.d15be89a-ee76-44f6-b1c9-b4cb9cd0d60b is not empty - skipping!
1: [rank4]:W1029 20:10:07.576000 1008487 torch/_inductor/triton_bundler.py:401] [20/0] Directory /tmp/triton/4651/node1/rank1/tmp.c84a672a-562f-4fc7-9b68-f4323124fec6 is not empty - skipping!
1: [rank7]:W1029 20:10:08.252000 1008490 torch/_inductor/triton_bundler.py:401] [27/0_1] Directory /tmp/triton/4651/node1/rank1/tmp.b9e8e8a3-d530-47d3-86f5-9a0f348a96db is not empty - skipping!
1: /usr/local/lib/python3.12/dist-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
1:   torch._dynamo.utils.warn_once(msg)
1: /usr/local/lib/python3.12/dist-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
1:   torch._dynamo.utils.warn_once(msg)
1: /usr/local/lib/python3.12/dist-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
1:   torch._dynamo.utils.warn_once(msg)
1: /usr/local/lib/python3.12/dist-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
1:   torch._dynamo.utils.warn_once(msg)
0: [rank2]:W1029 08:10:09.788000 1153291 torch/_inductor/triton_bundler.py:401] [38/0_1] Directory /tmp/triton/4651/node0/rank0/tmp.6c85eafc-807f-46ff-9836-28980b48ac37 is not empty - skipping!
0: /usr/local/lib/python3.12/dist-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
0:   torch._dynamo.utils.warn_once(msg)
0: /usr/local/lib/python3.12/dist-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
0:   torch._dynamo.utils.warn_once(msg)
0: /usr/local/lib/python3.12/dist-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
0:   torch._dynamo.utils.warn_once(msg)
0: /usr/local/lib/python3.12/dist-packages/torch/_dynamo/variables/functions.py:1575: UserWarning: Dynamo detected a call to a `functools.lru_cache`-wrapped function. Dynamo ignores the cache wrapper and directly traces the wrapped function. Silent incorrectness is only a *potential* risk, not something we have observed. Enable TORCH_LOGS="+dynamo" for a DEBUG stack trace.
0:   torch._dynamo.utils.warn_once(msg)
1: [rank5]:W1029 20:10:15.751000 1008488 torch/_inductor/triton_bundler.py:401] [54/0_1] Directory /tmp/triton/4651/node1/rank1/tmp.78c2c388-ad8e-47e9-b666-d8a3ee4d7ab4 is not empty - skipping!
1: [rank4]:W1029 20:10:16.416000 1008487 torch/_inductor/triton_bundler.py:401] [63/0] Directory /tmp/triton/4651/node1/rank1/tmp.b69cc226-3577-4e97-91f4-58cbe3c7fcc6 is not empty - skipping!
0: Capturing batches (bs=32 avail_mem=23.56 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 29/35 [00:32<00:20,  3.40s/it]Capturing batches (bs=24 avail_mem=23.56 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 29/35 [00:32<00:20,  3.40s/it][rank2]:W1029 08:10:17.456000 1153291 torch/_inductor/triton_bundler.py:401] [2/1_1] Directory /tmp/triton/4651/node0/rank0/tmp.a9a0ae7c-9ed9-4dc4-8bf4-0d54791be9ca is not empty - skipping!
1: Capturing batches (bs=32 avail_mem=10.30 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 29/35 [00:32<00:20,  3.48s/it]Capturing batches (bs=24 avail_mem=10.30 GB):  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 29/35 [00:32<00:20,  3.48s/it][rank5]:W1029 20:10:17.576000 1008488 torch/_inductor/triton_bundler.py:401] [17/1_1] Directory /tmp/triton/4651/node1/rank1/tmp.1591d62e-f931-43b3-ba0d-471a6fad7ce9 is not empty - skipping!
1: [rank5]:W1029 20:10:18.292000 1008488 torch/_inductor/triton_bundler.py:401] [20/1] Directory /tmp/triton/4651/node1/rank1/tmp.68280fe7-b219-418a-815a-d6edde58d21c is not empty - skipping!
1: [rank5]:W1029 20:10:18.293000 1008488 torch/_inductor/triton_bundler.py:401] [20/1] Directory /tmp/triton/4651/node1/rank1/tmp.a549f597-02ad-4ae5-ad0e-b28eaaa3c981 is not empty - skipping!
1: [rank5]:W1029 20:10:18.294000 1008488 torch/_inductor/triton_bundler.py:401] [20/1] Directory /tmp/triton/4651/node1/rank1/tmp.411b6c4d-8b1e-4d71-8597-75e8eb438040 is not empty - skipping!
1: [rank4]:W1029 20:10:18.294000 1008487 torch/_inductor/triton_bundler.py:401] [20/1] Directory /tmp/triton/4651/node1/rank1/tmp.33e0b06e-39df-484b-8038-e54901008874 is not empty - skipping!
1: [rank5]:W1029 20:10:18.294000 1008488 torch/_inductor/triton_bundler.py:401] [20/1] Directory /tmp/triton/4651/node1/rank1/tmp.0f3d887a-5fc5-4599-8dc8-7c033cc16301 is not empty - skipping!
1: [rank4]:W1029 20:10:18.295000 1008487 torch/_inductor/triton_bundler.py:401] [20/1] Directory /tmp/triton/4651/node1/rank1/tmp.089a34dc-ca29-410c-bf9a-6eae02e78eec is not empty - skipping!
1: [rank5]:W1029 20:10:18.295000 1008488 torch/_inductor/triton_bundler.py:401] [20/1] Directory /tmp/triton/4651/node1/rank1/tmp.33eb87a7-a634-4f19-82e5-54f46ecee233 is not empty - skipping!
1: [rank4]:W1029 20:10:18.295000 1008487 torch/_inductor/triton_bundler.py:401] [20/1] Directory /tmp/triton/4651/node1/rank1/tmp.d2cde67f-6689-48fa-b4fd-6b0383a4655a is not empty - skipping!
1: [rank4]:W1029 20:10:18.296000 1008487 torch/_inductor/triton_bundler.py:401] [20/1] Directory /tmp/triton/4651/node1/rank1/tmp.e8f82491-a381-417a-bbdf-8a3b823cc653 is not empty - skipping!
0: [rank3]:W1029 08:10:21.026000 1153292 torch/_inductor/triton_bundler.py:401] [3/3_1] Directory /tmp/triton/4651/node0/rank0/tmp.1d301b9e-08a4-4f34-a383-3147c96327a7 is not empty - skipping!
0: [rank3]:W1029 08:10:21.027000 1153292 torch/_inductor/triton_bundler.py:401] [3/3_1] Directory /tmp/triton/4651/node0/rank0/tmp.1eb27b60-fab7-49a1-a8f8-68e77aea3688 is not empty - skipping!
0: [rank2]:W1029 08:10:21.873000 1153291 torch/_inductor/triton_bundler.py:401] [44/1_1] Directory /tmp/triton/4651/node0/rank0/tmp.50ad75c0-d8e5-48ab-8ba9-91e5a7a45905 is not empty - skipping!
0: [rank2]:W1029 08:10:21.874000 1153291 torch/_inductor/triton_bundler.py:401] [44/1_1] Directory /tmp/triton/4651/node0/rank0/tmp.74c931eb-868e-46e8-aa19-29944607edf1 is not empty - skipping!
0: [rank2]:W1029 08:10:21.874000 1153291 torch/_inductor/triton_bundler.py:401] [44/1_1] Directory /tmp/triton/4651/node0/rank0/tmp.92e11521-0c94-490e-b1e0-c9fb65d066d7 is not empty - skipping!
0: [rank3]:W1029 08:10:21.875000 1153292 torch/_inductor/triton_bundler.py:401] [44/1_1] Directory /tmp/triton/4651/node0/rank0/tmp.045188a1-7b04-444e-8bfa-f4e01eccc94f is not empty - skipping!
0: [rank3]:W1029 08:10:21.876000 1153292 torch/_inductor/triton_bundler.py:401] [44/1_1] Directory /tmp/triton/4651/node0/rank0/tmp.fb183d03-9002-487f-ac4b-5e33716ca3fa is not empty - skipping!
0: [rank3]:W1029 08:10:21.876000 1153292 torch/_inductor/triton_bundler.py:401] [44/1_1] Directory /tmp/triton/4651/node0/rank0/tmp.dac1c276-1dd0-4961-925d-366b061328b9 is not empty - skipping!
0: [rank3]:W1029 08:10:21.877000 1153292 torch/_inductor/triton_bundler.py:401] [44/1_1] Directory /tmp/triton/4651/node0/rank0/tmp.4a6b67d1-1700-4ac1-a2a8-58b914a7895f is not empty - skipping!
0: [rank2]:W1029 08:10:22.004000 1153291 torch/_inductor/triton_bundler.py:401] [48/1_1] Directory /tmp/triton/4651/node0/rank0/tmp.761a4400-d899-4029-97fd-b87494b390b8 is not empty - skipping!
1: Capturing batches (bs=24 avail_mem=10.30 GB):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 30/35 [00:41<00:26,  5.26s/it]Capturing batches (bs=16 avail_mem=10.29 GB):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 30/35 [00:41<00:26,  5.26s/it][rank6]:W1029 20:10:27.581000 1008489 torch/_inductor/triton_bundler.py:401] [20/2] Directory /tmp/triton/4651/node1/rank1/tmp.d421b884-f4a2-4798-adec-0dddee415167 is not empty - skipping!
1: [rank6]:W1029 20:10:27.581000 1008489 torch/_inductor/triton_bundler.py:401] [20/2] Directory /tmp/triton/4651/node1/rank1/tmp.021b1581-6d1b-4584-a917-db5f6ec7b1c8 is not empty - skipping!
1: [rank6]:W1029 20:10:27.582000 1008489 torch/_inductor/triton_bundler.py:401] [20/2] Directory /tmp/triton/4651/node1/rank1/tmp.88479231-2fe7-451e-b762-35adfa1f042f is not empty - skipping!
1: [rank6]:W1029 20:10:27.583000 1008489 torch/_inductor/triton_bundler.py:401] [20/2] Directory /tmp/triton/4651/node1/rank1/tmp.dee728ae-764a-4af2-a06e-9bd91729739c is not empty - skipping!
1: [rank6]:W1029 20:10:27.583000 1008489 torch/_inductor/triton_bundler.py:401] [20/2] Directory /tmp/triton/4651/node1/rank1/tmp.cb8eb161-bb7e-4809-9f1b-97575be41837 is not empty - skipping!
1: [rank6]:W1029 20:10:27.584000 1008489 torch/_inductor/triton_bundler.py:401] [20/2] Directory /tmp/triton/4651/node1/rank1/tmp.7f337cd4-4776-4a1d-b587-c6d99f164249 is not empty - skipping!
1: [rank6]:W1029 20:10:27.584000 1008489 torch/_inductor/triton_bundler.py:401] [20/2] Directory /tmp/triton/4651/node1/rank1/tmp.982d5394-edf3-4fa7-9b64-74efd50c446e is not empty - skipping!
0: Capturing batches (bs=24 avail_mem=23.56 GB):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 30/35 [00:42<00:26,  5.28s/it]Capturing batches (bs=16 avail_mem=23.55 GB):  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 30/35 [00:42<00:26,  5.28s/it][rank2]:W1029 08:10:27.917000 1153291 torch/_inductor/triton_bundler.py:401] [16/2_1] Directory /tmp/triton/4651/node0/rank0/tmp.597db1fd-dd9c-4e65-b58d-e1a9c4d9e43e is not empty - skipping!
1: [rank4]:W1029 20:10:28.779000 1008487 torch/_inductor/triton_bundler.py:401] [39/4_1] Directory /tmp/triton/4651/node1/rank1/tmp.dd2ee1b1-1971-4e7b-86a7-9b735ef1a131 is not empty - skipping!
1: [rank4]:W1029 20:10:28.780000 1008487 torch/_inductor/triton_bundler.py:401] [39/4_1] Directory /tmp/triton/4651/node1/rank1/tmp.228c14fc-fcb1-47b1-8070-39822cb5bf63 is not empty - skipping!
0: [rank2]:W1029 08:10:31.479000 1153291 torch/_inductor/triton_bundler.py:401] [44/2_1] Directory /tmp/triton/4651/node0/rank0/tmp.5bae4098-f53c-45c3-9230-6ac9b829e534 is not empty - skipping!
0: [rank0]:W1029 08:10:31.479000 1153289 torch/_inductor/triton_bundler.py:401] [44/2_1] Directory /tmp/triton/4651/node0/rank0/tmp.817ffa4a-8275-4e85-9df8-0d5f4ece84e4 is not empty - skipping!
0: [rank2]:W1029 08:10:31.480000 1153291 torch/_inductor/triton_bundler.py:401] [44/2_1] Directory /tmp/triton/4651/node0/rank0/tmp.b9aa4cb8-ae3c-4b9c-a882-938a9230b69a is not empty - skipping!
0: [rank0]:W1029 08:10:31.480000 1153289 torch/_inductor/triton_bundler.py:401] [44/2_1] Directory /tmp/triton/4651/node0/rank0/tmp.c7d5aca1-fd98-4a5e-be6a-a140551f4e7f is not empty - skipping!
0: [rank2]:W1029 08:10:31.481000 1153291 torch/_inductor/triton_bundler.py:401] [44/2_1] Directory /tmp/triton/4651/node0/rank0/tmp.9bfc652f-e2ef-4f3c-98b8-c86e8b94e70a is not empty - skipping!
0: [rank0]:W1029 08:10:31.481000 1153289 torch/_inductor/triton_bundler.py:401] [44/2_1] Directory /tmp/triton/4651/node0/rank0/tmp.7c0d641d-759b-4fb3-8cbb-6a40ec64dd3d is not empty - skipping!
0: [rank2]:W1029 08:10:31.481000 1153291 torch/_inductor/triton_bundler.py:401] [44/2_1] Directory /tmp/triton/4651/node0/rank0/tmp.6f12a7a1-7796-458b-8fba-ee2844e9bc5e is not empty - skipping!
0: [rank0]:W1029 08:10:31.481000 1153289 torch/_inductor/triton_bundler.py:401] [44/2_1] Directory /tmp/triton/4651/node0/rank0/tmp.79141592-106b-4be1-aa2f-582e556fe299 is not empty - skipping!
0: [rank0]:W1029 08:10:31.482000 1153289 torch/_inductor/triton_bundler.py:401] [44/2_1] Directory /tmp/triton/4651/node0/rank0/tmp.f27e4e63-9bf1-4998-afc1-cbdb3c67bfbc is not empty - skipping!
0: [rank2]:W1029 08:10:31.482000 1153291 torch/_inductor/triton_bundler.py:401] [44/2_1] Directory /tmp/triton/4651/node0/rank0/tmp.c29d6b77-c4b5-4fa4-b2e2-7c7393a663cc is not empty - skipping!
0: [rank2]:W1029 08:10:31.483000 1153291 torch/_inductor/triton_bundler.py:401] [44/2_1] Directory /tmp/triton/4651/node0/rank0/tmp.0c29903a-3168-48a6-a39d-593fde2bbea8 is not empty - skipping!
0: [rank3]:W1029 08:10:31.483000 1153292 torch/_inductor/triton_bundler.py:401] [44/2_1] Directory /tmp/triton/4651/node0/rank0/tmp.871ae3ea-a313-4461-bcaf-bf11ca2d1b09 is not empty - skipping!
0: [rank2]:W1029 08:10:31.483000 1153291 torch/_inductor/triton_bundler.py:401] [44/2_1] Directory /tmp/triton/4651/node0/rank0/tmp.93bb1b7f-bb00-44b0-9f0f-322a821dae21 is not empty - skipping!
0: [rank3]:W1029 08:10:31.483000 1153292 torch/_inductor/triton_bundler.py:401] [44/2_1] Directory /tmp/triton/4651/node0/rank0/tmp.1f19cdcd-4110-41b0-a3d8-b2b66e4f7a6d is not empty - skipping!
0: [rank2]:W1029 08:10:31.484000 1153291 torch/_inductor/triton_bundler.py:401] [44/2_1] Directory /tmp/triton/4651/node0/rank0/tmp.e7ab1dd0-b7b9-49be-8342-5b4d4320b3d2 is not empty - skipping!
0: [rank0]:W1029 08:10:31.640000 1153289 torch/_inductor/triton_bundler.py:401] [48/2_1] Directory /tmp/triton/4651/node0/rank0/tmp.32e46223-44e8-4462-84c0-43cf0358bf60 is not empty - skipping!
1: [rank7]:W1029 20:10:35.222000 1008490 torch/_inductor/triton_bundler.py:401] [63/2] Directory /tmp/triton/4651/node1/rank1/tmp.92b121ad-f734-4d45-88e0-a2e4fd6c2334 is not empty - skipping!
0: Capturing batches (bs=16 avail_mem=23.55 GB):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 31/35 [00:52<00:26,  6.65s/it]Capturing batches (bs=8 avail_mem=23.55 GB):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 31/35 [00:52<00:26,  6.65s/it] [rank3]:W1029 08:10:36.948000 1153292 torch/_inductor/triton_bundler.py:401] [2/3_1] Directory /tmp/triton/4651/node0/rank0/tmp.9d2bff8e-bdd9-479c-98a9-78c0d9c90478 is not empty - skipping!
1: Capturing batches (bs=16 avail_mem=10.29 GB):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 31/35 [00:51<00:25,  6.50s/it]Capturing batches (bs=8 avail_mem=10.29 GB):  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 31/35 [00:51<00:25,  6.50s/it] [rank6]:W1029 20:10:37.058000 1008489 torch/_inductor/triton_bundler.py:401] [20/3] Directory /tmp/triton/4651/node1/rank1/tmp.2e4d1f77-fb8a-49a4-8dc5-60dc68da45dd is not empty - skipping!
1: [rank6]:W1029 20:10:37.058000 1008489 torch/_inductor/triton_bundler.py:401] [20/3] Directory /tmp/triton/4651/node1/rank1/tmp.0d163842-19f3-4d81-851e-6824c5421af8 is not empty - skipping!
1: [rank6]:W1029 20:10:37.059000 1008489 torch/_inductor/triton_bundler.py:401] [20/3] Directory /tmp/triton/4651/node1/rank1/tmp.439fcec2-fb81-4d33-b99c-89bce08b1b5b is not empty - skipping!
1: [rank6]:W1029 20:10:37.060000 1008489 torch/_inductor/triton_bundler.py:401] [20/3] Directory /tmp/triton/4651/node1/rank1/tmp.9e3982e6-8a37-41ed-9825-8aa30df120fb is not empty - skipping!
1: [rank6]:W1029 20:10:37.060000 1008489 torch/_inductor/triton_bundler.py:401] [20/3] Directory /tmp/triton/4651/node1/rank1/tmp.3f43c8c4-b572-42b2-8880-964743fb916e is not empty - skipping!
1: [rank6]:W1029 20:10:37.061000 1008489 torch/_inductor/triton_bundler.py:401] [20/3] Directory /tmp/triton/4651/node1/rank1/tmp.a46beb71-1cee-41ac-a069-a8771f89363e is not empty - skipping!
1: [rank6]:W1029 20:10:37.061000 1008489 torch/_inductor/triton_bundler.py:401] [20/3] Directory /tmp/triton/4651/node1/rank1/tmp.46d9736e-2c0c-4219-b5f5-d991db41e990 is not empty - skipping!
1: [rank6]:W1029 20:10:37.062000 1008489 torch/_inductor/triton_bundler.py:401] [20/3] Directory /tmp/triton/4651/node1/rank1/tmp.e9bd7e7d-c379-42f9-9ca3-1cc730807b2d is not empty - skipping!
1: [rank6]:W1029 20:10:39.091000 1008489 torch/_inductor/triton_bundler.py:401] [66/0] Directory /tmp/triton/4651/node1/rank1/tmp.27324bad-8445-493e-916f-caa0e3d66f55 is not empty - skipping!
0: [rank0]:W1029 08:10:40.033000 1153289 torch/_inductor/triton_bundler.py:401] [40/3_1] Directory /tmp/triton/4651/node0/rank0/tmp.992709ed-d2d6-4398-8e8e-a22765a40704 is not empty - skipping!
0: [rank2]:W1029 08:10:40.399000 1153291 torch/_inductor/triton_bundler.py:401] [3/7_1] Directory /tmp/triton/4651/node0/rank0/tmp.305b9718-d882-4d8e-a875-8fbc2bb0aea8 is not empty - skipping!
0: [rank0]:W1029 08:10:41.213000 1153289 torch/_inductor/triton_bundler.py:401] [44/3_1] Directory /tmp/triton/4651/node0/rank0/tmp.150ad058-276e-42b8-9ab3-e146a50b7b63 is not empty - skipping!
0: [rank0]:W1029 08:10:41.214000 1153289 torch/_inductor/triton_bundler.py:401] [44/3_1] Directory /tmp/triton/4651/node0/rank0/tmp.6ca8d9b8-b830-4cd5-aa95-0961537770e4 is not empty - skipping!
0: [rank0]:W1029 08:10:41.214000 1153289 torch/_inductor/triton_bundler.py:401] [44/3_1] Directory /tmp/triton/4651/node0/rank0/tmp.e63e3500-f1c1-48cf-8dca-3ff099ac0046 is not empty - skipping!
0: [rank0]:W1029 08:10:41.215000 1153289 torch/_inductor/triton_bundler.py:401] [44/3_1] Directory /tmp/triton/4651/node0/rank0/tmp.88a1d791-17e4-4694-8dea-7fdc4235fe5a is not empty - skipping!
0: [rank0]:W1029 08:10:41.215000 1153289 torch/_inductor/triton_bundler.py:401] [44/3_1] Directory /tmp/triton/4651/node0/rank0/tmp.44b534c2-c8df-45e4-b4d6-e62847ad0068 is not empty - skipping!
0: [rank0]:W1029 08:10:41.216000 1153289 torch/_inductor/triton_bundler.py:401] [44/3_1] Directory /tmp/triton/4651/node0/rank0/tmp.95f0c5bf-4d1c-45cd-9ac9-26f264c9d40d is not empty - skipping!
0: [rank0]:W1029 08:10:41.344000 1153289 torch/_inductor/triton_bundler.py:401] [48/3_1] Directory /tmp/triton/4651/node0/rank0/tmp.53143e01-e36d-489a-9f62-c84aef41785d is not empty - skipping!
0: [rank3]:W1029 08:10:41.543000 1153292 torch/_inductor/triton_bundler.py:401] [56/0] Directory /tmp/triton/4651/node0/rank0/tmp.b98f60d6-1eb3-4c17-b591-40ae14e1ca86 is not empty - skipping!
0: [rank2]:W1029 08:10:41.543000 1153291 torch/_inductor/triton_bundler.py:401] [56/0] Directory /tmp/triton/4651/node0/rank0/tmp.4846b9a6-c071-48cb-8f2b-8b4bc5229174 is not empty - skipping!
0: [rank3]:W1029 08:10:41.544000 1153292 torch/_inductor/triton_bundler.py:401] [56/0] Directory /tmp/triton/4651/node0/rank0/tmp.606a91fa-9048-46b5-a431-c4640410afdb is not empty - skipping!
0: [rank2]:W1029 08:10:41.544000 1153291 torch/_inductor/triton_bundler.py:401] [56/0] Directory /tmp/triton/4651/node0/rank0/tmp.2d504fb3-0ea6-4ad6-9ad9-14fa2b6cf712 is not empty - skipping!
1: [rank7]:W1029 20:10:44.916000 1008490 torch/_inductor/triton_bundler.py:401] [61/3_1] Directory /tmp/triton/4651/node1/rank1/tmp.d5db514f-67b5-441a-b2d0-444b9eb0eaf3 is not empty - skipping!
1: Capturing batches (bs=8 avail_mem=10.29 GB):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 32/35 [01:01<00:22,  7.62s/it]Capturing batches (bs=4 avail_mem=10.28 GB):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 32/35 [01:01<00:22,  7.62s/it][rank6]:W1029 20:10:46.624000 1008489 torch/_inductor/triton_bundler.py:401] [17/4_1] Directory /tmp/triton/4651/node1/rank1/tmp.eebe0f0c-8ad5-46c7-8e72-75a68c6c4613 is not empty - skipping!
1: [rank6]:W1029 20:10:46.625000 1008489 torch/_inductor/triton_bundler.py:401] [17/4_1] Directory /tmp/triton/4651/node1/rank1/tmp.9fe79fdf-12b4-4da4-9390-cfcc78cc11f6 is not empty - skipping!
1: [rank6]:W1029 20:10:47.224000 1008489 torch/_inductor/triton_bundler.py:401] [20/4] Directory /tmp/triton/4651/node1/rank1/tmp.6a3aca5a-13c8-47ad-a3ad-5fef5d51a6ab is not empty - skipping!
1: [rank6]:W1029 20:10:47.225000 1008489 torch/_inductor/triton_bundler.py:401] [20/4] Directory /tmp/triton/4651/node1/rank1/tmp.f6b3ab94-fc1c-4c10-9e58-2b0c9adba8f8 is not empty - skipping!
1: [rank4]:W1029 20:10:47.225000 1008487 torch/_inductor/triton_bundler.py:401] [20/4] Directory /tmp/triton/4651/node1/rank1/tmp.e46e1111-d6bc-4065-b759-465ecfc60fce is not empty - skipping!
1: [rank7]:W1029 20:10:47.225000 1008490 torch/_inductor/triton_bundler.py:401] [20/4] Directory /tmp/triton/4651/node1/rank1/tmp.fd089a22-1477-4912-9d11-aa4cf0d38064 is not empty - skipping!
1: [rank4]:W1029 20:10:47.226000 1008487 torch/_inductor/triton_bundler.py:401] [20/4] Directory /tmp/triton/4651/node1/rank1/tmp.ece56efc-f57d-4637-b80b-891d665982f5 is not empty - skipping!
1: [rank7]:W1029 20:10:47.226000 1008490 torch/_inductor/triton_bundler.py:401] [20/4] Directory /tmp/triton/4651/node1/rank1/tmp.92d2e9ae-44aa-4980-82ec-806425558f5f is not empty - skipping!
1: [rank4]:W1029 20:10:47.226000 1008487 torch/_inductor/triton_bundler.py:401] [20/4] Directory /tmp/triton/4651/node1/rank1/tmp.c46cddf2-3a20-47e2-9bde-3b2aff8a652c is not empty - skipping!
1: [rank7]:W1029 20:10:48.346000 1008490 torch/_inductor/triton_bundler.py:401] [39/8_1] Directory /tmp/triton/4651/node1/rank1/tmp.d872a3d1-5b2c-41ab-9ba3-feddc8c91277 is not empty - skipping!
1: [rank7]:W1029 20:10:48.347000 1008490 torch/_inductor/triton_bundler.py:401] [39/8_1] Directory /tmp/triton/4651/node1/rank1/tmp.0af2ac2d-3fcb-44dd-9e81-44bc1d9c5c5b is not empty - skipping!
1: [rank7]:W1029 20:10:49.017000 1008490 torch/_inductor/triton_bundler.py:401] [66/1] Directory /tmp/triton/4651/node1/rank1/tmp.4b1f3bc6-6350-4284-8280-542b26c1a188 is not empty - skipping!
1: [rank7]:W1029 20:10:49.018000 1008490 torch/_inductor/triton_bundler.py:401] [66/1] Directory /tmp/triton/4651/node1/rank1/tmp.2f5710dd-4d11-47a8-9fdd-d6753634276c is not empty - skipping!
1: [rank6]:W1029 20:10:49.018000 1008489 torch/_inductor/triton_bundler.py:401] [66/1] Directory /tmp/triton/4651/node1/rank1/tmp.d51b7137-68bb-472f-82a3-551d50e10896 is not empty - skipping!
0: Capturing batches (bs=8 avail_mem=23.55 GB):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 32/35 [01:02<00:22,  7.61s/it]Capturing batches (bs=4 avail_mem=23.54 GB):  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 32/35 [01:02<00:22,  7.61s/it]Capturing batches (bs=4 avail_mem=23.54 GB):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/35 [01:12<00:16,  8.33s/it]Capturing batches (bs=2 avail_mem=23.54 GB):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/35 [01:12<00:16,  8.33s/it][rank1]:W1029 08:10:56.829000 1153290 torch/_inductor/triton_bundler.py:401] [2/5_1] Directory /tmp/triton/4651/node0/rank0/tmp.692908cc-bb58-4086-b960-2bc43bb43f39 is not empty - skipping!
0: [rank2]:W1029 08:10:58.388000 1153291 torch/_inductor/triton_bundler.py:401] [19/5] Directory /tmp/triton/4651/node0/rank0/tmp.2704c552-142b-4eb0-8f0c-2f3cfb292baa is not empty - skipping!
0: [rank2]:W1029 08:10:58.389000 1153291 torch/_inductor/triton_bundler.py:401] [19/5] Directory /tmp/triton/4651/node0/rank0/tmp.15e3abab-d1fa-4f39-9182-c49f4bcd7b2b is not empty - skipping!
0: [rank2]:W1029 08:10:58.389000 1153291 torch/_inductor/triton_bundler.py:401] [19/5] Directory /tmp/triton/4651/node0/rank0/tmp.e12cff63-9b14-4e60-8399-c911b05adc06 is not empty - skipping!
0: [rank2]:W1029 08:10:58.390000 1153291 torch/_inductor/triton_bundler.py:401] [19/5] Directory /tmp/triton/4651/node0/rank0/tmp.ad2339ee-1af8-4a6e-b7d8-b04d07b2a57e is not empty - skipping!
0: [rank2]:W1029 08:10:58.390000 1153291 torch/_inductor/triton_bundler.py:401] [19/5] Directory /tmp/triton/4651/node0/rank0/tmp.5e1fc70f-3c6e-4b13-aa6b-69afa6c36223 is not empty - skipping!
0: [rank2]:W1029 08:10:58.391000 1153291 torch/_inductor/triton_bundler.py:401] [19/5] Directory /tmp/triton/4651/node0/rank0/tmp.7eabdb43-0842-4bf5-b53c-f2a36421d4f1 is not empty - skipping!
0: [rank0]:W1029 08:11:02.645000 1153289 torch/_inductor/triton_bundler.py:401] [56/2] Directory /tmp/triton/4651/node0/rank0/tmp.7eb9bbee-fea8-41fd-87f7-3fa6573da482 is not empty - skipping!
0: Capturing batches (bs=2 avail_mem=23.54 GB):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 34/35 [01:23<00:09,  9.31s/it]Capturing batches (bs=1 avail_mem=23.54 GB):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 34/35 [01:23<00:09,  9.31s/it][rank0]:W1029 08:11:08.808000 1153289 torch/_inductor/triton_bundler.py:401] [3/12_1] Directory /tmp/triton/4651/node0/rank0/tmp.b1ebc105-7a80-4726-8a42-61672577c34a is not empty - skipping!
0: [rank0]:W1029 08:11:08.808000 1153289 torch/_inductor/triton_bundler.py:401] [3/12_1] Directory /tmp/triton/4651/node0/rank0/tmp.f0fe732f-c210-46f1-bcff-0d5def5107d7 is not empty - skipping!
1: Capturing batches (bs=4 avail_mem=10.28 GB):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/35 [01:11<00:16,  8.39s/it]Capturing batches (bs=2 avail_mem=10.28 GB):  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 33/35 [01:11<00:16,  8.39s/it]Capturing batches (bs=2 avail_mem=10.28 GB):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 34/35 [01:22<00:09,  9.21s/it]Capturing batches (bs=1 avail_mem=10.27 GB):  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 34/35 [01:22<00:09,  9.21s/it][rank7]:W1029 20:11:16.978000 1008490 torch/_inductor/triton_bundler.py:401] [63/6] Directory /tmp/triton/4651/node1/rank1/tmp.ed3a4490-325c-4e10-b1f2-1052d6ecfccc is not empty - skipping!
1: Capturing batches (bs=1 avail_mem=10.27 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [01:33<00:00,  9.61s/it]Capturing batches (bs=1 avail_mem=10.27 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [01:33<00:00,  2.66s/it]
1: [2025-10-29 20:11:17 DP1 TP1 PP1] Registering 21 cuda graph addresses
1: [2025-10-29 20:11:17 DP0 TP0 PP1] Registering 21 cuda graph addresses
1: [2025-10-29 20:11:17 DP3 TP3 PP1] Registering 21 cuda graph addresses
1: [2025-10-29 20:11:17 DP2 TP2 PP1] Registering 21 cuda graph addresses
1: [2025-10-29 20:11:18 DP0 TP0 PP1] Capture cuda graph end. Time elapsed: 94.31 s. mem usage=8.58 GB. avail mem=10.27 GB.
0: [2025-10-29 08:11:18 DP3 TP3 PP0] Registering 0 cuda graph addresses
0: [2025-10-29 08:11:18 DP1 TP1 PP0] Registering 0 cuda graph addresses
0: Capturing batches (bs=1 avail_mem=23.54 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [01:34<00:00,  9.71s/it]Capturing batches (bs=1 avail_mem=23.54 GB): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 35/35 [01:34<00:00,  2.70s/it]
0: [2025-10-29 08:11:18 DP0 TP0 PP0] Registering 0 cuda graph addresses
0: [2025-10-29 08:11:18 DP2 TP2 PP0] Registering 0 cuda graph addresses
0: [2025-10-29 08:11:19 DP0 TP0 PP0] Capture cuda graph end. Time elapsed: 95.43 s. mem usage=4.91 GB. avail mem=23.53 GB.
0: [2025-10-29 08:11:20 DP0 TP0 PP0] max_total_num_tokens=849865, chunked_prefill_size=512, max_prefill_tokens=16384, max_running_requests=2744, context_len=163840, available_gpu_mem=23.53 GB
1: [2025-10-29 20:11:20 DP0 TP0 PP1] max_total_num_tokens=849865, chunked_prefill_size=512, max_prefill_tokens=16384, max_running_requests=2655, context_len=163840, available_gpu_mem=10.27 GB
1: [2025-10-29 20:11:20] Starting dummy health check server at 127.0.0.1:30000
0: [2025-10-29 08:11:32] 
0: Warmup...
0: [2025-10-29 08:11:32 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 1, 
0: [2025-10-29 08:11:32 DP0 TP0 PP0] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
0: [2025-10-29 08:11:32 DP0 TP0 PP0] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=32768, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
0: DeepGEMM warmup:   0%|          | 0/16384 [00:00<?, ?it/s]DeepGEMM warmup:  17%|â–ˆâ–‹        | 2743/16384 [00:00<00:00, 27424.80it/s]DeepGEMM warmup:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 6266/16384 [00:00<00:00, 32011.58it/s]DeepGEMM warmup:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 9971/16384 [00:00<00:00, 34309.44it/s]DeepGEMM warmup:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž | 13674/16384 [00:00<00:00, 35380.22it/s]DeepGEMM warmup: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16384/16384 [00:00<00:00, 34603.85it/s]
0: /sgl-workspace/sglang/python/sglang/srt/distributed/parallel_state.py:876: UserWarning: The given buffer is not writable, and PyTorch does not support non-writable tensors. This means you can write to the underlying (supposedly non-writable) buffer using the tensor. You may want to copy the buffer to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:1578.)
0:   object_tensor = torch.frombuffer(pickle.dumps(obj), dtype=torch.uint8).cuda(
0: /sgl-workspace/sglang/python/sglang/srt/distributed/parallel_state.py:876: UserWarning: The given buffer is not writable, and PyTorch does not support non-writable tensors. This means you can write to the underlying (supposedly non-writable) buffer using the tensor. You may want to copy the buffer to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:1578.)
0:   object_tensor = torch.frombuffer(pickle.dumps(obj), dtype=torch.uint8).cuda(
0: /sgl-workspace/sglang/python/sglang/srt/distributed/parallel_state.py:876: UserWarning: The given buffer is not writable, and PyTorch does not support non-writable tensors. This means you can write to the underlying (supposedly non-writable) buffer using the tensor. You may want to copy the buffer to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:1578.)
0:   object_tensor = torch.frombuffer(pickle.dumps(obj), dtype=torch.uint8).cuda(
0: /sgl-workspace/sglang/python/sglang/srt/distributed/parallel_state.py:876: UserWarning: The given buffer is not writable, and PyTorch does not support non-writable tensors. This means you can write to the underlying (supposedly non-writable) buffer using the tensor. You may want to copy the buffer to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:1578.)
0:   object_tensor = torch.frombuffer(pickle.dumps(obj), dtype=torch.uint8).cuda(
1: [2025-10-29 20:11:33 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 1, 
0: [2025-10-29 08:11:34 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 2, 
0: [2025-10-29 08:11:34 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 2, 
0: [2025-10-29 08:11:34 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 2, 
0: [2025-10-29 08:11:34 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
1: [2025-10-29 20:11:34 DP0 TP0 PP1] Entering DeepGEMM JIT Pre-Compile session. It may take a long time (typically 10-20 mins) if you have not run `sglang.compile_deep_gemm`. It is recommended to run `sglang.compile_deep_gemm` with same args as `sglang.launch_server` for pre-compilation to reduce the overhead if you have not run it before. For example: `python3 -m sglang.compile_deep_gemm --model deepseek-ai/DeepSeek-V3 --tp 8 --trust-remote-code`
1: [2025-10-29 20:11:34 DP0 TP0 PP1] Try DeepGEMM JIT Compiling for <GEMM_NT_F8F8BF16> N=32768, K=512, num_groups=1 with all Ms. It only takes a little time (typically 1 sec) if you have run `python3 -m sglang.compile_deep_gemm`. 
1: DeepGEMM warmup:   0%|          | 0/16384 [00:00<?, ?it/s]DeepGEMM warmup:  18%|â–ˆâ–Š        | 2920/16384 [00:00<00:00, 29192.65it/s]DeepGEMM warmup:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 6478/16384 [00:00<00:00, 32948.39it/s]DeepGEMM warmup:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 10178/16384 [00:00<00:00, 34797.60it/s]DeepGEMM warmup:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 13888/16384 [00:00<00:00, 35702.66it/s]DeepGEMM warmup: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 16384/16384 [00:00<00:00, 35044.72it/s]
1: /sgl-workspace/sglang/python/sglang/srt/distributed/parallel_state.py:876: UserWarning: The given buffer is not writable, and PyTorch does not support non-writable tensors. This means you can write to the underlying (supposedly non-writable) buffer using the tensor. You may want to copy the buffer to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:1578.)
1:   object_tensor = torch.frombuffer(pickle.dumps(obj), dtype=torch.uint8).cuda(
1: /sgl-workspace/sglang/python/sglang/srt/distributed/parallel_state.py:876: UserWarning: The given buffer is not writable, and PyTorch does not support non-writable tensors. This means you can write to the underlying (supposedly non-writable) buffer using the tensor. You may want to copy the buffer to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:1578.)
1:   object_tensor = torch.frombuffer(pickle.dumps(obj), dtype=torch.uint8).cuda(
1: /sgl-workspace/sglang/python/sglang/srt/distributed/parallel_state.py:876: UserWarning: The given buffer is not writable, and PyTorch does not support non-writable tensors. This means you can write to the underlying (supposedly non-writable) buffer using the tensor. You may want to copy the buffer to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:1578.)
1:   object_tensor = torch.frombuffer(pickle.dumps(obj), dtype=torch.uint8).cuda(
1: /sgl-workspace/sglang/python/sglang/srt/distributed/parallel_state.py:876: UserWarning: The given buffer is not writable, and PyTorch does not support non-writable tensors. This means you can write to the underlying (supposedly non-writable) buffer using the tensor. You may want to copy the buffer to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:1578.)
1:   object_tensor = torch.frombuffer(pickle.dumps(obj), dtype=torch.uint8).cuda(
1: [2025-10-29 20:11:35 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 2, 
1: [2025-10-29 20:11:35 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 2, 
1: [2025-10-29 20:11:35 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 2, 
1: [2025-10-29 20:11:35 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
0: [2025-10-29 08:11:35 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
0: [2025-10-29 08:11:35 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 511, #cached-token: 5, token usage: 0.00, #running-req: 0, #queue-req: 0, 
0: [2025-10-29 08:11:35 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
1: [2025-10-29 20:11:35 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 511, #cached-token: 5, token usage: 0.00, #running-req: 0, #queue-req: 0, 
1: [2025-10-29 20:11:35 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
1: [2025-10-29 20:11:35 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 0, 
0: [2025-10-29 08:11:37] 
0: Benchmark...
0: [2025-10-29 08:11:37 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 507, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
1: [2025-10-29 20:11:37 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 507, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 0, 
0: [2025-10-29 08:11:37 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.00, #running-req: 0, #queue-req: 42, 
0: [2025-10-29 08:11:37 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.00, #running-req: 0, #queue-req: 43, 
0: [2025-10-29 08:11:37 DP3 TP3 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 5, token usage: 0.00, #running-req: 0, #queue-req: 41, 
0: [2025-10-29 08:11:37 DP1 TP1 PP0] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 7, token usage: 0.00, #running-req: 0, #queue-req: 39, 
1: [2025-10-29 20:11:37 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.00, #running-req: 0, #queue-req: 42, 
1: [2025-10-29 20:11:37 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.00, #running-req: 0, #queue-req: 43, 
1: [2025-10-29 20:11:37 DP3 TP3 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 5, token usage: 0.00, #running-req: 0, #queue-req: 41, 
1: [2025-10-29 20:11:37 DP1 TP1 PP1] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 7, token usage: 0.00, #running-req: 0, #queue-req: 39, 
0: [2025-10-29 08:11:37 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 131, 
0: [2025-10-29 08:11:37 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 132, 
0: [2025-10-29 08:11:37 DP2 TP2 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 131, 
0: [2025-10-29 08:11:37 DP0 TP0 PP0] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 8, token usage: 0.00, #running-req: 1, #queue-req: 128, 
1: [2025-10-29 20:11:37 DP2 TP2 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 4, token usage: 0.00, #running-req: 0, #queue-req: 131, 
1: [2025-10-29 20:11:37 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 131, 
1: [2025-10-29 20:11:37 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 132, 
1: [2025-10-29 20:11:37 DP0 TP0 PP1] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 8, token usage: 0.00, #running-req: 1, #queue-req: 128, 
0: [2025-10-29 08:11:37 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.00, #running-req: 4, #queue-req: 149, 
0: [2025-10-29 08:11:37 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 6, #queue-req: 149, 
0: [2025-10-29 08:11:37 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.00, #running-req: 2, #queue-req: 145, 
0: [2025-10-29 08:11:37 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.00, #running-req: 2, #queue-req: 148, 
1: [2025-10-29 20:11:37 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.00, #running-req: 4, #queue-req: 149, 
1: [2025-10-29 20:11:37 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 6, #queue-req: 149, 
1: [2025-10-29 20:11:37 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.00, #running-req: 2, #queue-req: 148, 
1: [2025-10-29 20:11:37 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.00, #running-req: 2, #queue-req: 145, 
0: [2025-10-29 08:11:37 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 174, 
0: [2025-10-29 08:11:37 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 3, token usage: 0.00, #running-req: 1, #queue-req: 171, 
0: [2025-10-29 08:11:37 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 4, #queue-req: 173, 
0: [2025-10-29 08:11:37 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.00, #running-req: 7, #queue-req: 168, 
1: [2025-10-29 20:11:37 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 0, #queue-req: 174, 
1: [2025-10-29 20:11:37 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 4, #queue-req: 173, 
1: [2025-10-29 20:11:37 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 3, token usage: 0.00, #running-req: 1, #queue-req: 171, 
1: [2025-10-29 20:11:37 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.00, #running-req: 7, #queue-req: 168, 
0: [2025-10-29 08:11:37 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.00, #running-req: 6, #queue-req: 194, 
0: [2025-10-29 08:11:37 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 4, #queue-req: 189, 
0: [2025-10-29 08:11:37 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.00, #running-req: 5, #queue-req: 189, 
0: [2025-10-29 08:11:37 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 3, #queue-req: 194, 
1: [2025-10-29 20:11:37 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.00, #running-req: 6, #queue-req: 194, 
1: [2025-10-29 20:11:37 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 4, #queue-req: 189, 
1: [2025-10-29 20:11:37 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 3, #queue-req: 194, 
1: [2025-10-29 20:11:37 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.00, #running-req: 5, #queue-req: 189, 
0: [2025-10-29 08:11:37 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 218, 
0: [2025-10-29 08:11:37 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.00, #running-req: 4, #queue-req: 213, 
0: [2025-10-29 08:11:37 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 4, #queue-req: 219, 
0: [2025-10-29 08:11:37 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 8, #queue-req: 214, 
1: [2025-10-29 20:11:37 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 4, #queue-req: 219, 
1: [2025-10-29 20:11:37 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.00, #running-req: 0, #queue-req: 218, 
1: [2025-10-29 20:11:37 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 8, #queue-req: 214, 
1: [2025-10-29 20:11:37 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.00, #running-req: 4, #queue-req: 213, 
0: [2025-10-29 08:11:37 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.00, #running-req: 4, #queue-req: 238, 
0: [2025-10-29 08:11:37 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.00, #running-req: 3, #queue-req: 241, 
0: [2025-10-29 08:11:37 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.00, #running-req: 7, #queue-req: 235, 
0: [2025-10-29 08:11:37 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 7, #queue-req: 243, 
1: [2025-10-29 20:11:38 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.00, #running-req: 3, #queue-req: 241, 
1: [2025-10-29 20:11:38 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.00, #running-req: 4, #queue-req: 238, 
1: [2025-10-29 20:11:38 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.00, #running-req: 7, #queue-req: 243, 
1: [2025-10-29 20:11:38 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.00, #running-req: 7, #queue-req: 235, 
0: [2025-10-29 08:11:38 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.00, #running-req: 1, #queue-req: 261, 
0: [2025-10-29 08:11:38 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.00, #running-req: 4, #queue-req: 261, 
0: [2025-10-29 08:11:38 DP0 TP0 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 5, token usage: 0.00, #running-req: 8, #queue-req: 254, 
0: [2025-10-29 08:11:38 DP3 TP3 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 6, token usage: 0.00, #running-req: 5, #queue-req: 251, 
1: [2025-10-29 20:11:38 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.00, #running-req: 4, #queue-req: 261, 
1: [2025-10-29 20:11:38 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.00, #running-req: 1, #queue-req: 261, 
1: [2025-10-29 20:11:38 DP0 TP0 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 5, token usage: 0.00, #running-req: 8, #queue-req: 254, 
1: [2025-10-29 20:11:38 DP3 TP3 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 6, token usage: 0.00, #running-req: 5, #queue-req: 251, 
0: [2025-10-29 08:11:38 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.00, #running-req: 7, #queue-req: 283, 
0: [2025-10-29 08:11:38 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.00, #running-req: 10, #queue-req: 276, 
0: [2025-10-29 08:11:38 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.00, #running-req: 5, #queue-req: 285, 
0: [2025-10-29 08:11:38 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.01, #running-req: 5, #queue-req: 278, 
1: [2025-10-29 20:11:38 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.00, #running-req: 5, #queue-req: 285, 
1: [2025-10-29 20:11:38 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.00, #running-req: 7, #queue-req: 283, 
1: [2025-10-29 20:11:38 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.01, #running-req: 5, #queue-req: 278, 
1: [2025-10-29 20:11:38 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.00, #running-req: 10, #queue-req: 276, 
0: [2025-10-29 08:11:38 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 3, #queue-req: 311, 
0: [2025-10-29 08:11:38 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.01, #running-req: 9, #queue-req: 300, 
0: [2025-10-29 08:11:38 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 12, #queue-req: 306, 
0: [2025-10-29 08:11:38 DP2 TP2 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 6, token usage: 0.01, #running-req: 5, #queue-req: 307, 
1: [2025-10-29 20:11:38 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 12, #queue-req: 306, 
1: [2025-10-29 20:11:38 DP2 TP2 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 6, token usage: 0.01, #running-req: 5, #queue-req: 307, 
1: [2025-10-29 20:11:38 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.01, #running-req: 9, #queue-req: 300, 
1: [2025-10-29 20:11:38 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 3, #queue-req: 311, 
0: [2025-10-29 08:11:38 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 5, token usage: 0.01, #running-req: 10, #queue-req: 324, 
0: [2025-10-29 08:11:38 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.01, #running-req: 11, #queue-req: 315, 
0: [2025-10-29 08:11:38 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 3, token usage: 0.01, #running-req: 6, #queue-req: 322, 
0: [2025-10-29 08:11:38 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 9, token usage: 0.01, #running-req: 6, #queue-req: 321, 
1: [2025-10-29 20:11:38 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.01, #running-req: 11, #queue-req: 315, 
1: [2025-10-29 20:11:38 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 5, token usage: 0.01, #running-req: 10, #queue-req: 324, 
1: [2025-10-29 20:11:38 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 3, token usage: 0.01, #running-req: 6, #queue-req: 322, 
1: [2025-10-29 20:11:38 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 9, token usage: 0.01, #running-req: 6, #queue-req: 321, 
0: [2025-10-29 08:11:38 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.01, #running-req: 12, #queue-req: 345, 
0: [2025-10-29 08:11:38 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.01, #running-req: 3, #queue-req: 348, 
0: [2025-10-29 08:11:38 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.01, #running-req: 10, #queue-req: 347, 
0: [2025-10-29 08:11:38 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.01, #running-req: 12, #queue-req: 340, 
1: [2025-10-29 20:11:38 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.01, #running-req: 3, #queue-req: 348, 
1: [2025-10-29 20:11:38 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.01, #running-req: 12, #queue-req: 345, 
1: [2025-10-29 20:11:38 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.01, #running-req: 10, #queue-req: 347, 
1: [2025-10-29 20:11:38 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.01, #running-req: 12, #queue-req: 340, 
0: [2025-10-29 08:11:38 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 13, #queue-req: 366, 
0: [2025-10-29 08:11:38 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.01, #running-req: 14, #queue-req: 374, 
0: [2025-10-29 08:11:38 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 9, #queue-req: 374, 
0: [2025-10-29 08:11:38 DP0 TP0 PP0] Prefill batch. #new-seq: 9, #new-token: 512, #cached-token: 13, token usage: 0.01, #running-req: 8, #queue-req: 363, 
1: [2025-10-29 20:11:38 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 9, #queue-req: 374, 
1: [2025-10-29 20:11:38 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 13, #queue-req: 366, 
1: [2025-10-29 20:11:38 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.01, #running-req: 14, #queue-req: 374, 
1: [2025-10-29 20:11:38 DP0 TP0 PP1] Prefill batch. #new-seq: 9, #new-token: 512, #cached-token: 13, token usage: 0.01, #running-req: 8, #queue-req: 363, 
0: [2025-10-29 08:11:38 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 5, #queue-req: 374, 
0: [2025-10-29 08:11:38 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 14, #queue-req: 367, 
0: [2025-10-29 08:11:38 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 11, #queue-req: 374, 
0: [2025-10-29 08:11:38 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.01, #running-req: 15, #queue-req: 360, 
1: [2025-10-29 20:11:38 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 5, #queue-req: 374, 
1: [2025-10-29 20:11:38 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 11, #queue-req: 374, 
1: [2025-10-29 20:11:38 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.01, #running-req: 15, #queue-req: 360, 
1: [2025-10-29 20:11:38 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 14, #queue-req: 367, 
0: [2025-10-29 08:11:38 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 13, #queue-req: 367, 
0: [2025-10-29 08:11:38 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.01, #running-req: 9, #queue-req: 373, 
0: [2025-10-29 08:11:38 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.01, #running-req: 16, #queue-req: 359, 
0: [2025-10-29 08:11:38 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 15, #queue-req: 374, 
1: [2025-10-29 20:11:38 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.01, #running-req: 9, #queue-req: 373, 
1: [2025-10-29 20:11:38 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 13, #queue-req: 367, 
1: [2025-10-29 20:11:38 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.01, #running-req: 16, #queue-req: 359, 
1: [2025-10-29 20:11:38 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 15, #queue-req: 374, 
0: [2025-10-29 08:11:38 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 5, #queue-req: 374, 
0: [2025-10-29 08:11:38 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.01, #running-req: 11, #queue-req: 372, 
0: [2025-10-29 08:11:38 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 14, #queue-req: 367, 
0: [2025-10-29 08:11:38 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.01, #running-req: 18, #queue-req: 357, 
1: [2025-10-29 20:11:38 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.01, #running-req: 11, #queue-req: 372, 
1: [2025-10-29 20:11:38 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 5, #queue-req: 374, 
1: [2025-10-29 20:11:38 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 14, #queue-req: 367, 
1: [2025-10-29 20:11:38 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.01, #running-req: 18, #queue-req: 357, 
0: [2025-10-29 08:11:38 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 15, #queue-req: 385, 
0: [2025-10-29 08:11:38 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 17, #queue-req: 368, 
0: [2025-10-29 08:11:38 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 3, token usage: 0.01, #running-req: 13, #queue-req: 374, 
0: [2025-10-29 08:11:38 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.01, #running-req: 10, #queue-req: 382, 
1: [2025-10-29 20:11:38 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 15, #queue-req: 385, 
1: [2025-10-29 20:11:38 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 17, #queue-req: 368, 
1: [2025-10-29 20:11:38 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.01, #running-req: 10, #queue-req: 382, 
1: [2025-10-29 20:11:38 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 3, token usage: 0.01, #running-req: 13, #queue-req: 374, 
0: [2025-10-29 08:11:38 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 14, #queue-req: 399, 
0: [2025-10-29 08:11:38 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 5, #queue-req: 409, 
0: [2025-10-29 08:11:38 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 20, #queue-req: 393, 
0: [2025-10-29 08:11:38 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.01, #running-req: 12, #queue-req: 403, 
1: [2025-10-29 20:11:38 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 20, #queue-req: 393, 
1: [2025-10-29 20:11:38 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 14, #queue-req: 399, 
1: [2025-10-29 20:11:38 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 5, #queue-req: 409, 
1: [2025-10-29 20:11:38 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.01, #running-req: 12, #queue-req: 403, 
0: [2025-10-29 08:11:38 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 15, #queue-req: 434, 
0: [2025-10-29 08:11:38 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.01, #running-req: 16, #queue-req: 421, 
0: [2025-10-29 08:11:38 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.01, #running-req: 11, #queue-req: 426, 
0: [2025-10-29 08:11:38 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.01, #running-req: 17, #queue-req: 416, 
1: [2025-10-29 20:11:38 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 15, #queue-req: 434, 
1: [2025-10-29 20:11:38 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.01, #running-req: 11, #queue-req: 426, 
1: [2025-10-29 20:11:38 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.01, #running-req: 16, #queue-req: 421, 
1: [2025-10-29 20:11:38 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.01, #running-req: 17, #queue-req: 416, 
0: [2025-10-29 08:11:38 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 14, #queue-req: 444, 
0: [2025-10-29 08:11:38 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 3, token usage: 0.01, #running-req: 20, #queue-req: 437, 
0: [2025-10-29 08:11:38 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 5, #queue-req: 458, 
0: [2025-10-29 08:11:38 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 447, 
1: [2025-10-29 20:11:38 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 3, token usage: 0.01, #running-req: 20, #queue-req: 437, 
1: [2025-10-29 20:11:38 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 14, #queue-req: 444, 
1: [2025-10-29 20:11:38 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 3, token usage: 0.01, #running-req: 15, #queue-req: 447, 
1: [2025-10-29 20:11:38 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 5, #queue-req: 458, 
0: [2025-10-29 08:11:38 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 19, #queue-req: 466, 
0: [2025-10-29 08:11:38 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.01, #running-req: 18, #queue-req: 457, 
0: [2025-10-29 08:11:38 DP2 TP2 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 5, token usage: 0.01, #running-req: 13, #queue-req: 464, 
0: [2025-10-29 08:11:38 DP1 TP1 PP0] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 8, token usage: 0.01, #running-req: 15, #queue-req: 473, 
1: [2025-10-29 20:11:38 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.01, #running-req: 18, #queue-req: 457, 
1: [2025-10-29 20:11:38 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 19, #queue-req: 466, 
1: [2025-10-29 20:11:38 DP2 TP2 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 5, token usage: 0.01, #running-req: 13, #queue-req: 464, 
1: [2025-10-29 20:11:38 DP1 TP1 PP1] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 8, token usage: 0.01, #running-req: 15, #queue-req: 473, 
0: [2025-10-29 08:11:38 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.01, #running-req: 14, #queue-req: 465, 
0: [2025-10-29 08:11:38 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.01, #running-req: 5, #queue-req: 469, 
0: [2025-10-29 08:11:38 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 18, #queue-req: 464, 
0: [2025-10-29 08:11:38 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.01, #running-req: 23, #queue-req: 455, 
1: [2025-10-29 20:11:39 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 18, #queue-req: 464, 
1: [2025-10-29 20:11:39 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.01, #running-req: 14, #queue-req: 465, 
1: [2025-10-29 20:11:39 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.01, #running-req: 5, #queue-req: 469, 
1: [2025-10-29 20:11:39 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.01, #running-req: 23, #queue-req: 455, 
0: [2025-10-29 08:11:39 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.01, #running-req: 19, #queue-req: 463, 
0: [2025-10-29 08:11:39 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 19, #queue-req: 455, 
0: [2025-10-29 08:11:39 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.01, #running-req: 21, #queue-req: 468, 
0: [2025-10-29 08:11:39 DP2 TP2 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 6, token usage: 0.01, #running-req: 17, #queue-req: 460, 
1: [2025-10-29 20:11:39 DP2 TP2 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 6, token usage: 0.01, #running-req: 17, #queue-req: 460, 
1: [2025-10-29 20:11:39 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.01, #running-req: 19, #queue-req: 463, 
1: [2025-10-29 20:11:39 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 19, #queue-req: 455, 
1: [2025-10-29 20:11:39 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.01, #running-req: 21, #queue-req: 468, 
0: [2025-10-29 08:11:39 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.01, #running-req: 18, #queue-req: 458, 
0: [2025-10-29 08:11:39 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 25, #queue-req: 455, 
0: [2025-10-29 08:11:39 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.01, #running-req: 9, #queue-req: 467, 
0: [2025-10-29 08:11:39 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.01, #running-req: 15, #queue-req: 460, 
1: [2025-10-29 20:11:39 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.01, #running-req: 18, #queue-req: 458, 
1: [2025-10-29 20:11:39 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.01, #running-req: 25, #queue-req: 455, 
1: [2025-10-29 20:11:39 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.01, #running-req: 9, #queue-req: 467, 
1: [2025-10-29 20:11:39 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.01, #running-req: 15, #queue-req: 460, 
0: [2025-10-29 08:11:39 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 19, #queue-req: 453, 
0: [2025-10-29 08:11:39 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.01, #running-req: 22, #queue-req: 466, 
0: [2025-10-29 08:11:39 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.01, #running-req: 21, #queue-req: 458, 
0: [2025-10-29 08:11:39 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.01, #running-req: 21, #queue-req: 455, 
1: [2025-10-29 20:11:39 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.01, #running-req: 22, #queue-req: 466, 
1: [2025-10-29 20:11:39 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.01, #running-req: 21, #queue-req: 458, 
1: [2025-10-29 20:11:39 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 19, #queue-req: 453, 
1: [2025-10-29 20:11:39 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.01, #running-req: 21, #queue-req: 455, 
0: [2025-10-29 08:11:39 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 25, #queue-req: 452, 
0: [2025-10-29 08:11:39 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.02, #running-req: 18, #queue-req: 456, 
0: [2025-10-29 08:11:39 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.02, #running-req: 20, #queue-req: 453, 
0: [2025-10-29 08:11:39 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 7, token usage: 0.02, #running-req: 10, #queue-req: 462, 
1: [2025-10-29 20:11:39 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 25, #queue-req: 452, 
1: [2025-10-29 20:11:39 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.02, #running-req: 20, #queue-req: 453, 
1: [2025-10-29 20:11:39 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.02, #running-req: 18, #queue-req: 456, 
1: [2025-10-29 20:11:39 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 7, token usage: 0.02, #running-req: 10, #queue-req: 462, 
0: [2025-10-29 08:11:39 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 21, #queue-req: 451, 
0: [2025-10-29 08:11:39 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 23, #queue-req: 455, 
0: [2025-10-29 08:11:39 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 23, #queue-req: 461, 
0: [2025-10-29 08:11:39 DP2 TP2 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 6, token usage: 0.02, #running-req: 24, #queue-req: 449, 
1: [2025-10-29 20:11:39 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 21, #queue-req: 451, 
1: [2025-10-29 20:11:39 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 23, #queue-req: 461, 
1: [2025-10-29 20:11:39 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 23, #queue-req: 455, 
1: [2025-10-29 20:11:39 DP2 TP2 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 6, token usage: 0.02, #running-req: 24, #queue-req: 449, 
0: [2025-10-29 08:11:39 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 14, #queue-req: 460, 
0: [2025-10-29 08:11:39 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 20, #queue-req: 454, 
0: [2025-10-29 08:11:39 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.02, #running-req: 22, #queue-req: 449, 
0: [2025-10-29 08:11:39 DP0 TP0 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 4, token usage: 0.02, #running-req: 26, #queue-req: 447, 
1: [2025-10-29 20:11:39 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 14, #queue-req: 460, 
1: [2025-10-29 20:11:39 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 20, #queue-req: 454, 
1: [2025-10-29 20:11:39 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.02, #running-req: 22, #queue-req: 449, 
1: [2025-10-29 20:11:39 DP0 TP0 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 4, token usage: 0.02, #running-req: 26, #queue-req: 447, 
0: [2025-10-29 08:11:39 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 24, #queue-req: 459, 
0: [2025-10-29 08:11:39 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.02, #running-req: 24, #queue-req: 454, 
0: [2025-10-29 08:11:39 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 22, #queue-req: 446, 
0: [2025-10-29 08:11:39 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 11, token usage: 0.02, #running-req: 28, #queue-req: 447, 
1: [2025-10-29 20:11:39 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 22, #queue-req: 446, 
1: [2025-10-29 20:11:39 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 24, #queue-req: 459, 
1: [2025-10-29 20:11:39 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.02, #running-req: 24, #queue-req: 454, 
1: [2025-10-29 20:11:39 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 11, token usage: 0.02, #running-req: 28, #queue-req: 447, 
0: [2025-10-29 08:11:39 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 22, #queue-req: 446, 
0: [2025-10-29 08:11:39 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 10, token usage: 0.02, #running-req: 30, #queue-req: 444, 
0: [2025-10-29 08:11:39 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 457, 
0: [2025-10-29 08:11:39 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.02, #running-req: 21, #queue-req: 451, 
1: [2025-10-29 20:11:39 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 22, #queue-req: 446, 
1: [2025-10-29 20:11:39 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.02, #running-req: 15, #queue-req: 457, 
1: [2025-10-29 20:11:39 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 10, token usage: 0.02, #running-req: 30, #queue-req: 444, 
1: [2025-10-29 20:11:39 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.02, #running-req: 21, #queue-req: 451, 
0: [2025-10-29 08:11:39 DP3 TP3 PP0] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 13, token usage: 0.02, #running-req: 24, #queue-req: 444, 
0: [2025-10-29 08:11:39 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 9, token usage: 0.02, #running-req: 23, #queue-req: 442, 
0: [2025-10-29 08:11:39 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 30, #queue-req: 445, 
0: [2025-10-29 08:11:39 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 7, token usage: 0.02, #running-req: 25, #queue-req: 453, 
1: [2025-10-29 20:11:39 DP3 TP3 PP1] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 13, token usage: 0.02, #running-req: 24, #queue-req: 444, 
1: [2025-10-29 20:11:39 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 7, token usage: 0.02, #running-req: 25, #queue-req: 453, 
1: [2025-10-29 20:11:39 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 30, #queue-req: 445, 
1: [2025-10-29 20:11:39 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 9, token usage: 0.02, #running-req: 23, #queue-req: 442, 
0: [2025-10-29 08:11:39 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.02, #running-req: 17, #queue-req: 453, 
0: [2025-10-29 08:11:39 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 23, #queue-req: 444, 
0: [2025-10-29 08:11:39 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.02, #running-req: 32, #queue-req: 440, 
0: [2025-10-29 08:11:39 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.02, #running-req: 24, #queue-req: 442, 
1: [2025-10-29 20:11:39 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 23, #queue-req: 444, 
1: [2025-10-29 20:11:39 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.02, #running-req: 32, #queue-req: 440, 
1: [2025-10-29 20:11:39 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.02, #running-req: 17, #queue-req: 453, 
1: [2025-10-29 20:11:39 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.02, #running-req: 24, #queue-req: 442, 
0: [2025-10-29 08:11:39 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.02, #running-req: 25, #queue-req: 440, 
0: [2025-10-29 08:11:39 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.02, #running-req: 29, #queue-req: 451, 
0: [2025-10-29 08:11:39 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 31, #queue-req: 441, 
0: [2025-10-29 08:11:39 DP2 TP2 PP0] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 11, token usage: 0.02, #running-req: 31, #queue-req: 437, 
1: [2025-10-29 20:11:39 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.02, #running-req: 25, #queue-req: 440, 
1: [2025-10-29 20:11:39 DP2 TP2 PP1] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 11, token usage: 0.02, #running-req: 31, #queue-req: 437, 
1: [2025-10-29 20:11:39 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 31, #queue-req: 441, 
1: [2025-10-29 20:11:39 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.02, #running-req: 29, #queue-req: 451, 
0: [2025-10-29 08:11:39 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.02, #running-req: 17, #queue-req: 447, 
0: [2025-10-29 08:11:39 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 34, #queue-req: 439, 
0: [2025-10-29 08:11:39 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 24, #queue-req: 436, 
0: [2025-10-29 08:11:39 DP3 TP3 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 6, token usage: 0.02, #running-req: 26, #queue-req: 437, 
1: [2025-10-29 20:11:39 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.02, #running-req: 17, #queue-req: 447, 
1: [2025-10-29 20:11:39 DP3 TP3 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 6, token usage: 0.02, #running-req: 26, #queue-req: 437, 
1: [2025-10-29 20:11:39 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 24, #queue-req: 436, 
1: [2025-10-29 20:11:39 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 34, #queue-req: 439, 
0: [2025-10-29 08:11:39 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.02, #running-req: 25, #queue-req: 438, 
0: [2025-10-29 08:11:39 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.02, #running-req: 32, #queue-req: 437, 
0: [2025-10-29 08:11:39 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 31, #queue-req: 446, 
0: [2025-10-29 08:11:39 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 38, #queue-req: 435, 
1: [2025-10-29 20:11:39 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.02, #running-req: 25, #queue-req: 438, 
1: [2025-10-29 20:11:39 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 31, #queue-req: 446, 
1: [2025-10-29 20:11:39 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.02, #running-req: 32, #queue-req: 437, 
1: [2025-10-29 20:11:39 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 38, #queue-req: 435, 
0: [2025-10-29 08:11:39 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 35, #queue-req: 437, 
0: [2025-10-29 08:11:39 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 30, #queue-req: 435, 
0: [2025-10-29 08:11:39 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.02, #running-req: 21, #queue-req: 443, 
0: [2025-10-29 08:11:39 DP2 TP2 PP0] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 16, token usage: 0.02, #running-req: 25, #queue-req: 428, 
1: [2025-10-29 20:11:39 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 35, #queue-req: 437, 
1: [2025-10-29 20:11:39 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.02, #running-req: 21, #queue-req: 443, 
1: [2025-10-29 20:11:39 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 30, #queue-req: 435, 
1: [2025-10-29 20:11:39 DP2 TP2 PP1] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 16, token usage: 0.02, #running-req: 25, #queue-req: 428, 
0: [2025-10-29 08:11:39 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.02, #running-req: 32, #queue-req: 435, 
0: [2025-10-29 08:11:39 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.02, #running-req: 26, #queue-req: 434, 
0: [2025-10-29 08:11:39 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 39, #queue-req: 427, 
0: [2025-10-29 08:11:39 DP1 TP1 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 5, token usage: 0.02, #running-req: 32, #queue-req: 438, 
1: [2025-10-29 20:11:39 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.02, #running-req: 32, #queue-req: 435, 
1: [2025-10-29 20:11:39 DP1 TP1 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 5, token usage: 0.02, #running-req: 32, #queue-req: 438, 
1: [2025-10-29 20:11:39 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 39, #queue-req: 427, 
1: [2025-10-29 20:11:39 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.02, #running-req: 26, #queue-req: 434, 
0: [2025-10-29 08:11:39 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.02, #running-req: 24, #queue-req: 437, 
0: [2025-10-29 08:11:39 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 36, #queue-req: 433, 
0: [2025-10-29 08:11:39 DP3 TP3 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 6, token usage: 0.02, #running-req: 32, #queue-req: 431, 
0: [2025-10-29 08:11:39 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.02, #running-req: 32, #queue-req: 424, 
1: [2025-10-29 20:11:39 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.02, #running-req: 24, #queue-req: 437, 
1: [2025-10-29 20:11:39 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 36, #queue-req: 433, 
1: [2025-10-29 20:11:39 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.02, #running-req: 32, #queue-req: 424, 
1: [2025-10-29 20:11:39 DP3 TP3 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 6, token usage: 0.02, #running-req: 32, #queue-req: 431, 
0: [2025-10-29 08:11:39 DP3 TP3 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.02, #running-req: 32, #queue-req: 427, 
0: [2025-10-29 08:11:39 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 29, #queue-req: 432, 
0: [2025-10-29 08:11:39 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.02, #running-req: 37, #queue-req: 437, 
0: [2025-10-29 08:11:39 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.02, #running-req: 40, #queue-req: 423, 
1: [2025-10-29 20:11:40 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.02, #running-req: 40, #queue-req: 423, 
1: [2025-10-29 20:11:40 DP3 TP3 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.02, #running-req: 32, #queue-req: 427, 
1: [2025-10-29 20:11:40 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.02, #running-req: 37, #queue-req: 437, 
1: [2025-10-29 20:11:40 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 29, #queue-req: 432, 
0: [2025-10-29 08:11:40 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 37, #queue-req: 431, 
0: [2025-10-29 08:11:40 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 25, #queue-req: 435, 
0: [2025-10-29 08:11:40 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 35, #queue-req: 422, 
0: [2025-10-29 08:11:40 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.02, #running-req: 36, #queue-req: 425, 
1: [2025-10-29 20:11:40 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.02, #running-req: 35, #queue-req: 422, 
1: [2025-10-29 20:11:40 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 37, #queue-req: 431, 
1: [2025-10-29 20:11:40 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.02, #running-req: 36, #queue-req: 425, 
1: [2025-10-29 20:11:40 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 25, #queue-req: 435, 
0: [2025-10-29 08:11:40 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.02, #running-req: 37, #queue-req: 432, 
0: [2025-10-29 08:11:40 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 30, #queue-req: 430, 
0: [2025-10-29 08:11:40 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.02, #running-req: 36, #queue-req: 424, 
0: [2025-10-29 08:11:40 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 41, #queue-req: 420, 
1: [2025-10-29 20:11:40 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 30, #queue-req: 430, 
1: [2025-10-29 20:11:40 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.02, #running-req: 41, #queue-req: 420, 
1: [2025-10-29 20:11:40 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.02, #running-req: 37, #queue-req: 432, 
1: [2025-10-29 20:11:40 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.02, #running-req: 36, #queue-req: 424, 
0: [2025-10-29 08:11:40 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.02, #running-req: 27, #queue-req: 432, 
0: [2025-10-29 08:11:40 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.03, #running-req: 38, #queue-req: 427, 
0: [2025-10-29 08:11:40 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.02, #running-req: 38, #queue-req: 423, 
0: [2025-10-29 08:11:40 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.02, #running-req: 36, #queue-req: 419, 
1: [2025-10-29 20:11:40 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.02, #running-req: 36, #queue-req: 419, 
1: [2025-10-29 20:11:40 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.02, #running-req: 27, #queue-req: 432, 
1: [2025-10-29 20:11:40 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.02, #running-req: 38, #queue-req: 423, 
1: [2025-10-29 20:11:40 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.03, #running-req: 38, #queue-req: 427, 
0: [2025-10-29 08:11:40 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 31, #queue-req: 427, 
0: [2025-10-29 08:11:40 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 43, #queue-req: 419, 
0: [2025-10-29 08:11:40 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.03, #running-req: 37, #queue-req: 422, 
0: [2025-10-29 08:11:40 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.03, #running-req: 40, #queue-req: 431, 
1: [2025-10-29 20:11:40 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 31, #queue-req: 427, 
1: [2025-10-29 20:11:40 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 43, #queue-req: 419, 
1: [2025-10-29 20:11:40 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.03, #running-req: 40, #queue-req: 431, 
1: [2025-10-29 20:11:40 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.03, #running-req: 37, #queue-req: 422, 
0: [2025-10-29 08:11:40 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.03, #running-req: 27, #queue-req: 428, 
0: [2025-10-29 08:11:40 DP0 TP0 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 9, token usage: 0.03, #running-req: 41, #queue-req: 423, 
0: [2025-10-29 08:11:40 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.03, #running-req: 39, #queue-req: 421, 
0: [2025-10-29 08:11:40 DP2 TP2 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 10, token usage: 0.03, #running-req: 37, #queue-req: 414, 
1: [2025-10-29 20:11:40 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.03, #running-req: 27, #queue-req: 428, 
1: [2025-10-29 20:11:40 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.03, #running-req: 39, #queue-req: 421, 
1: [2025-10-29 20:11:40 DP0 TP0 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 9, token usage: 0.03, #running-req: 41, #queue-req: 423, 
1: [2025-10-29 20:11:40 DP2 TP2 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 10, token usage: 0.03, #running-req: 37, #queue-req: 414, 
0: [2025-10-29 08:11:40 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 31, #queue-req: 423, 
0: [2025-10-29 08:11:40 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.03, #running-req: 43, #queue-req: 413, 
0: [2025-10-29 08:11:40 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.03, #running-req: 38, #queue-req: 420, 
0: [2025-10-29 08:11:40 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 41, #queue-req: 428, 
1: [2025-10-29 20:11:40 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 31, #queue-req: 423, 
1: [2025-10-29 20:11:40 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.03, #running-req: 43, #queue-req: 413, 
1: [2025-10-29 20:11:40 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 41, #queue-req: 428, 
1: [2025-10-29 20:11:40 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.03, #running-req: 38, #queue-req: 420, 
0: [2025-10-29 08:11:40 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 42, #queue-req: 413, 
0: [2025-10-29 08:11:40 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.03, #running-req: 30, #queue-req: 426, 
0: [2025-10-29 08:11:40 DP0 TP0 PP0] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 10, token usage: 0.03, #running-req: 45, #queue-req: 417, 
0: [2025-10-29 08:11:40 DP3 TP3 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 4, token usage: 0.03, #running-req: 40, #queue-req: 416, 
1: [2025-10-29 20:11:40 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.03, #running-req: 30, #queue-req: 426, 
1: [2025-10-29 20:11:40 DP3 TP3 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 4, token usage: 0.03, #running-req: 40, #queue-req: 416, 
1: [2025-10-29 20:11:40 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 42, #queue-req: 413, 
1: [2025-10-29 20:11:40 DP0 TP0 PP1] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 10, token usage: 0.03, #running-req: 45, #queue-req: 417, 
0: [2025-10-29 08:11:40 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.03, #running-req: 41, #queue-req: 424, 
0: [2025-10-29 08:11:40 DP0 TP0 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 12, token usage: 0.03, #running-req: 31, #queue-req: 412, 
0: [2025-10-29 08:11:40 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.03, #running-req: 39, #queue-req: 415, 
0: [2025-10-29 08:11:40 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.03, #running-req: 44, #queue-req: 411, 
1: [2025-10-29 20:11:40 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.03, #running-req: 41, #queue-req: 424, 
1: [2025-10-29 20:11:40 DP0 TP0 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 12, token usage: 0.03, #running-req: 31, #queue-req: 412, 
1: [2025-10-29 20:11:40 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.03, #running-req: 39, #queue-req: 415, 
1: [2025-10-29 20:11:40 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.03, #running-req: 44, #queue-req: 411, 
0: [2025-10-29 08:11:40 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.03, #running-req: 42, #queue-req: 408, 
0: [2025-10-29 08:11:40 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.03, #running-req: 51, #queue-req: 411, 
0: [2025-10-29 08:11:40 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.03, #running-req: 44, #queue-req: 414, 
0: [2025-10-29 08:11:40 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 7, token usage: 0.03, #running-req: 32, #queue-req: 420, 
1: [2025-10-29 20:11:40 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.03, #running-req: 42, #queue-req: 408, 
1: [2025-10-29 20:11:40 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.03, #running-req: 51, #queue-req: 411, 
1: [2025-10-29 20:11:40 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.03, #running-req: 44, #queue-req: 414, 
1: [2025-10-29 20:11:40 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 7, token usage: 0.03, #running-req: 32, #queue-req: 420, 
0: [2025-10-29 08:11:40 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 36, #queue-req: 411, 
0: [2025-10-29 08:11:40 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.03, #running-req: 46, #queue-req: 406, 
0: [2025-10-29 08:11:40 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.03, #running-req: 40, #queue-req: 412, 
0: [2025-10-29 08:11:40 DP1 TP1 PP0] Prefill batch. #new-seq: 9, #new-token: 512, #cached-token: 17, token usage: 0.03, #running-req: 43, #queue-req: 412, 
1: [2025-10-29 20:11:40 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.03, #running-req: 40, #queue-req: 412, 
1: [2025-10-29 20:11:40 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 36, #queue-req: 411, 
1: [2025-10-29 20:11:40 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.03, #running-req: 46, #queue-req: 406, 
1: [2025-10-29 20:11:40 DP1 TP1 PP1] Prefill batch. #new-seq: 9, #new-token: 512, #cached-token: 17, token usage: 0.03, #running-req: 43, #queue-req: 412, 
0: [2025-10-29 08:11:40 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.03, #running-req: 52, #queue-req: 409, 
0: [2025-10-29 08:11:40 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.03, #running-req: 45, #queue-req: 405, 
0: [2025-10-29 08:11:40 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.03, #running-req: 45, #queue-req: 410, 
0: [2025-10-29 08:11:40 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 6, token usage: 0.03, #running-req: 36, #queue-req: 408, 
1: [2025-10-29 20:11:40 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.03, #running-req: 45, #queue-req: 405, 
1: [2025-10-29 20:11:40 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 6, token usage: 0.03, #running-req: 36, #queue-req: 408, 
1: [2025-10-29 20:11:40 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.03, #running-req: 52, #queue-req: 409, 
1: [2025-10-29 20:11:40 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.03, #running-req: 45, #queue-req: 410, 
0: [2025-10-29 08:11:40 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.03, #running-req: 36, #queue-req: 408, 
0: [2025-10-29 08:11:40 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 48, #queue-req: 405, 
0: [2025-10-29 08:11:40 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 42, #queue-req: 410, 
0: [2025-10-29 08:11:40 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.03, #running-req: 51, #queue-req: 406, 
1: [2025-10-29 20:11:40 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 48, #queue-req: 405, 
1: [2025-10-29 20:11:40 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.03, #running-req: 36, #queue-req: 408, 
1: [2025-10-29 20:11:40 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 42, #queue-req: 410, 
1: [2025-10-29 20:11:40 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.03, #running-req: 51, #queue-req: 406, 
0: [2025-10-29 08:11:40 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 54, #queue-req: 408, 
0: [2025-10-29 08:11:40 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 47, #queue-req: 410, 
0: [2025-10-29 08:11:40 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.03, #running-req: 46, #queue-req: 404, 
0: [2025-10-29 08:11:40 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.03, #running-req: 40, #queue-req: 405, 
1: [2025-10-29 20:11:40 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.03, #running-req: 40, #queue-req: 405, 
1: [2025-10-29 20:11:40 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 54, #queue-req: 408, 
1: [2025-10-29 20:11:40 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.03, #running-req: 46, #queue-req: 404, 
1: [2025-10-29 20:11:40 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 47, #queue-req: 410, 
0: [2025-10-29 08:11:40 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 48, #queue-req: 404, 
0: [2025-10-29 08:11:40 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 42, #queue-req: 410, 
0: [2025-10-29 08:11:40 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.03, #running-req: 37, #queue-req: 407, 
0: [2025-10-29 08:11:40 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.03, #running-req: 53, #queue-req: 403, 
1: [2025-10-29 20:11:40 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 48, #queue-req: 404, 
1: [2025-10-29 20:11:40 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 42, #queue-req: 410, 
1: [2025-10-29 20:11:40 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.03, #running-req: 53, #queue-req: 403, 
1: [2025-10-29 20:11:40 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.03, #running-req: 37, #queue-req: 407, 
0: [2025-10-29 08:11:40 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.03, #running-req: 54, #queue-req: 405, 
0: [2025-10-29 08:11:40 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 47, #queue-req: 410, 
0: [2025-10-29 08:11:40 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 41, #queue-req: 403, 
0: [2025-10-29 08:11:40 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 47, #queue-req: 404, 
1: [2025-10-29 20:11:40 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.03, #running-req: 54, #queue-req: 405, 
1: [2025-10-29 20:11:40 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 47, #queue-req: 404, 
1: [2025-10-29 20:11:40 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 41, #queue-req: 403, 
1: [2025-10-29 20:11:40 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 47, #queue-req: 410, 
0: [2025-10-29 08:11:40 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.03, #running-req: 48, #queue-req: 403, 
0: [2025-10-29 08:11:40 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.03, #running-req: 42, #queue-req: 408, 
0: [2025-10-29 08:11:40 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 38, #queue-req: 405, 
0: [2025-10-29 08:11:40 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.03, #running-req: 55, #queue-req: 401, 
1: [2025-10-29 20:11:40 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.03, #running-req: 48, #queue-req: 403, 
1: [2025-10-29 20:11:40 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 38, #queue-req: 405, 
1: [2025-10-29 20:11:40 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.03, #running-req: 55, #queue-req: 401, 
1: [2025-10-29 20:11:40 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.03, #running-req: 42, #queue-req: 408, 
0: [2025-10-29 08:11:40 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.03, #running-req: 47, #queue-req: 401, 
0: [2025-10-29 08:11:40 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 9, token usage: 0.03, #running-req: 47, #queue-req: 407, 
0: [2025-10-29 08:11:40 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.03, #running-req: 41, #queue-req: 399, 
0: [2025-10-29 08:11:40 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.03, #running-req: 56, #queue-req: 403, 
1: [2025-10-29 20:11:41 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.03, #running-req: 47, #queue-req: 401, 
1: [2025-10-29 20:11:41 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 9, token usage: 0.03, #running-req: 47, #queue-req: 407, 
1: [2025-10-29 20:11:41 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.03, #running-req: 41, #queue-req: 399, 
1: [2025-10-29 20:11:41 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.03, #running-req: 56, #queue-req: 403, 
0: [2025-10-29 08:11:41 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.03, #running-req: 38, #queue-req: 401, 
0: [2025-10-29 08:11:41 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 1, token usage: 0.03, #running-req: 57, #queue-req: 398, 
0: [2025-10-29 08:11:41 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 44, #queue-req: 407, 
0: [2025-10-29 08:11:41 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.03, #running-req: 49, #queue-req: 399, 
1: [2025-10-29 20:11:41 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.03, #running-req: 38, #queue-req: 401, 
1: [2025-10-29 20:11:41 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 1, token usage: 0.03, #running-req: 57, #queue-req: 398, 
1: [2025-10-29 20:11:41 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.03, #running-req: 49, #queue-req: 399, 
1: [2025-10-29 20:11:41 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 44, #queue-req: 407, 
0: [2025-10-29 08:11:41 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 44, #queue-req: 398, 
0: [2025-10-29 08:11:41 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.03, #running-req: 58, #queue-req: 399, 
0: [2025-10-29 08:11:41 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.03, #running-req: 49, #queue-req: 396, 
0: [2025-10-29 08:11:41 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.03, #running-req: 48, #queue-req: 404, 
1: [2025-10-29 20:11:41 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.03, #running-req: 44, #queue-req: 398, 
1: [2025-10-29 20:11:41 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.03, #running-req: 58, #queue-req: 399, 
1: [2025-10-29 20:11:41 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.03, #running-req: 49, #queue-req: 396, 
1: [2025-10-29 20:11:41 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.03, #running-req: 48, #queue-req: 404, 
0: [2025-10-29 08:11:41 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.03, #running-req: 44, #queue-req: 403, 
0: [2025-10-29 08:11:41 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.03, #running-req: 57, #queue-req: 396, 
0: [2025-10-29 08:11:41 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.04, #running-req: 40, #queue-req: 397, 
0: [2025-10-29 08:11:41 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.03, #running-req: 51, #queue-req: 394, 
1: [2025-10-29 20:11:41 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.03, #running-req: 44, #queue-req: 403, 
1: [2025-10-29 20:11:41 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.03, #running-req: 57, #queue-req: 396, 
1: [2025-10-29 20:11:41 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.03, #running-req: 51, #queue-req: 394, 
1: [2025-10-29 20:11:41 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.04, #running-req: 40, #queue-req: 397, 
0: [2025-10-29 08:11:41 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 10, token usage: 0.04, #running-req: 44, #queue-req: 392, 
0: [2025-10-29 08:11:41 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 60, #queue-req: 397, 
0: [2025-10-29 08:11:41 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 51, #queue-req: 403, 
0: [2025-10-29 08:11:41 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.04, #running-req: 52, #queue-req: 393, 
1: [2025-10-29 20:11:41 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 60, #queue-req: 397, 
1: [2025-10-29 20:11:41 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.04, #running-req: 52, #queue-req: 393, 
1: [2025-10-29 20:11:41 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 51, #queue-req: 403, 
1: [2025-10-29 20:11:41 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 10, token usage: 0.04, #running-req: 44, #queue-req: 392, 
0: [2025-10-29 08:11:41 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.04, #running-req: 42, #queue-req: 394, 
0: [2025-10-29 08:11:41 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 59, #queue-req: 392, 
0: [2025-10-29 08:11:41 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.04, #running-req: 53, #queue-req: 391, 
0: [2025-10-29 08:11:41 DP3 TP3 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 9, token usage: 0.04, #running-req: 45, #queue-req: 399, 
1: [2025-10-29 20:11:41 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.04, #running-req: 53, #queue-req: 391, 
1: [2025-10-29 20:11:41 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 59, #queue-req: 392, 
1: [2025-10-29 20:11:41 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.04, #running-req: 42, #queue-req: 394, 
1: [2025-10-29 20:11:41 DP3 TP3 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 9, token usage: 0.04, #running-req: 45, #queue-req: 399, 
0: [2025-10-29 08:11:41 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.04, #running-req: 60, #queue-req: 393, 
0: [2025-10-29 08:11:41 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 51, #queue-req: 399, 
0: [2025-10-29 08:11:41 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.04, #running-req: 48, #queue-req: 391, 
0: [2025-10-29 08:11:41 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.04, #running-req: 53, #queue-req: 389, 
1: [2025-10-29 20:11:41 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 51, #queue-req: 399, 
1: [2025-10-29 20:11:41 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.04, #running-req: 60, #queue-req: 393, 
1: [2025-10-29 20:11:41 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.04, #running-req: 48, #queue-req: 391, 
1: [2025-10-29 20:11:41 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.04, #running-req: 53, #queue-req: 389, 
0: [2025-10-29 08:11:41 DP1 TP1 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 12, token usage: 0.04, #running-req: 59, #queue-req: 386, 
0: [2025-10-29 08:11:41 DP0 TP0 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 12, token usage: 0.04, #running-req: 45, #queue-req: 389, 
0: [2025-10-29 08:11:41 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.04, #running-req: 49, #queue-req: 396, 
0: [2025-10-29 08:11:41 DP2 TP2 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 12, token usage: 0.04, #running-req: 55, #queue-req: 384, 
1: [2025-10-29 20:11:41 DP1 TP1 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 12, token usage: 0.04, #running-req: 59, #queue-req: 386, 
1: [2025-10-29 20:11:41 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.04, #running-req: 49, #queue-req: 396, 
1: [2025-10-29 20:11:41 DP0 TP0 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 12, token usage: 0.04, #running-req: 45, #queue-req: 389, 
1: [2025-10-29 20:11:41 DP2 TP2 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 12, token usage: 0.04, #running-req: 55, #queue-req: 384, 
0: [2025-10-29 08:11:41 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.04, #running-req: 51, #queue-req: 394, 
0: [2025-10-29 08:11:41 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 61, #queue-req: 389, 
0: [2025-10-29 08:11:41 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.04, #running-req: 55, #queue-req: 381, 
0: [2025-10-29 08:11:41 DP1 TP1 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 11, token usage: 0.04, #running-req: 49, #queue-req: 381, 
1: [2025-10-29 20:11:41 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.04, #running-req: 51, #queue-req: 394, 
1: [2025-10-29 20:11:41 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 61, #queue-req: 389, 
1: [2025-10-29 20:11:41 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.04, #running-req: 55, #queue-req: 381, 
1: [2025-10-29 20:11:41 DP1 TP1 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 11, token usage: 0.04, #running-req: 49, #queue-req: 381, 
0: [2025-10-29 08:11:41 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.04, #running-req: 49, #queue-req: 388, 
0: [2025-10-29 08:11:41 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.04, #running-req: 52, #queue-req: 393, 
0: [2025-10-29 08:11:41 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 64, #queue-req: 381, 
0: [2025-10-29 08:11:41 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.04, #running-req: 60, #queue-req: 379, 
1: [2025-10-29 20:11:41 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.04, #running-req: 60, #queue-req: 379, 
1: [2025-10-29 20:11:41 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 64, #queue-req: 381, 
1: [2025-10-29 20:11:41 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.04, #running-req: 52, #queue-req: 393, 
1: [2025-10-29 20:11:41 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.04, #running-req: 49, #queue-req: 388, 
0: [2025-10-29 08:11:41 DP0 TP0 PP0] Prefill batch. #new-seq: 10, #new-token: 512, #cached-token: 16, token usage: 0.04, #running-req: 61, #queue-req: 379, 
0: [2025-10-29 08:11:41 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 54, #queue-req: 381, 
0: [2025-10-29 08:11:41 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.04, #running-req: 53, #queue-req: 392, 
0: [2025-10-29 08:11:41 DP2 TP2 PP0] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 16, token usage: 0.04, #running-req: 58, #queue-req: 372, 
1: [2025-10-29 20:11:41 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 54, #queue-req: 381, 
1: [2025-10-29 20:11:41 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.04, #running-req: 53, #queue-req: 392, 
1: [2025-10-29 20:11:41 DP0 TP0 PP1] Prefill batch. #new-seq: 10, #new-token: 512, #cached-token: 16, token usage: 0.04, #running-req: 61, #queue-req: 379, 
1: [2025-10-29 20:11:41 DP2 TP2 PP1] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 16, token usage: 0.04, #running-req: 58, #queue-req: 372, 
0: [2025-10-29 08:11:41 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.04, #running-req: 64, #queue-req: 379, 
0: [2025-10-29 08:11:41 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.04, #running-req: 50, #queue-req: 378, 
0: [2025-10-29 08:11:41 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 53, #queue-req: 392, 
0: [2025-10-29 08:11:41 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 62, #queue-req: 372, 
1: [2025-10-29 20:11:41 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.04, #running-req: 64, #queue-req: 379, 
1: [2025-10-29 20:11:41 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.04, #running-req: 50, #queue-req: 378, 
1: [2025-10-29 20:11:41 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 62, #queue-req: 372, 
1: [2025-10-29 20:11:41 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 53, #queue-req: 392, 
0: [2025-10-29 08:11:41 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 10, token usage: 0.04, #running-req: 54, #queue-req: 375, 
0: [2025-10-29 08:11:41 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 70, #queue-req: 378, 
0: [2025-10-29 08:11:41 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.04, #running-req: 65, #queue-req: 371, 
0: [2025-10-29 08:11:41 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.04, #running-req: 54, #queue-req: 389, 
1: [2025-10-29 20:11:41 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 10, token usage: 0.04, #running-req: 54, #queue-req: 375, 
1: [2025-10-29 20:11:41 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 70, #queue-req: 378, 
1: [2025-10-29 20:11:41 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.04, #running-req: 65, #queue-req: 371, 
1: [2025-10-29 20:11:41 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.04, #running-req: 54, #queue-req: 389, 
0: [2025-10-29 08:11:41 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 53, #queue-req: 389, 
0: [2025-10-29 08:11:41 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 62, #queue-req: 371, 
0: [2025-10-29 08:11:41 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 11, token usage: 0.04, #running-req: 51, #queue-req: 375, 
0: [2025-10-29 08:11:41 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.04, #running-req: 66, #queue-req: 373, 
1: [2025-10-29 20:11:41 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 62, #queue-req: 371, 
1: [2025-10-29 20:11:41 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 53, #queue-req: 389, 
1: [2025-10-29 20:11:41 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.04, #running-req: 66, #queue-req: 373, 
1: [2025-10-29 20:11:41 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 11, token usage: 0.04, #running-req: 51, #queue-req: 375, 
0: [2025-10-29 08:11:41 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 70, #queue-req: 375, 
0: [2025-10-29 08:11:41 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 57, #queue-req: 389, 
0: [2025-10-29 08:11:41 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.04, #running-req: 66, #queue-req: 370, 
0: [2025-10-29 08:11:41 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.04, #running-req: 58, #queue-req: 370, 
1: [2025-10-29 20:11:41 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 70, #queue-req: 375, 
1: [2025-10-29 20:11:41 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.04, #running-req: 66, #queue-req: 370, 
1: [2025-10-29 20:11:41 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.04, #running-req: 58, #queue-req: 370, 
1: [2025-10-29 20:11:41 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 57, #queue-req: 389, 
0: [2025-10-29 08:11:41 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.04, #running-req: 53, #queue-req: 388, 
0: [2025-10-29 08:11:41 DP2 TP2 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 6, token usage: 0.04, #running-req: 62, #queue-req: 366, 
0: [2025-10-29 08:11:41 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.04, #running-req: 54, #queue-req: 372, 
0: [2025-10-29 08:11:41 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 7, token usage: 0.04, #running-req: 68, #queue-req: 366, 
1: [2025-10-29 20:11:41 DP2 TP2 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 6, token usage: 0.04, #running-req: 62, #queue-req: 366, 
1: [2025-10-29 20:11:41 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.04, #running-req: 53, #queue-req: 388, 
1: [2025-10-29 20:11:41 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 7, token usage: 0.04, #running-req: 68, #queue-req: 366, 
1: [2025-10-29 20:11:41 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.04, #running-req: 54, #queue-req: 372, 
0: [2025-10-29 08:11:41 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 70, #queue-req: 372, 
0: [2025-10-29 08:11:41 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.04, #running-req: 57, #queue-req: 386, 
0: [2025-10-29 08:11:41 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.04, #running-req: 61, #queue-req: 363, 
0: [2025-10-29 08:11:41 DP2 TP2 PP0] Prefill batch. #new-seq: 9, #new-token: 512, #cached-token: 16, token usage: 0.04, #running-req: 67, #queue-req: 358, 
1: [2025-10-29 20:11:41 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 70, #queue-req: 372, 
1: [2025-10-29 20:11:41 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.04, #running-req: 57, #queue-req: 386, 
1: [2025-10-29 20:11:41 DP2 TP2 PP1] Prefill batch. #new-seq: 9, #new-token: 512, #cached-token: 16, token usage: 0.04, #running-req: 67, #queue-req: 358, 
1: [2025-10-29 20:11:41 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.04, #running-req: 61, #queue-req: 363, 
0: [2025-10-29 08:11:41 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.04, #running-req: 57, #queue-req: 370, 
0: [2025-10-29 08:11:41 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 54, #queue-req: 386, 
0: [2025-10-29 08:11:41 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.04, #running-req: 66, #queue-req: 357, 
0: [2025-10-29 08:11:41 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.04, #running-req: 72, #queue-req: 362, 
1: [2025-10-29 20:11:42 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.04, #running-req: 72, #queue-req: 362, 
1: [2025-10-29 20:11:42 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 54, #queue-req: 386, 
1: [2025-10-29 20:11:42 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.04, #running-req: 57, #queue-req: 370, 
1: [2025-10-29 20:11:42 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.04, #running-req: 66, #queue-req: 357, 
0: [2025-10-29 08:11:42 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.04, #running-req: 71, #queue-req: 368, 
0: [2025-10-29 08:11:42 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 59, #queue-req: 386, 
0: [2025-10-29 08:11:42 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.04, #running-req: 64, #queue-req: 361, 
0: [2025-10-29 08:11:42 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 75, #queue-req: 357, 
1: [2025-10-29 20:11:42 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.04, #running-req: 64, #queue-req: 361, 
1: [2025-10-29 20:11:42 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 59, #queue-req: 386, 
1: [2025-10-29 20:11:42 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.04, #running-req: 71, #queue-req: 368, 
1: [2025-10-29 20:11:42 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 75, #queue-req: 357, 
0: [2025-10-29 08:11:42 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 54, #queue-req: 386, 
0: [2025-10-29 08:11:42 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.05, #running-req: 58, #queue-req: 365, 
0: [2025-10-29 08:11:42 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 73, #queue-req: 361, 
0: [2025-10-29 08:11:42 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 67, #queue-req: 357, 
1: [2025-10-29 20:11:42 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 54, #queue-req: 386, 
1: [2025-10-29 20:11:42 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 73, #queue-req: 361, 
1: [2025-10-29 20:11:42 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.04, #running-req: 67, #queue-req: 357, 
1: [2025-10-29 20:11:42 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.05, #running-req: 58, #queue-req: 365, 
0: [2025-10-29 08:11:42 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 75, #queue-req: 357, 
0: [2025-10-29 08:11:42 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 59, #queue-req: 386, 
0: [2025-10-29 08:11:42 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.05, #running-req: 65, #queue-req: 360, 
0: [2025-10-29 08:11:42 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.05, #running-req: 73, #queue-req: 363, 
1: [2025-10-29 20:11:42 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 75, #queue-req: 357, 
1: [2025-10-29 20:11:42 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 59, #queue-req: 386, 
1: [2025-10-29 20:11:42 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.05, #running-req: 73, #queue-req: 363, 
1: [2025-10-29 20:11:42 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.05, #running-req: 65, #queue-req: 360, 
0: [2025-10-29 08:11:42 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.05, #running-req: 73, #queue-req: 358, 
0: [2025-10-29 08:11:42 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 67, #queue-req: 357, 
0: [2025-10-29 08:11:42 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.05, #running-req: 61, #queue-req: 362, 
0: [2025-10-29 08:11:42 DP3 TP3 PP0] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 14, token usage: 0.05, #running-req: 54, #queue-req: 379, 
1: [2025-10-29 20:11:42 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.05, #running-req: 73, #queue-req: 358, 
1: [2025-10-29 20:11:42 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.05, #running-req: 61, #queue-req: 362, 
1: [2025-10-29 20:11:42 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 67, #queue-req: 357, 
1: [2025-10-29 20:11:42 DP3 TP3 PP1] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 14, token usage: 0.05, #running-req: 54, #queue-req: 379, 
0: [2025-10-29 08:11:42 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.05, #running-req: 59, #queue-req: 378, 
0: [2025-10-29 08:11:42 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 75, #queue-req: 357, 
0: [2025-10-29 08:11:42 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.05, #running-req: 75, #queue-req: 361, 
0: [2025-10-29 08:11:42 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 66, #queue-req: 358, 
1: [2025-10-29 20:11:42 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.05, #running-req: 75, #queue-req: 361, 
1: [2025-10-29 20:11:42 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 75, #queue-req: 357, 
1: [2025-10-29 20:11:42 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.05, #running-req: 59, #queue-req: 378, 
1: [2025-10-29 20:11:42 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 66, #queue-req: 358, 
0: [2025-10-29 08:11:42 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.05, #running-req: 67, #queue-req: 356, 
0: [2025-10-29 08:11:42 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.05, #running-req: 62, #queue-req: 360, 
0: [2025-10-29 08:11:42 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 61, #queue-req: 378, 
0: [2025-10-29 08:11:42 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 75, #queue-req: 358, 
1: [2025-10-29 20:11:42 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.05, #running-req: 62, #queue-req: 360, 
1: [2025-10-29 20:11:42 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.05, #running-req: 67, #queue-req: 356, 
1: [2025-10-29 20:11:42 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 61, #queue-req: 378, 
1: [2025-10-29 20:11:42 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 75, #queue-req: 358, 
0: [2025-10-29 08:11:42 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.05, #running-req: 75, #queue-req: 354, 
0: [2025-10-29 08:11:42 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.05, #running-req: 66, #queue-req: 356, 
0: [2025-10-29 08:11:42 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.05, #running-req: 76, #queue-req: 358, 
0: [2025-10-29 08:11:42 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.05, #running-req: 60, #queue-req: 377, 
1: [2025-10-29 20:11:42 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.05, #running-req: 75, #queue-req: 354, 
1: [2025-10-29 20:11:42 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.05, #running-req: 66, #queue-req: 356, 
1: [2025-10-29 20:11:42 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.05, #running-req: 60, #queue-req: 377, 
1: [2025-10-29 20:11:42 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.05, #running-req: 76, #queue-req: 358, 
0: [2025-10-29 08:11:42 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 75, #queue-req: 356, 
0: [2025-10-29 08:11:42 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.05, #running-req: 61, #queue-req: 374, 
0: [2025-10-29 08:11:42 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 63, #queue-req: 358, 
0: [2025-10-29 08:11:42 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.05, #running-req: 68, #queue-req: 352, 
1: [2025-10-29 20:11:42 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 75, #queue-req: 356, 
1: [2025-10-29 20:11:42 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.05, #running-req: 61, #queue-req: 374, 
1: [2025-10-29 20:11:42 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 63, #queue-req: 358, 
1: [2025-10-29 20:11:42 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.05, #running-req: 68, #queue-req: 352, 
0: [2025-10-29 08:11:42 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 78, #queue-req: 358, 
0: [2025-10-29 08:11:42 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.05, #running-req: 68, #queue-req: 355, 
0: [2025-10-29 08:11:42 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 14, token usage: 0.05, #running-req: 77, #queue-req: 351, 
0: [2025-10-29 08:11:42 DP3 TP3 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 9, token usage: 0.05, #running-req: 61, #queue-req: 370, 
1: [2025-10-29 20:11:42 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 78, #queue-req: 358, 
1: [2025-10-29 20:11:42 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 14, token usage: 0.05, #running-req: 77, #queue-req: 351, 
1: [2025-10-29 20:11:42 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.05, #running-req: 68, #queue-req: 355, 
1: [2025-10-29 20:11:42 DP3 TP3 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 9, token usage: 0.05, #running-req: 61, #queue-req: 370, 
0: [2025-10-29 08:11:42 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 63, #queue-req: 358, 
0: [2025-10-29 08:11:42 DP1 TP1 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 12, token usage: 0.05, #running-req: 75, #queue-req: 350, 
0: [2025-10-29 08:11:42 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.05, #running-req: 64, #queue-req: 368, 
0: [2025-10-29 08:11:42 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.05, #running-req: 70, #queue-req: 349, 
1: [2025-10-29 20:11:42 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 63, #queue-req: 358, 
1: [2025-10-29 20:11:42 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.05, #running-req: 70, #queue-req: 349, 
1: [2025-10-29 20:11:42 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.05, #running-req: 64, #queue-req: 368, 
1: [2025-10-29 20:11:42 DP1 TP1 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 12, token usage: 0.05, #running-req: 75, #queue-req: 350, 
0: [2025-10-29 08:11:42 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.05, #running-req: 78, #queue-req: 355, 
0: [2025-10-29 08:11:42 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.05, #running-req: 78, #queue-req: 348, 
0: [2025-10-29 08:11:42 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 69, #queue-req: 350, 
0: [2025-10-29 08:11:42 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.05, #running-req: 65, #queue-req: 365, 
1: [2025-10-29 20:11:42 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.05, #running-req: 78, #queue-req: 348, 
1: [2025-10-29 20:11:42 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 69, #queue-req: 350, 
1: [2025-10-29 20:11:42 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.05, #running-req: 78, #queue-req: 355, 
1: [2025-10-29 20:11:42 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.05, #running-req: 65, #queue-req: 365, 
0: [2025-10-29 08:11:42 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 10, token usage: 0.05, #running-req: 63, #queue-req: 352, 
0: [2025-10-29 08:11:42 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 72, #queue-req: 348, 
0: [2025-10-29 08:11:42 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.05, #running-req: 66, #queue-req: 364, 
0: [2025-10-29 08:11:42 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.05, #running-req: 80, #queue-req: 349, 
1: [2025-10-29 20:11:42 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 10, token usage: 0.05, #running-req: 63, #queue-req: 352, 
1: [2025-10-29 20:11:42 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 72, #queue-req: 348, 
1: [2025-10-29 20:11:42 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.05, #running-req: 66, #queue-req: 364, 
1: [2025-10-29 20:11:42 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.05, #running-req: 80, #queue-req: 349, 
0: [2025-10-29 08:11:42 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 10, token usage: 0.05, #running-req: 82, #queue-req: 349, 
0: [2025-10-29 08:11:42 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.05, #running-req: 69, #queue-req: 348, 
0: [2025-10-29 08:11:42 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.05, #running-req: 79, #queue-req: 347, 
0: [2025-10-29 08:11:42 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.05, #running-req: 68, #queue-req: 362, 
1: [2025-10-29 20:11:42 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.05, #running-req: 69, #queue-req: 348, 
1: [2025-10-29 20:11:42 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 10, token usage: 0.05, #running-req: 82, #queue-req: 349, 
1: [2025-10-29 20:11:42 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.05, #running-req: 79, #queue-req: 347, 
1: [2025-10-29 20:11:42 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.05, #running-req: 68, #queue-req: 362, 
0: [2025-10-29 08:11:42 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.05, #running-req: 72, #queue-req: 346, 
0: [2025-10-29 08:11:42 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.05, #running-req: 66, #queue-req: 347, 
0: [2025-10-29 08:11:42 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 67, #queue-req: 362, 
0: [2025-10-29 08:11:42 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.05, #running-req: 81, #queue-req: 347, 
1: [2025-10-29 20:11:42 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.05, #running-req: 72, #queue-req: 346, 
1: [2025-10-29 20:11:42 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.05, #running-req: 66, #queue-req: 347, 
1: [2025-10-29 20:11:42 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.05, #running-req: 81, #queue-req: 347, 
1: [2025-10-29 20:11:42 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 67, #queue-req: 362, 
0: [2025-10-29 08:11:42 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.05, #running-req: 84, #queue-req: 345, 
0: [2025-10-29 08:11:42 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.05, #running-req: 80, #queue-req: 345, 
0: [2025-10-29 08:11:42 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.05, #running-req: 70, #queue-req: 345, 
0: [2025-10-29 08:11:42 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.05, #running-req: 70, #queue-req: 359, 
1: [2025-10-29 20:11:42 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.05, #running-req: 70, #queue-req: 345, 
1: [2025-10-29 20:11:42 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.05, #running-req: 80, #queue-req: 345, 
1: [2025-10-29 20:11:42 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.05, #running-req: 84, #queue-req: 345, 
1: [2025-10-29 20:11:42 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.05, #running-req: 70, #queue-req: 359, 
0: [2025-10-29 08:11:42 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 67, #queue-req: 359, 
0: [2025-10-29 08:11:42 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.05, #running-req: 68, #queue-req: 343, 
0: [2025-10-29 08:11:43 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.05, #running-req: 73, #queue-req: 344, 
0: [2025-10-29 08:11:43 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.05, #running-req: 82, #queue-req: 342, 
1: [2025-10-29 20:11:43 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 67, #queue-req: 359, 
1: [2025-10-29 20:11:43 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.05, #running-req: 68, #queue-req: 343, 
1: [2025-10-29 20:11:43 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.05, #running-req: 73, #queue-req: 344, 
1: [2025-10-29 20:11:43 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.05, #running-req: 82, #queue-req: 342, 
0: [2025-10-29 08:11:43 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 81, #queue-req: 344, 
0: [2025-10-29 08:11:43 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.05, #running-req: 86, #queue-req: 341, 
0: [2025-10-29 08:11:43 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.05, #running-req: 72, #queue-req: 341, 
0: [2025-10-29 08:11:43 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.05, #running-req: 73, #queue-req: 356, 
1: [2025-10-29 20:11:43 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.05, #running-req: 72, #queue-req: 341, 
1: [2025-10-29 20:11:43 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 81, #queue-req: 344, 
1: [2025-10-29 20:11:43 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.05, #running-req: 86, #queue-req: 341, 
1: [2025-10-29 20:11:43 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.05, #running-req: 73, #queue-req: 356, 
0: [2025-10-29 08:11:43 DP3 TP3 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 12, token usage: 0.05, #running-req: 67, #queue-req: 351, 
0: [2025-10-29 08:11:43 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 70, #queue-req: 341, 
0: [2025-10-29 08:11:43 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 12, token usage: 0.05, #running-req: 85, #queue-req: 339, 
0: [2025-10-29 08:11:43 DP2 TP2 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 10, token usage: 0.05, #running-req: 74, #queue-req: 340, 
1: [2025-10-29 20:11:43 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 70, #queue-req: 341, 
1: [2025-10-29 20:11:43 DP3 TP3 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 12, token usage: 0.05, #running-req: 67, #queue-req: 351, 
1: [2025-10-29 20:11:43 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 12, token usage: 0.05, #running-req: 85, #queue-req: 339, 
1: [2025-10-29 20:11:43 DP2 TP2 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 10, token usage: 0.05, #running-req: 74, #queue-req: 340, 
0: [2025-10-29 08:11:43 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.05, #running-req: 81, #queue-req: 339, 
0: [2025-10-29 08:11:43 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 73, #queue-req: 339, 
0: [2025-10-29 08:11:43 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.06, #running-req: 88, #queue-req: 338, 
0: [2025-10-29 08:11:43 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.05, #running-req: 76, #queue-req: 350, 
1: [2025-10-29 20:11:43 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.05, #running-req: 81, #queue-req: 339, 
1: [2025-10-29 20:11:43 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.06, #running-req: 88, #queue-req: 338, 
1: [2025-10-29 20:11:43 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.05, #running-req: 73, #queue-req: 339, 
1: [2025-10-29 20:11:43 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.05, #running-req: 76, #queue-req: 350, 
0: [2025-10-29 08:11:43 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 70, #queue-req: 338, 
0: [2025-10-29 08:11:43 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.06, #running-req: 72, #queue-req: 348, 
0: [2025-10-29 08:11:43 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.06, #running-req: 87, #queue-req: 337, 
0: [2025-10-29 08:11:43 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.06, #running-req: 78, #queue-req: 336, 
1: [2025-10-29 20:11:43 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 70, #queue-req: 338, 
1: [2025-10-29 20:11:43 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.06, #running-req: 78, #queue-req: 336, 
1: [2025-10-29 20:11:43 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.06, #running-req: 72, #queue-req: 348, 
1: [2025-10-29 20:11:43 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.06, #running-req: 87, #queue-req: 337, 
0: [2025-10-29 08:11:43 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.06, #running-req: 73, #queue-req: 335, 
0: [2025-10-29 08:11:43 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.06, #running-req: 91, #queue-req: 335, 
0: [2025-10-29 08:11:43 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.06, #running-req: 82, #queue-req: 335, 
0: [2025-10-29 08:11:43 DP3 TP3 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 12, token usage: 0.06, #running-req: 77, #queue-req: 344, 
1: [2025-10-29 20:11:43 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.06, #running-req: 73, #queue-req: 335, 
1: [2025-10-29 20:11:43 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.06, #running-req: 82, #queue-req: 335, 
1: [2025-10-29 20:11:43 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.06, #running-req: 91, #queue-req: 335, 
1: [2025-10-29 20:11:43 DP3 TP3 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 12, token usage: 0.06, #running-req: 77, #queue-req: 344, 
0: [2025-10-29 08:11:43 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.06, #running-req: 70, #queue-req: 332, 
0: [2025-10-29 08:11:43 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 74, #queue-req: 344, 
0: [2025-10-29 08:11:43 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 12, token usage: 0.06, #running-req: 89, #queue-req: 332, 
0: [2025-10-29 08:11:43 DP2 TP2 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 6, token usage: 0.06, #running-req: 81, #queue-req: 330, 
1: [2025-10-29 20:11:43 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.06, #running-req: 70, #queue-req: 332, 
1: [2025-10-29 20:11:43 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 74, #queue-req: 344, 
1: [2025-10-29 20:11:43 DP2 TP2 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 6, token usage: 0.06, #running-req: 81, #queue-req: 330, 
1: [2025-10-29 20:11:43 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 12, token usage: 0.06, #running-req: 89, #queue-req: 332, 
0: [2025-10-29 08:11:43 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.06, #running-req: 94, #queue-req: 329, 
0: [2025-10-29 08:11:43 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.06, #running-req: 81, #queue-req: 342, 
0: [2025-10-29 08:11:43 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.06, #running-req: 75, #queue-req: 329, 
0: [2025-10-29 08:11:43 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.06, #running-req: 83, #queue-req: 329, 
1: [2025-10-29 20:11:43 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.06, #running-req: 83, #queue-req: 329, 
1: [2025-10-29 20:11:43 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.06, #running-req: 75, #queue-req: 329, 
1: [2025-10-29 20:11:43 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.06, #running-req: 94, #queue-req: 329, 
1: [2025-10-29 20:11:43 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.06, #running-req: 81, #queue-req: 342, 
0: [2025-10-29 08:11:43 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 74, #queue-req: 342, 
0: [2025-10-29 08:11:43 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.06, #running-req: 73, #queue-req: 327, 
0: [2025-10-29 08:11:43 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.06, #running-req: 86, #queue-req: 327, 
0: [2025-10-29 08:11:43 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.06, #running-req: 92, #queue-req: 326, 
1: [2025-10-29 20:11:43 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 74, #queue-req: 342, 
1: [2025-10-29 20:11:43 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.06, #running-req: 73, #queue-req: 327, 
1: [2025-10-29 20:11:43 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.06, #running-req: 86, #queue-req: 327, 
1: [2025-10-29 20:11:43 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.06, #running-req: 92, #queue-req: 326, 
0: [2025-10-29 08:11:43 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.06, #running-req: 97, #queue-req: 325, 
0: [2025-10-29 08:11:43 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.06, #running-req: 78, #queue-req: 325, 
0: [2025-10-29 08:11:43 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.06, #running-req: 84, #queue-req: 325, 
0: [2025-10-29 08:11:43 DP3 TP3 PP0] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 15, token usage: 0.06, #running-req: 83, #queue-req: 336, 
1: [2025-10-29 20:11:43 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.06, #running-req: 78, #queue-req: 325, 
1: [2025-10-29 20:11:43 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.06, #running-req: 84, #queue-req: 325, 
1: [2025-10-29 20:11:43 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.06, #running-req: 97, #queue-req: 325, 
1: [2025-10-29 20:11:43 DP3 TP3 PP1] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 15, token usage: 0.06, #running-req: 83, #queue-req: 336, 
0: [2025-10-29 08:11:43 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.06, #running-req: 74, #queue-req: 335, 
0: [2025-10-29 08:11:43 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.06, #running-req: 75, #queue-req: 324, 
0: [2025-10-29 08:11:43 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 95, #queue-req: 325, 
0: [2025-10-29 08:11:43 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.06, #running-req: 88, #queue-req: 323, 
1: [2025-10-29 20:11:43 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.06, #running-req: 74, #queue-req: 335, 
1: [2025-10-29 20:11:43 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.06, #running-req: 75, #queue-req: 324, 
1: [2025-10-29 20:11:43 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.06, #running-req: 88, #queue-req: 323, 
1: [2025-10-29 20:11:43 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 95, #queue-req: 325, 
0: [2025-10-29 08:11:43 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.06, #running-req: 99, #queue-req: 323, 
0: [2025-10-29 08:11:43 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 86, #queue-req: 323, 
0: [2025-10-29 08:11:43 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 11, token usage: 0.06, #running-req: 89, #queue-req: 333, 
0: [2025-10-29 08:11:43 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.06, #running-req: 79, #queue-req: 322, 
1: [2025-10-29 20:11:43 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 86, #queue-req: 323, 
1: [2025-10-29 20:11:43 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.06, #running-req: 99, #queue-req: 323, 
1: [2025-10-29 20:11:43 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 11, token usage: 0.06, #running-req: 89, #queue-req: 333, 
1: [2025-10-29 20:11:43 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.06, #running-req: 79, #queue-req: 322, 
0: [2025-10-29 08:11:43 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 95, #queue-req: 322, 
0: [2025-10-29 08:11:43 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.06, #running-req: 75, #queue-req: 331, 
0: [2025-10-29 08:11:43 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.06, #running-req: 90, #queue-req: 321, 
0: [2025-10-29 08:11:43 DP0 TP0 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 14, token usage: 0.06, #running-req: 76, #queue-req: 318, 
1: [2025-10-29 20:11:43 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 95, #queue-req: 322, 
1: [2025-10-29 20:11:43 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.06, #running-req: 90, #queue-req: 321, 
1: [2025-10-29 20:11:43 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.06, #running-req: 75, #queue-req: 331, 
1: [2025-10-29 20:11:43 DP0 TP0 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 14, token usage: 0.06, #running-req: 76, #queue-req: 318, 
0: [2025-10-29 08:11:43 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.06, #running-req: 86, #queue-req: 320, 
0: [2025-10-29 08:11:43 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 100, #queue-req: 318, 
0: [2025-10-29 08:11:43 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.06, #running-req: 91, #queue-req: 330, 
0: [2025-10-29 08:11:43 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.06, #running-req: 82, #queue-req: 320, 
1: [2025-10-29 20:11:43 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.06, #running-req: 86, #queue-req: 320, 
1: [2025-10-29 20:11:43 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 100, #queue-req: 318, 
1: [2025-10-29 20:11:43 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.06, #running-req: 91, #queue-req: 330, 
1: [2025-10-29 20:11:43 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.06, #running-req: 82, #queue-req: 320, 
0: [2025-10-29 08:11:43 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.06, #running-req: 95, #queue-req: 318, 
0: [2025-10-29 08:11:43 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.06, #running-req: 81, #queue-req: 316, 
0: [2025-10-29 08:11:43 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.06, #running-req: 77, #queue-req: 327, 
0: [2025-10-29 08:11:43 DP2 TP2 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 9, token usage: 0.06, #running-req: 92, #queue-req: 315, 
1: [2025-10-29 20:11:43 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.06, #running-req: 95, #queue-req: 318, 
1: [2025-10-29 20:11:43 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.06, #running-req: 77, #queue-req: 327, 
1: [2025-10-29 20:11:43 DP2 TP2 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 9, token usage: 0.06, #running-req: 92, #queue-req: 315, 
1: [2025-10-29 20:11:43 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.06, #running-req: 81, #queue-req: 316, 
0: [2025-10-29 08:11:43 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 100, #queue-req: 316, 
0: [2025-10-29 08:11:43 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.06, #running-req: 84, #queue-req: 317, 
0: [2025-10-29 08:11:43 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 92, #queue-req: 327, 
0: [2025-10-29 08:11:43 DP2 TP2 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 14, token usage: 0.06, #running-req: 87, #queue-req: 310, 
1: [2025-10-29 20:11:43 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 100, #queue-req: 316, 
1: [2025-10-29 20:11:43 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.06, #running-req: 84, #queue-req: 317, 
1: [2025-10-29 20:11:43 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 92, #queue-req: 327, 
1: [2025-10-29 20:11:43 DP2 TP2 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 14, token usage: 0.06, #running-req: 87, #queue-req: 310, 
0: [2025-10-29 08:11:43 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 83, #queue-req: 316, 
0: [2025-10-29 08:11:43 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.06, #running-req: 97, #queue-req: 314, 
0: [2025-10-29 08:11:43 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 97, #queue-req: 310, 
0: [2025-10-29 08:11:43 DP3 TP3 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 7, token usage: 0.06, #running-req: 80, #queue-req: 322, 
1: [2025-10-29 20:11:44 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.06, #running-req: 97, #queue-req: 314, 
1: [2025-10-29 20:11:44 DP3 TP3 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 7, token usage: 0.06, #running-req: 80, #queue-req: 322, 
1: [2025-10-29 20:11:44 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 97, #queue-req: 310, 
1: [2025-10-29 20:11:44 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 83, #queue-req: 316, 
0: [2025-10-29 08:11:44 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.06, #running-req: 92, #queue-req: 321, 
0: [2025-10-29 08:11:44 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 100, #queue-req: 316, 
0: [2025-10-29 08:11:44 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.06, #running-req: 92, #queue-req: 307, 
0: [2025-10-29 08:11:44 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.06, #running-req: 85, #queue-req: 312, 
1: [2025-10-29 20:11:44 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.06, #running-req: 92, #queue-req: 321, 
1: [2025-10-29 20:11:44 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 100, #queue-req: 316, 
1: [2025-10-29 20:11:44 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.06, #running-req: 92, #queue-req: 307, 
1: [2025-10-29 20:11:44 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.06, #running-req: 85, #queue-req: 312, 
0: [2025-10-29 08:11:44 DP2 TP2 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 10, token usage: 0.06, #running-req: 97, #queue-req: 302, 
0: [2025-10-29 08:11:44 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 83, #queue-req: 316, 
0: [2025-10-29 08:11:44 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.06, #running-req: 85, #queue-req: 320, 
0: [2025-10-29 08:11:44 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 100, #queue-req: 312, 
1: [2025-10-29 20:11:44 DP2 TP2 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 10, token usage: 0.06, #running-req: 97, #queue-req: 302, 
1: [2025-10-29 20:11:44 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 83, #queue-req: 316, 
1: [2025-10-29 20:11:44 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.06, #running-req: 100, #queue-req: 312, 
1: [2025-10-29 20:11:44 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.06, #running-req: 85, #queue-req: 320, 
0: [2025-10-29 08:11:44 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 100, #queue-req: 316, 
0: [2025-10-29 08:11:44 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.06, #running-req: 93, #queue-req: 319, 
0: [2025-10-29 08:11:44 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.06, #running-req: 95, #queue-req: 300, 
0: [2025-10-29 08:11:44 DP1 TP1 PP0] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 8, token usage: 0.06, #running-req: 87, #queue-req: 306, 
1: [2025-10-29 20:11:44 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.06, #running-req: 93, #queue-req: 319, 
1: [2025-10-29 20:11:44 DP1 TP1 PP1] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 8, token usage: 0.06, #running-req: 87, #queue-req: 306, 
1: [2025-10-29 20:11:44 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.06, #running-req: 95, #queue-req: 300, 
1: [2025-10-29 20:11:44 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 100, #queue-req: 316, 
0: [2025-10-29 08:11:44 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 100, #queue-req: 306, 
0: [2025-10-29 08:11:44 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 83, #queue-req: 316, 
0: [2025-10-29 08:11:44 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.07, #running-req: 86, #queue-req: 316, 
0: [2025-10-29 08:11:44 DP2 TP2 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 14, token usage: 0.07, #running-req: 102, #queue-req: 296, 
1: [2025-10-29 20:11:44 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 100, #queue-req: 306, 
1: [2025-10-29 20:11:44 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.07, #running-req: 86, #queue-req: 316, 
1: [2025-10-29 20:11:44 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 83, #queue-req: 316, 
1: [2025-10-29 20:11:44 DP2 TP2 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 14, token usage: 0.07, #running-req: 102, #queue-req: 296, 
0: [2025-10-29 08:11:44 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 100, #queue-req: 316, 
0: [2025-10-29 08:11:44 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 97, #queue-req: 296, 
0: [2025-10-29 08:11:44 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.07, #running-req: 93, #queue-req: 304, 
0: [2025-10-29 08:11:44 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.07, #running-req: 94, #queue-req: 313, 
1: [2025-10-29 20:11:44 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 97, #queue-req: 296, 
1: [2025-10-29 20:11:44 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.07, #running-req: 93, #queue-req: 304, 
1: [2025-10-29 20:11:44 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.07, #running-req: 94, #queue-req: 313, 
1: [2025-10-29 20:11:44 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 100, #queue-req: 316, 
0: [2025-10-29 08:11:44 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.07, #running-req: 100, #queue-req: 302, 
0: [2025-10-29 08:11:44 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 83, #queue-req: 316, 
0: [2025-10-29 08:11:44 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 106, #queue-req: 296, 
0: [2025-10-29 08:11:44 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 89, #queue-req: 313, 
1: [2025-10-29 20:11:44 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 106, #queue-req: 296, 
1: [2025-10-29 20:11:44 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.07, #running-req: 100, #queue-req: 302, 
1: [2025-10-29 20:11:44 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 89, #queue-req: 313, 
1: [2025-10-29 20:11:44 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 83, #queue-req: 316, 
0: [2025-10-29 08:11:44 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 11, token usage: 0.07, #running-req: 97, #queue-req: 294, 
0: [2025-10-29 08:11:44 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 95, #queue-req: 302, 
0: [2025-10-29 08:11:44 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 100, #queue-req: 316, 
0: [2025-10-29 08:11:44 DP3 TP3 PP0] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 18, token usage: 0.07, #running-req: 97, #queue-req: 306, 
1: [2025-10-29 20:11:44 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 11, token usage: 0.07, #running-req: 97, #queue-req: 294, 
1: [2025-10-29 20:11:44 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 95, #queue-req: 302, 
1: [2025-10-29 20:11:44 DP3 TP3 PP1] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 18, token usage: 0.07, #running-req: 97, #queue-req: 306, 
1: [2025-10-29 20:11:44 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 100, #queue-req: 316, 
0: [2025-10-29 08:11:44 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 89, #queue-req: 306, 
0: [2025-10-29 08:11:44 DP2 TP2 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 7, token usage: 0.07, #running-req: 106, #queue-req: 290, 
0: [2025-10-29 08:11:44 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 102, #queue-req: 302, 
0: [2025-10-29 08:11:44 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 83, #queue-req: 316, 
1: [2025-10-29 20:11:44 DP2 TP2 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 7, token usage: 0.07, #running-req: 106, #queue-req: 290, 
1: [2025-10-29 20:11:44 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 89, #queue-req: 306, 
1: [2025-10-29 20:11:44 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 102, #queue-req: 302, 
1: [2025-10-29 20:11:44 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 83, #queue-req: 316, 
0: [2025-10-29 08:11:44 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 95, #queue-req: 302, 
0: [2025-10-29 08:11:44 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 104, #queue-req: 306, 
0: [2025-10-29 08:11:44 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 99, #queue-req: 290, 
0: [2025-10-29 08:11:44 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 100, #queue-req: 316, 
1: [2025-10-29 20:11:44 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 95, #queue-req: 302, 
1: [2025-10-29 20:11:44 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 99, #queue-req: 290, 
1: [2025-10-29 20:11:44 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 104, #queue-req: 306, 
1: [2025-10-29 20:11:44 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 100, #queue-req: 316, 
0: [2025-10-29 08:11:44 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 89, #queue-req: 306, 
0: [2025-10-29 08:11:44 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.07, #running-req: 102, #queue-req: 301, 
0: [2025-10-29 08:11:44 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 110, #queue-req: 290, 
0: [2025-10-29 08:11:44 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 83, #queue-req: 316, 
1: [2025-10-29 20:11:44 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 89, #queue-req: 306, 
1: [2025-10-29 20:11:44 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.07, #running-req: 102, #queue-req: 301, 
1: [2025-10-29 20:11:44 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 110, #queue-req: 290, 
1: [2025-10-29 20:11:44 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 83, #queue-req: 316, 
0: [2025-10-29 08:11:44 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 95, #queue-req: 301, 
0: [2025-10-29 08:11:44 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 99, #queue-req: 290, 
0: [2025-10-29 08:11:44 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 3, token usage: 0.07, #running-req: 104, #queue-req: 303, 
0: [2025-10-29 08:11:44 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.07, #running-req: 100, #queue-req: 314, 
1: [2025-10-29 20:11:44 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 99, #queue-req: 290, 
1: [2025-10-29 20:11:44 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 95, #queue-req: 301, 
1: [2025-10-29 20:11:44 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 3, token usage: 0.07, #running-req: 104, #queue-req: 303, 
1: [2025-10-29 20:11:44 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.07, #running-req: 100, #queue-req: 314, 
0: [2025-10-29 08:11:44 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.07, #running-req: 83, #queue-req: 313, 
0: [2025-10-29 08:11:44 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 110, #queue-req: 290, 
0: [2025-10-29 08:11:44 DP3 TP3 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 16, token usage: 0.07, #running-req: 89, #queue-req: 298, 
0: [2025-10-29 08:11:44 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.07, #running-req: 103, #queue-req: 300, 
1: [2025-10-29 20:11:44 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.07, #running-req: 83, #queue-req: 313, 
1: [2025-10-29 20:11:44 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 110, #queue-req: 290, 
1: [2025-10-29 20:11:44 DP3 TP3 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 16, token usage: 0.07, #running-req: 89, #queue-req: 298, 
1: [2025-10-29 20:11:44 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.07, #running-req: 103, #queue-req: 300, 
0: [2025-10-29 08:11:44 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.07, #running-req: 95, #queue-req: 299, 
0: [2025-10-29 08:11:44 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 14, token usage: 0.07, #running-req: 99, #queue-req: 287, 
0: [2025-10-29 08:11:44 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 102, #queue-req: 313, 
0: [2025-10-29 08:11:44 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 107, #queue-req: 298, 
1: [2025-10-29 20:11:44 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.07, #running-req: 95, #queue-req: 299, 
1: [2025-10-29 20:11:44 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 107, #queue-req: 298, 
1: [2025-10-29 20:11:44 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 102, #queue-req: 313, 
1: [2025-10-29 20:11:44 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 14, token usage: 0.07, #running-req: 99, #queue-req: 287, 
0: [2025-10-29 08:11:44 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.07, #running-req: 110, #queue-req: 286, 
0: [2025-10-29 08:11:44 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 84, #queue-req: 313, 
0: [2025-10-29 08:11:44 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.07, #running-req: 94, #queue-req: 297, 
0: [2025-10-29 08:11:44 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.07, #running-req: 104, #queue-req: 297, 
1: [2025-10-29 20:11:45 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.07, #running-req: 110, #queue-req: 286, 
1: [2025-10-29 20:11:45 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.07, #running-req: 104, #queue-req: 297, 
1: [2025-10-29 20:11:45 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.07, #running-req: 94, #queue-req: 297, 
1: [2025-10-29 20:11:45 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 84, #queue-req: 313, 
0: [2025-10-29 08:11:45 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 102, #queue-req: 313, 
0: [2025-10-29 08:11:45 DP3 TP3 PP0] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 11, token usage: 0.07, #running-req: 107, #queue-req: 291, 
0: [2025-10-29 08:11:45 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.07, #running-req: 102, #queue-req: 284, 
0: [2025-10-29 08:11:45 DP1 TP1 PP0] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 12, token usage: 0.07, #running-req: 96, #queue-req: 290, 
1: [2025-10-29 20:11:45 DP3 TP3 PP1] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 11, token usage: 0.07, #running-req: 107, #queue-req: 291, 
1: [2025-10-29 20:11:45 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 102, #queue-req: 313, 
1: [2025-10-29 20:11:45 DP1 TP1 PP1] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 12, token usage: 0.07, #running-req: 96, #queue-req: 290, 
1: [2025-10-29 20:11:45 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.07, #running-req: 102, #queue-req: 284, 
0: [2025-10-29 08:11:45 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.07, #running-req: 84, #queue-req: 312, 
0: [2025-10-29 08:11:45 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.07, #running-req: 106, #queue-req: 288, 
0: [2025-10-29 08:11:45 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.07, #running-req: 95, #queue-req: 289, 
0: [2025-10-29 08:11:45 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.07, #running-req: 111, #queue-req: 283, 
1: [2025-10-29 20:11:45 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.07, #running-req: 111, #queue-req: 283, 
1: [2025-10-29 20:11:45 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.07, #running-req: 84, #queue-req: 312, 
1: [2025-10-29 20:11:45 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.07, #running-req: 106, #queue-req: 288, 
1: [2025-10-29 20:11:45 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.07, #running-req: 95, #queue-req: 289, 
0: [2025-10-29 08:11:45 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.07, #running-req: 102, #queue-req: 311, 
0: [2025-10-29 08:11:45 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 103, #queue-req: 288, 
0: [2025-10-29 08:11:45 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.07, #running-req: 113, #queue-req: 287, 
0: [2025-10-29 08:11:45 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.07, #running-req: 104, #queue-req: 280, 
1: [2025-10-29 20:11:45 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.07, #running-req: 104, #queue-req: 280, 
1: [2025-10-29 20:11:45 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.07, #running-req: 102, #queue-req: 311, 
1: [2025-10-29 20:11:45 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 103, #queue-req: 288, 
1: [2025-10-29 20:11:45 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.07, #running-req: 113, #queue-req: 287, 
0: [2025-10-29 08:11:45 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.07, #running-req: 85, #queue-req: 310, 
0: [2025-10-29 08:11:45 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.07, #running-req: 112, #queue-req: 279, 
0: [2025-10-29 08:11:45 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.07, #running-req: 108, #queue-req: 286, 
0: [2025-10-29 08:11:45 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.07, #running-req: 97, #queue-req: 284, 
1: [2025-10-29 20:11:45 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.07, #running-req: 112, #queue-req: 279, 
1: [2025-10-29 20:11:45 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.07, #running-req: 85, #queue-req: 310, 
1: [2025-10-29 20:11:45 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.07, #running-req: 108, #queue-req: 286, 
1: [2025-10-29 20:11:45 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.07, #running-req: 97, #queue-req: 284, 
0: [2025-10-29 08:11:45 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.07, #running-req: 103, #queue-req: 283, 
0: [2025-10-29 08:11:45 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 103, #queue-req: 310, 
0: [2025-10-29 08:11:45 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 107, #queue-req: 279, 
0: [2025-10-29 08:11:45 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.07, #running-req: 115, #queue-req: 282, 
1: [2025-10-29 20:11:45 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.07, #running-req: 103, #queue-req: 283, 
1: [2025-10-29 20:11:45 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 107, #queue-req: 279, 
1: [2025-10-29 20:11:45 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.07, #running-req: 103, #queue-req: 310, 
1: [2025-10-29 20:11:45 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.07, #running-req: 115, #queue-req: 282, 
0: [2025-10-29 08:11:45 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 86, #queue-req: 310, 
0: [2025-10-29 08:11:45 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.07, #running-req: 110, #queue-req: 282, 
0: [2025-10-29 08:11:45 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.07, #running-req: 100, #queue-req: 281, 
0: [2025-10-29 08:11:45 DP2 TP2 PP0] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 10, token usage: 0.07, #running-req: 113, #queue-req: 273, 
1: [2025-10-29 20:11:45 DP2 TP2 PP1] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 10, token usage: 0.07, #running-req: 113, #queue-req: 273, 
1: [2025-10-29 20:11:45 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.07, #running-req: 100, #queue-req: 281, 
1: [2025-10-29 20:11:45 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.07, #running-req: 110, #queue-req: 282, 
1: [2025-10-29 20:11:45 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 86, #queue-req: 310, 
0: [2025-10-29 08:11:45 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 103, #queue-req: 310, 
0: [2025-10-29 08:11:45 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.08, #running-req: 107, #queue-req: 270, 
0: [2025-10-29 08:11:45 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.08, #running-req: 117, #queue-req: 280, 
0: [2025-10-29 08:11:45 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.08, #running-req: 106, #queue-req: 279, 
1: [2025-10-29 20:11:45 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 103, #queue-req: 310, 
1: [2025-10-29 20:11:45 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.08, #running-req: 107, #queue-req: 270, 
1: [2025-10-29 20:11:45 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.08, #running-req: 117, #queue-req: 280, 
1: [2025-10-29 20:11:45 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.08, #running-req: 106, #queue-req: 279, 
0: [2025-10-29 08:11:45 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.08, #running-req: 86, #queue-req: 307, 
0: [2025-10-29 08:11:45 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.08, #running-req: 101, #queue-req: 278, 
0: [2025-10-29 08:11:45 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.08, #running-req: 111, #queue-req: 278, 
0: [2025-10-29 08:11:45 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.08, #running-req: 119, #queue-req: 268, 
1: [2025-10-29 20:11:45 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.08, #running-req: 111, #queue-req: 278, 
1: [2025-10-29 20:11:45 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.08, #running-req: 101, #queue-req: 278, 
1: [2025-10-29 20:11:45 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.08, #running-req: 86, #queue-req: 307, 
1: [2025-10-29 20:11:45 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.08, #running-req: 119, #queue-req: 268, 
0: [2025-10-29 08:11:45 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.08, #running-req: 103, #queue-req: 305, 
0: [2025-10-29 08:11:45 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 118, #queue-req: 278, 
0: [2025-10-29 08:11:45 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 110, #queue-req: 268, 
0: [2025-10-29 08:11:45 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.08, #running-req: 109, #queue-req: 277, 
1: [2025-10-29 20:11:45 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 118, #queue-req: 278, 
1: [2025-10-29 20:11:45 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.08, #running-req: 109, #queue-req: 277, 
1: [2025-10-29 20:11:45 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.08, #running-req: 103, #queue-req: 305, 
1: [2025-10-29 20:11:45 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 110, #queue-req: 268, 
0: [2025-10-29 08:11:45 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 89, #queue-req: 305, 
0: [2025-10-29 08:11:45 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.08, #running-req: 103, #queue-req: 277, 
0: [2025-10-29 08:11:45 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 112, #queue-req: 276, 
0: [2025-10-29 08:11:45 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 121, #queue-req: 268, 
1: [2025-10-29 20:11:45 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 89, #queue-req: 305, 
1: [2025-10-29 20:11:45 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 112, #queue-req: 276, 
1: [2025-10-29 20:11:45 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 121, #queue-req: 268, 
1: [2025-10-29 20:11:45 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.08, #running-req: 103, #queue-req: 277, 
0: [2025-10-29 08:11:45 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.08, #running-req: 118, #queue-req: 275, 
0: [2025-10-29 08:11:45 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.08, #running-req: 110, #queue-req: 266, 
0: [2025-10-29 08:11:45 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.08, #running-req: 105, #queue-req: 302, 
0: [2025-10-29 08:11:45 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 382, token usage: 0.08, #running-req: 110, #queue-req: 272, 
1: [2025-10-29 20:11:45 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.08, #running-req: 110, #queue-req: 266, 
1: [2025-10-29 20:11:45 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.08, #running-req: 118, #queue-req: 275, 
1: [2025-10-29 20:11:45 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.08, #running-req: 105, #queue-req: 302, 
1: [2025-10-29 20:11:45 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 382, token usage: 0.08, #running-req: 110, #queue-req: 272, 
0: [2025-10-29 08:11:45 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 89, #queue-req: 301, 
0: [2025-10-29 08:11:45 DP2 TP2 PP0] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 13, token usage: 0.08, #running-req: 121, #queue-req: 260, 
0: [2025-10-29 08:11:45 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 113, #queue-req: 272, 
0: [2025-10-29 08:11:45 DP3 TP3 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 13, token usage: 0.08, #running-req: 104, #queue-req: 271, 
1: [2025-10-29 20:11:45 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 89, #queue-req: 301, 
1: [2025-10-29 20:11:45 DP2 TP2 PP1] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 13, token usage: 0.08, #running-req: 121, #queue-req: 260, 
1: [2025-10-29 20:11:45 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 113, #queue-req: 272, 
1: [2025-10-29 20:11:45 DP3 TP3 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 13, token usage: 0.08, #running-req: 104, #queue-req: 271, 
0: [2025-10-29 08:11:45 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 108, #queue-req: 301, 
0: [2025-10-29 08:11:45 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.08, #running-req: 114, #queue-req: 271, 
0: [2025-10-29 08:11:45 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.08, #running-req: 112, #queue-req: 258, 
0: [2025-10-29 08:11:45 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.08, #running-req: 120, #queue-req: 268, 
1: [2025-10-29 20:11:45 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.08, #running-req: 114, #queue-req: 271, 
1: [2025-10-29 20:11:45 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.08, #running-req: 120, #queue-req: 268, 
1: [2025-10-29 20:11:45 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 108, #queue-req: 301, 
1: [2025-10-29 20:11:45 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.08, #running-req: 112, #queue-req: 258, 
0: [2025-10-29 08:11:45 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.08, #running-req: 113, #queue-req: 268, 
0: [2025-10-29 08:11:45 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.08, #running-req: 90, #queue-req: 298, 
0: [2025-10-29 08:11:45 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 108, #queue-req: 268, 
0: [2025-10-29 08:11:45 DP2 TP2 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 16, token usage: 0.08, #running-req: 127, #queue-req: 253, 
1: [2025-10-29 20:11:45 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.08, #running-req: 113, #queue-req: 268, 
1: [2025-10-29 20:11:45 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 108, #queue-req: 268, 
1: [2025-10-29 20:11:45 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.08, #running-req: 90, #queue-req: 298, 
1: [2025-10-29 20:11:45 DP2 TP2 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 16, token usage: 0.08, #running-req: 127, #queue-req: 253, 
0: [2025-10-29 08:11:45 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 108, #queue-req: 297, 
0: [2025-10-29 08:11:45 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.08, #running-req: 114, #queue-req: 252, 
0: [2025-10-29 08:11:45 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 115, #queue-req: 268, 
0: [2025-10-29 08:11:45 DP3 TP3 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 15, token usage: 0.08, #running-req: 123, #queue-req: 263, 
1: [2025-10-29 20:11:45 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 115, #queue-req: 268, 
1: [2025-10-29 20:11:45 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 108, #queue-req: 297, 
1: [2025-10-29 20:11:45 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.08, #running-req: 114, #queue-req: 252, 
1: [2025-10-29 20:11:45 DP3 TP3 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 15, token usage: 0.08, #running-req: 123, #queue-req: 263, 
0: [2025-10-29 08:11:45 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.08, #running-req: 108, #queue-req: 260, 
0: [2025-10-29 08:11:45 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 93, #queue-req: 297, 
0: [2025-10-29 08:11:45 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 116, #queue-req: 267, 
0: [2025-10-29 08:11:45 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 132, #queue-req: 252, 
1: [2025-10-29 20:11:46 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.08, #running-req: 108, #queue-req: 260, 
1: [2025-10-29 20:11:46 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 116, #queue-req: 267, 
1: [2025-10-29 20:11:46 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 93, #queue-req: 297, 
1: [2025-10-29 20:11:46 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 132, #queue-req: 252, 
0: [2025-10-29 08:11:46 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.08, #running-req: 115, #queue-req: 264, 
0: [2025-10-29 08:11:46 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 109, #queue-req: 296, 
0: [2025-10-29 08:11:46 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 115, #queue-req: 252, 
0: [2025-10-29 08:11:46 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.08, #running-req: 128, #queue-req: 257, 
1: [2025-10-29 20:11:46 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 109, #queue-req: 296, 
1: [2025-10-29 20:11:46 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 115, #queue-req: 252, 
1: [2025-10-29 20:11:46 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.08, #running-req: 115, #queue-req: 264, 
1: [2025-10-29 20:11:46 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.08, #running-req: 128, #queue-req: 257, 
0: [2025-10-29 08:11:46 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.08, #running-req: 93, #queue-req: 295, 
0: [2025-10-29 08:11:46 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.08, #running-req: 132, #queue-req: 251, 
0: [2025-10-29 08:11:46 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.08, #running-req: 117, #queue-req: 262, 
0: [2025-10-29 08:11:46 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.08, #running-req: 111, #queue-req: 254, 
1: [2025-10-29 20:11:46 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.08, #running-req: 132, #queue-req: 251, 
1: [2025-10-29 20:11:46 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.08, #running-req: 93, #queue-req: 295, 
1: [2025-10-29 20:11:46 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.08, #running-req: 117, #queue-req: 262, 
1: [2025-10-29 20:11:46 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.08, #running-req: 111, #queue-req: 254, 
0: [2025-10-29 08:11:46 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 115, #queue-req: 251, 
0: [2025-10-29 08:11:46 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 110, #queue-req: 294, 
0: [2025-10-29 08:11:46 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 118, #queue-req: 261, 
0: [2025-10-29 08:11:46 DP3 TP3 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 9, token usage: 0.08, #running-req: 131, #queue-req: 249, 
1: [2025-10-29 20:11:46 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 115, #queue-req: 251, 
1: [2025-10-29 20:11:46 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 110, #queue-req: 294, 
1: [2025-10-29 20:11:46 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 118, #queue-req: 261, 
1: [2025-10-29 20:11:46 DP3 TP3 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 9, token usage: 0.08, #running-req: 131, #queue-req: 249, 
0: [2025-10-29 08:11:46 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 94, #queue-req: 294, 
0: [2025-10-29 08:11:46 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 114, #queue-req: 248, 
0: [2025-10-29 08:11:46 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.08, #running-req: 119, #queue-req: 258, 
0: [2025-10-29 08:11:46 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.08, #running-req: 133, #queue-req: 248, 
1: [2025-10-29 20:11:46 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 94, #queue-req: 294, 
1: [2025-10-29 20:11:46 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.08, #running-req: 133, #queue-req: 248, 
1: [2025-10-29 20:11:46 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 114, #queue-req: 248, 
1: [2025-10-29 20:11:46 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.08, #running-req: 119, #queue-req: 258, 
0: [2025-10-29 08:11:46 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 115, #queue-req: 248, 
0: [2025-10-29 08:11:46 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 111, #queue-req: 294, 
0: [2025-10-29 08:11:46 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 119, #queue-req: 257, 
0: [2025-10-29 08:11:46 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.08, #running-req: 136, #queue-req: 246, 
1: [2025-10-29 20:11:46 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 115, #queue-req: 248, 
1: [2025-10-29 20:11:46 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 111, #queue-req: 294, 
1: [2025-10-29 20:11:46 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 119, #queue-req: 257, 
1: [2025-10-29 20:11:46 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.08, #running-req: 136, #queue-req: 246, 
0: [2025-10-29 08:11:46 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.08, #running-req: 94, #queue-req: 291, 
0: [2025-10-29 08:11:46 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 136, #queue-req: 248, 
0: [2025-10-29 08:11:46 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.08, #running-req: 115, #queue-req: 245, 
0: [2025-10-29 08:11:46 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.08, #running-req: 122, #queue-req: 256, 
1: [2025-10-29 20:11:46 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 136, #queue-req: 248, 
1: [2025-10-29 20:11:46 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.08, #running-req: 94, #queue-req: 291, 
1: [2025-10-29 20:11:46 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.08, #running-req: 122, #queue-req: 256, 
1: [2025-10-29 20:11:46 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.08, #running-req: 115, #queue-req: 245, 
0: [2025-10-29 08:11:46 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.09, #running-req: 111, #queue-req: 290, 
0: [2025-10-29 08:11:46 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 115, #queue-req: 248, 
0: [2025-10-29 08:11:46 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.08, #running-req: 120, #queue-req: 255, 
0: [2025-10-29 08:11:46 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 138, #queue-req: 244, 
1: [2025-10-29 20:11:46 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.09, #running-req: 111, #queue-req: 290, 
1: [2025-10-29 20:11:46 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.08, #running-req: 115, #queue-req: 248, 
1: [2025-10-29 20:11:46 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.08, #running-req: 120, #queue-req: 255, 
1: [2025-10-29 20:11:46 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.08, #running-req: 138, #queue-req: 244, 
0: [2025-10-29 08:11:46 DP2 TP2 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 10, token usage: 0.09, #running-req: 136, #queue-req: 243, 
0: [2025-10-29 08:11:46 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.09, #running-req: 123, #queue-req: 254, 
0: [2025-10-29 08:11:46 DP0 TP0 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 14, token usage: 0.09, #running-req: 97, #queue-req: 286, 
0: [2025-10-29 08:11:46 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 116, #queue-req: 244, 
1: [2025-10-29 20:11:46 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 116, #queue-req: 244, 
1: [2025-10-29 20:11:46 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.09, #running-req: 123, #queue-req: 254, 
1: [2025-10-29 20:11:46 DP0 TP0 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 14, token usage: 0.09, #running-req: 97, #queue-req: 286, 
1: [2025-10-29 20:11:46 DP2 TP2 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 10, token usage: 0.09, #running-req: 136, #queue-req: 243, 
0: [2025-10-29 08:11:46 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.09, #running-req: 115, #queue-req: 240, 
0: [2025-10-29 08:11:46 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 112, #queue-req: 286, 
0: [2025-10-29 08:11:46 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 121, #queue-req: 254, 
0: [2025-10-29 08:11:46 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 139, #queue-req: 244, 
1: [2025-10-29 20:11:46 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.09, #running-req: 115, #queue-req: 240, 
1: [2025-10-29 20:11:46 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 121, #queue-req: 254, 
1: [2025-10-29 20:11:46 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 112, #queue-req: 286, 
1: [2025-10-29 20:11:46 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 139, #queue-req: 244, 
0: [2025-10-29 08:11:46 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 116, #queue-req: 244, 
0: [2025-10-29 08:11:46 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 101, #queue-req: 286, 
0: [2025-10-29 08:11:46 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 141, #queue-req: 240, 
0: [2025-10-29 08:11:46 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.09, #running-req: 124, #queue-req: 253, 
1: [2025-10-29 20:11:46 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 116, #queue-req: 244, 
1: [2025-10-29 20:11:46 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.09, #running-req: 124, #queue-req: 253, 
1: [2025-10-29 20:11:46 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 101, #queue-req: 286, 
1: [2025-10-29 20:11:46 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 141, #queue-req: 240, 
0: [2025-10-29 08:11:46 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.09, #running-req: 121, #queue-req: 252, 
0: [2025-10-29 08:11:46 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 112, #queue-req: 286, 
0: [2025-10-29 08:11:46 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 13, token usage: 0.09, #running-req: 139, #queue-req: 242, 
0: [2025-10-29 08:11:46 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.09, #running-req: 118, #queue-req: 237, 
1: [2025-10-29 20:11:46 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.09, #running-req: 121, #queue-req: 252, 
1: [2025-10-29 20:11:46 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 112, #queue-req: 286, 
1: [2025-10-29 20:11:46 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 13, token usage: 0.09, #running-req: 139, #queue-req: 242, 
1: [2025-10-29 20:11:46 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.09, #running-req: 118, #queue-req: 237, 
0: [2025-10-29 08:11:46 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.09, #running-req: 141, #queue-req: 236, 
0: [2025-10-29 08:11:46 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.09, #running-req: 116, #queue-req: 239, 
0: [2025-10-29 08:11:46 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.09, #running-req: 101, #queue-req: 284, 
0: [2025-10-29 08:11:46 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.09, #running-req: 125, #queue-req: 249, 
1: [2025-10-29 20:11:46 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.09, #running-req: 141, #queue-req: 236, 
1: [2025-10-29 20:11:46 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.09, #running-req: 116, #queue-req: 239, 
1: [2025-10-29 20:11:46 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.09, #running-req: 101, #queue-req: 284, 
1: [2025-10-29 20:11:46 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.09, #running-req: 125, #queue-req: 249, 
0: [2025-10-29 08:11:46 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.09, #running-req: 112, #queue-req: 283, 
0: [2025-10-29 08:11:46 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.09, #running-req: 121, #queue-req: 235, 
0: [2025-10-29 08:11:46 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 122, #queue-req: 249, 
0: [2025-10-29 08:11:46 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.09, #running-req: 141, #queue-req: 237, 
1: [2025-10-29 20:11:46 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.09, #running-req: 112, #queue-req: 283, 
1: [2025-10-29 20:11:46 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.09, #running-req: 121, #queue-req: 235, 
1: [2025-10-29 20:11:46 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 122, #queue-req: 249, 
1: [2025-10-29 20:11:46 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.09, #running-req: 141, #queue-req: 237, 
0: [2025-10-29 08:11:46 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.09, #running-req: 128, #queue-req: 248, 
0: [2025-10-29 08:11:46 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 119, #queue-req: 237, 
0: [2025-10-29 08:11:46 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 142, #queue-req: 235, 
0: [2025-10-29 08:11:46 DP0 TP0 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 10, token usage: 0.09, #running-req: 103, #queue-req: 278, 
1: [2025-10-29 20:11:46 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 142, #queue-req: 235, 
1: [2025-10-29 20:11:46 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 119, #queue-req: 237, 
1: [2025-10-29 20:11:46 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.09, #running-req: 128, #queue-req: 248, 
1: [2025-10-29 20:11:46 DP0 TP0 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 10, token usage: 0.09, #running-req: 103, #queue-req: 278, 
0: [2025-10-29 08:11:46 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.09, #running-req: 122, #queue-req: 246, 
0: [2025-10-29 08:11:46 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 113, #queue-req: 278, 
0: [2025-10-29 08:11:46 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 143, #queue-req: 237, 
0: [2025-10-29 08:11:46 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.09, #running-req: 122, #queue-req: 233, 
1: [2025-10-29 20:11:46 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.09, #running-req: 122, #queue-req: 246, 
1: [2025-10-29 20:11:46 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 113, #queue-req: 278, 
1: [2025-10-29 20:11:46 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 143, #queue-req: 237, 
1: [2025-10-29 20:11:46 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.09, #running-req: 122, #queue-req: 233, 
0: [2025-10-29 08:11:46 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.09, #running-req: 119, #queue-req: 236, 
0: [2025-10-29 08:11:46 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.09, #running-req: 142, #queue-req: 231, 
0: [2025-10-29 08:11:46 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.09, #running-req: 108, #queue-req: 277, 
0: [2025-10-29 08:11:46 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.09, #running-req: 129, #queue-req: 245, 
1: [2025-10-29 20:11:47 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.09, #running-req: 142, #queue-req: 231, 
1: [2025-10-29 20:11:47 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.09, #running-req: 119, #queue-req: 236, 
1: [2025-10-29 20:11:47 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.09, #running-req: 129, #queue-req: 245, 
1: [2025-10-29 20:11:47 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.09, #running-req: 108, #queue-req: 277, 
0: [2025-10-29 08:11:47 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.09, #running-req: 143, #queue-req: 233, 
0: [2025-10-29 08:11:47 DP0 TP0 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 13, token usage: 0.09, #running-req: 113, #queue-req: 272, 
0: [2025-10-29 08:11:47 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 124, #queue-req: 231, 
0: [2025-10-29 08:11:47 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.09, #running-req: 124, #queue-req: 244, 
1: [2025-10-29 20:11:47 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.09, #running-req: 143, #queue-req: 233, 
1: [2025-10-29 20:11:47 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.09, #running-req: 124, #queue-req: 244, 
1: [2025-10-29 20:11:47 DP0 TP0 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 13, token usage: 0.09, #running-req: 113, #queue-req: 272, 
1: [2025-10-29 20:11:47 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 124, #queue-req: 231, 
0: [2025-10-29 08:11:47 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 144, #queue-req: 231, 
0: [2025-10-29 08:11:47 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.09, #running-req: 130, #queue-req: 243, 
0: [2025-10-29 08:11:47 DP0 TP0 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 12, token usage: 0.09, #running-req: 109, #queue-req: 267, 
0: [2025-10-29 08:11:47 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.09, #running-req: 120, #queue-req: 229, 
1: [2025-10-29 20:11:47 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.09, #running-req: 130, #queue-req: 243, 
1: [2025-10-29 20:11:47 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 144, #queue-req: 231, 
1: [2025-10-29 20:11:47 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.09, #running-req: 120, #queue-req: 229, 
1: [2025-10-29 20:11:47 DP0 TP0 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 12, token usage: 0.09, #running-req: 109, #queue-req: 267, 
0: [2025-10-29 08:11:47 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.09, #running-req: 147, #queue-req: 228, 
0: [2025-10-29 08:11:47 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.09, #running-req: 124, #queue-req: 229, 
0: [2025-10-29 08:11:47 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.09, #running-req: 118, #queue-req: 265, 
0: [2025-10-29 08:11:47 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.09, #running-req: 125, #queue-req: 242, 
1: [2025-10-29 20:11:47 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.09, #running-req: 124, #queue-req: 229, 
1: [2025-10-29 20:11:47 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.09, #running-req: 125, #queue-req: 242, 
1: [2025-10-29 20:11:47 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.09, #running-req: 147, #queue-req: 228, 
1: [2025-10-29 20:11:47 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.09, #running-req: 118, #queue-req: 265, 
0: [2025-10-29 08:11:47 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 144, #queue-req: 229, 
0: [2025-10-29 08:11:47 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 123, #queue-req: 228, 
0: [2025-10-29 08:11:47 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.09, #running-req: 131, #queue-req: 240, 
0: [2025-10-29 08:11:47 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 18, token usage: 0.09, #running-req: 114, #queue-req: 262, 
1: [2025-10-29 20:11:47 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 144, #queue-req: 229, 
1: [2025-10-29 20:11:47 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 123, #queue-req: 228, 
1: [2025-10-29 20:11:47 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.09, #running-req: 131, #queue-req: 240, 
1: [2025-10-29 20:11:47 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 18, token usage: 0.09, #running-req: 114, #queue-req: 262, 
0: [2025-10-29 08:11:47 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 126, #queue-req: 229, 
0: [2025-10-29 08:11:47 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 120, #queue-req: 262, 
0: [2025-10-29 08:11:47 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 148, #queue-req: 228, 
0: [2025-10-29 08:11:47 DP1 TP1 PP0] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 18, token usage: 0.09, #running-req: 126, #queue-req: 233, 
1: [2025-10-29 20:11:47 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 120, #queue-req: 262, 
1: [2025-10-29 20:11:47 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 126, #queue-req: 229, 
1: [2025-10-29 20:11:47 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 148, #queue-req: 228, 
1: [2025-10-29 20:11:47 DP1 TP1 PP1] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 18, token usage: 0.09, #running-req: 126, #queue-req: 233, 
0: [2025-10-29 08:11:47 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 123, #queue-req: 228, 
0: [2025-10-29 08:11:47 DP2 TP2 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 12, token usage: 0.09, #running-req: 144, #queue-req: 225, 
0: [2025-10-29 08:11:47 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.09, #running-req: 117, #queue-req: 260, 
0: [2025-10-29 08:11:47 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 133, #queue-req: 233, 
1: [2025-10-29 20:11:47 DP2 TP2 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 12, token usage: 0.09, #running-req: 144, #queue-req: 225, 
1: [2025-10-29 20:11:47 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 123, #queue-req: 228, 
1: [2025-10-29 20:11:47 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 133, #queue-req: 233, 
1: [2025-10-29 20:11:47 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.09, #running-req: 117, #queue-req: 260, 
0: [2025-10-29 08:11:47 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.10, #running-req: 120, #queue-req: 258, 
0: [2025-10-29 08:11:47 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.09, #running-req: 126, #queue-req: 223, 
0: [2025-10-29 08:11:47 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 148, #queue-req: 228, 
0: [2025-10-29 08:11:47 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.09, #running-req: 133, #queue-req: 232, 
1: [2025-10-29 20:11:47 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.09, #running-req: 126, #queue-req: 223, 
1: [2025-10-29 20:11:47 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.10, #running-req: 120, #queue-req: 258, 
1: [2025-10-29 20:11:47 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.09, #running-req: 148, #queue-req: 228, 
1: [2025-10-29 20:11:47 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.09, #running-req: 133, #queue-req: 232, 
0: [2025-10-29 08:11:47 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 133, #queue-req: 231, 
0: [2025-10-29 08:11:47 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 123, #queue-req: 228, 
0: [2025-10-29 08:11:47 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.10, #running-req: 119, #queue-req: 256, 
0: [2025-10-29 08:11:47 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 148, #queue-req: 222, 
1: [2025-10-29 20:11:47 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 133, #queue-req: 231, 
1: [2025-10-29 20:11:47 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 123, #queue-req: 228, 
1: [2025-10-29 20:11:47 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 148, #queue-req: 222, 
1: [2025-10-29 20:11:47 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.10, #running-req: 119, #queue-req: 256, 
0: [2025-10-29 08:11:47 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 148, #queue-req: 228, 
0: [2025-10-29 08:11:47 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 122, #queue-req: 256, 
0: [2025-10-29 08:11:47 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 9, token usage: 0.10, #running-req: 128, #queue-req: 220, 
0: [2025-10-29 08:11:47 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 134, #queue-req: 229, 
1: [2025-10-29 20:11:47 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 122, #queue-req: 256, 
1: [2025-10-29 20:11:47 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 9, token usage: 0.10, #running-req: 128, #queue-req: 220, 
1: [2025-10-29 20:11:47 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 134, #queue-req: 229, 
1: [2025-10-29 20:11:47 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 148, #queue-req: 228, 
0: [2025-10-29 08:11:47 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 123, #queue-req: 227, 
0: [2025-10-29 08:11:47 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 121, #queue-req: 256, 
0: [2025-10-29 08:11:47 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 134, #queue-req: 229, 
0: [2025-10-29 08:11:47 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 149, #queue-req: 218, 
1: [2025-10-29 20:11:47 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 134, #queue-req: 229, 
1: [2025-10-29 20:11:47 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 121, #queue-req: 256, 
1: [2025-10-29 20:11:47 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 149, #queue-req: 218, 
1: [2025-10-29 20:11:47 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 123, #queue-req: 227, 
0: [2025-10-29 08:11:47 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.10, #running-req: 148, #queue-req: 226, 
0: [2025-10-29 08:11:47 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 122, #queue-req: 256, 
0: [2025-10-29 08:11:47 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 136, #queue-req: 229, 
0: [2025-10-29 08:11:47 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.10, #running-req: 130, #queue-req: 215, 
1: [2025-10-29 20:11:47 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 122, #queue-req: 256, 
1: [2025-10-29 20:11:47 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.10, #running-req: 148, #queue-req: 226, 
1: [2025-10-29 20:11:47 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.10, #running-req: 130, #queue-req: 215, 
1: [2025-10-29 20:11:47 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 136, #queue-req: 229, 
0: [2025-10-29 08:11:47 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 134, #queue-req: 229, 
0: [2025-10-29 08:11:47 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 121, #queue-req: 256, 
0: [2025-10-29 08:11:47 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.10, #running-req: 124, #queue-req: 225, 
0: [2025-10-29 08:11:47 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.10, #running-req: 151, #queue-req: 213, 
1: [2025-10-29 20:11:47 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 121, #queue-req: 256, 
1: [2025-10-29 20:11:47 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.10, #running-req: 151, #queue-req: 213, 
1: [2025-10-29 20:11:47 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 134, #queue-req: 229, 
1: [2025-10-29 20:11:47 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.10, #running-req: 124, #queue-req: 225, 
0: [2025-10-29 08:11:47 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 122, #queue-req: 256, 
0: [2025-10-29 08:11:47 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 136, #queue-req: 228, 
0: [2025-10-29 08:11:47 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.10, #running-req: 133, #queue-req: 212, 
0: [2025-10-29 08:11:47 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.10, #running-req: 149, #queue-req: 222, 
1: [2025-10-29 20:11:47 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 136, #queue-req: 228, 
1: [2025-10-29 20:11:47 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.10, #running-req: 149, #queue-req: 222, 
1: [2025-10-29 20:11:47 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 122, #queue-req: 256, 
1: [2025-10-29 20:11:47 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.10, #running-req: 133, #queue-req: 212, 
0: [2025-10-29 08:11:47 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 134, #queue-req: 226, 
0: [2025-10-29 08:11:47 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 121, #queue-req: 256, 
0: [2025-10-29 08:11:47 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.10, #running-req: 125, #queue-req: 221, 
0: [2025-10-29 08:11:47 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.10, #running-req: 153, #queue-req: 211, 
1: [2025-10-29 20:11:47 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 134, #queue-req: 226, 
1: [2025-10-29 20:11:47 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.10, #running-req: 153, #queue-req: 211, 
1: [2025-10-29 20:11:47 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.10, #running-req: 125, #queue-req: 221, 
1: [2025-10-29 20:11:47 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 121, #queue-req: 256, 
0: [2025-10-29 08:11:47 DP0 TP0 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.10, #running-req: 122, #queue-req: 252, 
0: [2025-10-29 08:11:47 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.10, #running-req: 134, #queue-req: 210, 
0: [2025-10-29 08:11:47 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.10, #running-req: 152, #queue-req: 219, 
0: [2025-10-29 08:11:47 DP1 TP1 PP0] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 19, token usage: 0.10, #running-req: 137, #queue-req: 220, 
1: [2025-10-29 20:11:48 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.10, #running-req: 134, #queue-req: 210, 
1: [2025-10-29 20:11:48 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.10, #running-req: 152, #queue-req: 219, 
1: [2025-10-29 20:11:48 DP1 TP1 PP1] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 19, token usage: 0.10, #running-req: 137, #queue-req: 220, 
1: [2025-10-29 20:11:48 DP0 TP0 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.10, #running-req: 122, #queue-req: 252, 
0: [2025-10-29 08:11:48 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.10, #running-req: 121, #queue-req: 251, 
0: [2025-10-29 08:11:48 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 136, #queue-req: 220, 
0: [2025-10-29 08:11:48 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 126, #queue-req: 219, 
0: [2025-10-29 08:11:48 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.10, #running-req: 154, #queue-req: 207, 
1: [2025-10-29 20:11:48 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.10, #running-req: 121, #queue-req: 251, 
1: [2025-10-29 20:11:48 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 136, #queue-req: 220, 
1: [2025-10-29 20:11:48 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.10, #running-req: 154, #queue-req: 207, 
1: [2025-10-29 20:11:48 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 126, #queue-req: 219, 
0: [2025-10-29 08:11:48 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 135, #queue-req: 206, 
0: [2025-10-29 08:11:48 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.10, #running-req: 126, #queue-req: 248, 
0: [2025-10-29 08:11:48 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 154, #queue-req: 219, 
0: [2025-10-29 08:11:48 DP1 TP1 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 10, token usage: 0.10, #running-req: 143, #queue-req: 215, 
1: [2025-10-29 20:11:48 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 135, #queue-req: 206, 
1: [2025-10-29 20:11:48 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.10, #running-req: 126, #queue-req: 248, 
1: [2025-10-29 20:11:48 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 154, #queue-req: 219, 
1: [2025-10-29 20:11:48 DP1 TP1 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 10, token usage: 0.10, #running-req: 143, #queue-req: 215, 
0: [2025-10-29 08:11:48 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.10, #running-req: 136, #queue-req: 214, 
0: [2025-10-29 08:11:48 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 126, #queue-req: 218, 
0: [2025-10-29 08:11:48 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 157, #queue-req: 205, 
0: [2025-10-29 08:11:48 DP0 TP0 PP0] Prefill batch. #new-seq: 9, #new-token: 512, #cached-token: 24, token usage: 0.10, #running-req: 122, #queue-req: 240, 
1: [2025-10-29 20:11:48 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.10, #running-req: 136, #queue-req: 214, 
1: [2025-10-29 20:11:48 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 126, #queue-req: 218, 
1: [2025-10-29 20:11:48 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 157, #queue-req: 205, 
1: [2025-10-29 20:11:48 DP0 TP0 PP1] Prefill batch. #new-seq: 9, #new-token: 512, #cached-token: 24, token usage: 0.10, #running-req: 122, #queue-req: 240, 
0: [2025-10-29 08:11:48 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 154, #queue-req: 218, 
0: [2025-10-29 08:11:48 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 129, #queue-req: 240, 
0: [2025-10-29 08:11:48 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.10, #running-req: 136, #queue-req: 204, 
0: [2025-10-29 08:11:48 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.10, #running-req: 148, #queue-req: 211, 
1: [2025-10-29 20:11:48 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 154, #queue-req: 218, 
1: [2025-10-29 20:11:48 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 129, #queue-req: 240, 
1: [2025-10-29 20:11:48 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.10, #running-req: 136, #queue-req: 204, 
1: [2025-10-29 20:11:48 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.10, #running-req: 148, #queue-req: 211, 
0: [2025-10-29 08:11:48 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 130, #queue-req: 240, 
0: [2025-10-29 08:11:48 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 127, #queue-req: 218, 
0: [2025-10-29 08:11:48 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.10, #running-req: 158, #queue-req: 202, 
0: [2025-10-29 08:11:48 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 137, #queue-req: 210, 
1: [2025-10-29 20:11:48 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 137, #queue-req: 210, 
1: [2025-10-29 20:11:48 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 130, #queue-req: 240, 
1: [2025-10-29 20:11:48 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.10, #running-req: 158, #queue-req: 202, 
1: [2025-10-29 20:11:48 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 127, #queue-req: 218, 
0: [2025-10-29 08:11:48 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 154, #queue-req: 218, 
0: [2025-10-29 08:11:48 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 129, #queue-req: 240, 
0: [2025-10-29 08:11:48 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.10, #running-req: 151, #queue-req: 208, 
0: [2025-10-29 08:11:48 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.10, #running-req: 137, #queue-req: 199, 
1: [2025-10-29 20:11:48 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 129, #queue-req: 240, 
1: [2025-10-29 20:11:48 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 154, #queue-req: 218, 
1: [2025-10-29 20:11:48 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.10, #running-req: 137, #queue-req: 199, 
1: [2025-10-29 20:11:48 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.10, #running-req: 151, #queue-req: 208, 
0: [2025-10-29 08:11:48 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 127, #queue-req: 218, 
0: [2025-10-29 08:11:48 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.10, #running-req: 130, #queue-req: 239, 
0: [2025-10-29 08:11:48 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 138, #queue-req: 208, 
0: [2025-10-29 08:11:48 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.10, #running-req: 160, #queue-req: 198, 
1: [2025-10-29 20:11:48 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 138, #queue-req: 208, 
1: [2025-10-29 20:11:48 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 127, #queue-req: 218, 
1: [2025-10-29 20:11:48 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.10, #running-req: 160, #queue-req: 198, 
1: [2025-10-29 20:11:48 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.10, #running-req: 130, #queue-req: 239, 
0: [2025-10-29 08:11:48 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 129, #queue-req: 239, 
0: [2025-10-29 08:11:48 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 154, #queue-req: 218, 
0: [2025-10-29 08:11:48 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.10, #running-req: 153, #queue-req: 204, 
0: [2025-10-29 08:11:48 DP2 TP2 PP0] Prefill batch. #new-seq: 12, #new-token: 512, #cached-token: 22, token usage: 0.10, #running-req: 140, #queue-req: 187, 
1: [2025-10-29 20:11:48 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 129, #queue-req: 239, 
1: [2025-10-29 20:11:48 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 154, #queue-req: 218, 
1: [2025-10-29 20:11:48 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.10, #running-req: 153, #queue-req: 204, 
1: [2025-10-29 20:11:48 DP2 TP2 PP1] Prefill batch. #new-seq: 12, #new-token: 512, #cached-token: 22, token usage: 0.10, #running-req: 140, #queue-req: 187, 
0: [2025-10-29 08:11:48 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 138, #queue-req: 204, 
0: [2025-10-29 08:11:48 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 131, #queue-req: 239, 
0: [2025-10-29 08:11:48 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 127, #queue-req: 217, 
0: [2025-10-29 08:11:48 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 161, #queue-req: 187, 
1: [2025-10-29 20:11:48 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 138, #queue-req: 204, 
1: [2025-10-29 20:11:48 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.10, #running-req: 127, #queue-req: 217, 
1: [2025-10-29 20:11:48 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.10, #running-req: 161, #queue-req: 187, 
1: [2025-10-29 20:11:48 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 131, #queue-req: 239, 
0: [2025-10-29 08:11:48 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.11, #running-req: 154, #queue-req: 214, 
0: [2025-10-29 08:11:48 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.11, #running-req: 129, #queue-req: 237, 
0: [2025-10-29 08:11:48 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.11, #running-req: 157, #queue-req: 203, 
0: [2025-10-29 08:11:48 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.11, #running-req: 151, #queue-req: 185, 
1: [2025-10-29 20:11:48 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.11, #running-req: 154, #queue-req: 214, 
1: [2025-10-29 20:11:48 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.11, #running-req: 157, #queue-req: 203, 
1: [2025-10-29 20:11:48 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.11, #running-req: 129, #queue-req: 237, 
1: [2025-10-29 20:11:48 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.11, #running-req: 151, #queue-req: 185, 
0: [2025-10-29 08:11:48 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.11, #running-req: 138, #queue-req: 202, 
0: [2025-10-29 08:11:48 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.11, #running-req: 131, #queue-req: 235, 
0: [2025-10-29 08:11:48 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.11, #running-req: 161, #queue-req: 184, 
0: [2025-10-29 08:11:48 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.11, #running-req: 128, #queue-req: 212, 
1: [2025-10-29 20:11:48 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.11, #running-req: 161, #queue-req: 184, 
1: [2025-10-29 20:11:48 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.11, #running-req: 131, #queue-req: 235, 
1: [2025-10-29 20:11:48 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.11, #running-req: 138, #queue-req: 202, 
1: [2025-10-29 20:11:48 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.11, #running-req: 128, #queue-req: 212, 
0: [2025-10-29 08:11:48 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.11, #running-req: 131, #queue-req: 234, 
0: [2025-10-29 08:11:48 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.11, #running-req: 153, #queue-req: 183, 
0: [2025-10-29 08:11:48 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.11, #running-req: 158, #queue-req: 200, 
0: [2025-10-29 08:11:48 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 11, token usage: 0.11, #running-req: 157, #queue-req: 210, 
1: [2025-10-29 20:11:48 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.11, #running-req: 131, #queue-req: 234, 
1: [2025-10-29 20:11:48 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.11, #running-req: 153, #queue-req: 183, 
1: [2025-10-29 20:11:48 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.11, #running-req: 158, #queue-req: 200, 
1: [2025-10-29 20:11:48 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 11, token usage: 0.11, #running-req: 157, #queue-req: 210, 
0: [2025-10-29 08:11:48 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.11, #running-req: 133, #queue-req: 233, 
0: [2025-10-29 08:11:48 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 130, #queue-req: 210, 
0: [2025-10-29 08:11:48 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 162, #queue-req: 183, 
0: [2025-10-29 08:11:48 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 139, #queue-req: 200, 
1: [2025-10-29 20:11:48 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 162, #queue-req: 183, 
1: [2025-10-29 20:11:48 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 139, #queue-req: 200, 
1: [2025-10-29 20:11:48 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.11, #running-req: 133, #queue-req: 233, 
1: [2025-10-29 20:11:48 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 130, #queue-req: 210, 
0: [2025-10-29 08:11:48 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 132, #queue-req: 233, 
0: [2025-10-29 08:11:48 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.11, #running-req: 154, #queue-req: 181, 
0: [2025-10-29 08:11:48 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.11, #running-req: 159, #queue-req: 207, 
0: [2025-10-29 08:11:48 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.11, #running-req: 160, #queue-req: 199, 
1: [2025-10-29 20:11:48 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 132, #queue-req: 233, 
1: [2025-10-29 20:11:48 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.11, #running-req: 160, #queue-req: 199, 
1: [2025-10-29 20:11:48 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.11, #running-req: 154, #queue-req: 181, 
1: [2025-10-29 20:11:48 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.11, #running-req: 159, #queue-req: 207, 
0: [2025-10-29 08:11:48 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 3, token usage: 0.11, #running-req: 130, #queue-req: 204, 
0: [2025-10-29 08:11:48 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 11, token usage: 0.11, #running-req: 139, #queue-req: 195, 
0: [2025-10-29 08:11:48 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 14, token usage: 0.11, #running-req: 162, #queue-req: 179, 
0: [2025-10-29 08:11:48 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 134, #queue-req: 233, 
1: [2025-10-29 20:11:48 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 14, token usage: 0.11, #running-req: 162, #queue-req: 179, 
1: [2025-10-29 20:11:48 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 3, token usage: 0.11, #running-req: 130, #queue-req: 204, 
1: [2025-10-29 20:11:48 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 134, #queue-req: 233, 
1: [2025-10-29 20:11:48 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 11, token usage: 0.11, #running-req: 139, #queue-req: 195, 
0: [2025-10-29 08:11:48 DP0 TP0 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 7, token usage: 0.11, #running-req: 132, #queue-req: 229, 
0: [2025-10-29 08:11:48 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.11, #running-req: 162, #queue-req: 203, 
0: [2025-10-29 08:11:48 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.11, #running-req: 161, #queue-req: 194, 
0: [2025-10-29 08:11:48 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.11, #running-req: 156, #queue-req: 177, 
1: [2025-10-29 20:11:49 DP0 TP0 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 7, token usage: 0.11, #running-req: 132, #queue-req: 229, 
1: [2025-10-29 20:11:49 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.11, #running-req: 156, #queue-req: 177, 
1: [2025-10-29 20:11:49 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.11, #running-req: 161, #queue-req: 194, 
1: [2025-10-29 20:11:49 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.11, #running-req: 162, #queue-req: 203, 
0: [2025-10-29 08:11:49 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.11, #running-req: 134, #queue-req: 226, 
0: [2025-10-29 08:11:49 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 143, #queue-req: 194, 
0: [2025-10-29 08:11:49 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.11, #running-req: 133, #queue-req: 201, 
0: [2025-10-29 08:11:49 DP2 TP2 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 7, token usage: 0.11, #running-req: 164, #queue-req: 173, 
1: [2025-10-29 20:11:49 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.11, #running-req: 134, #queue-req: 226, 
1: [2025-10-29 20:11:49 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 143, #queue-req: 194, 
1: [2025-10-29 20:11:49 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.11, #running-req: 133, #queue-req: 201, 
1: [2025-10-29 20:11:49 DP2 TP2 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 7, token usage: 0.11, #running-req: 164, #queue-req: 173, 
0: [2025-10-29 08:11:49 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.11, #running-req: 136, #queue-req: 225, 
0: [2025-10-29 08:11:49 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.11, #running-req: 163, #queue-req: 200, 
0: [2025-10-29 08:11:49 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.11, #running-req: 162, #queue-req: 192, 
0: [2025-10-29 08:11:49 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 158, #queue-req: 173, 
1: [2025-10-29 20:11:49 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.11, #running-req: 136, #queue-req: 225, 
1: [2025-10-29 20:11:49 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 158, #queue-req: 173, 
1: [2025-10-29 20:11:49 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.11, #running-req: 162, #queue-req: 192, 
1: [2025-10-29 20:11:49 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.11, #running-req: 163, #queue-req: 200, 
0: [2025-10-29 08:11:49 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.11, #running-req: 143, #queue-req: 189, 
0: [2025-10-29 08:11:49 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.11, #running-req: 135, #queue-req: 197, 
0: [2025-10-29 08:11:49 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 168, #queue-req: 173, 
0: [2025-10-29 08:11:49 DP0 TP0 PP0] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 17, token usage: 0.11, #running-req: 137, #queue-req: 219, 
1: [2025-10-29 20:11:49 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.11, #running-req: 143, #queue-req: 189, 
1: [2025-10-29 20:11:49 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 168, #queue-req: 173, 
1: [2025-10-29 20:11:49 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.11, #running-req: 135, #queue-req: 197, 
1: [2025-10-29 20:11:49 DP0 TP0 PP1] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 17, token usage: 0.11, #running-req: 137, #queue-req: 219, 
0: [2025-10-29 08:11:49 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 158, #queue-req: 173, 
0: [2025-10-29 08:11:49 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.11, #running-req: 164, #queue-req: 196, 
0: [2025-10-29 08:11:49 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 164, #queue-req: 189, 
0: [2025-10-29 08:11:49 DP0 TP0 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 10, token usage: 0.11, #running-req: 137, #queue-req: 214, 
1: [2025-10-29 20:11:49 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 164, #queue-req: 189, 
1: [2025-10-29 20:11:49 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 158, #queue-req: 173, 
1: [2025-10-29 20:11:49 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.11, #running-req: 164, #queue-req: 196, 
1: [2025-10-29 20:11:49 DP0 TP0 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 10, token usage: 0.11, #running-req: 137, #queue-req: 214, 
0: [2025-10-29 08:11:49 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 168, #queue-req: 173, 
0: [2025-10-29 08:11:49 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.11, #running-req: 138, #queue-req: 195, 
0: [2025-10-29 08:11:49 DP0 TP0 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 17, token usage: 0.11, #running-req: 143, #queue-req: 210, 
0: [2025-10-29 08:11:49 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.11, #running-req: 146, #queue-req: 186, 
1: [2025-10-29 20:11:49 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 168, #queue-req: 173, 
1: [2025-10-29 20:11:49 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.11, #running-req: 138, #queue-req: 195, 
1: [2025-10-29 20:11:49 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.11, #running-req: 146, #queue-req: 186, 
1: [2025-10-29 20:11:49 DP0 TP0 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 17, token usage: 0.11, #running-req: 143, #queue-req: 210, 
0: [2025-10-29 08:11:49 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.11, #running-req: 164, #queue-req: 185, 
0: [2025-10-29 08:11:49 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 158, #queue-req: 173, 
0: [2025-10-29 08:11:49 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.11, #running-req: 142, #queue-req: 209, 
0: [2025-10-29 08:11:49 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.11, #running-req: 165, #queue-req: 193, 
1: [2025-10-29 20:11:49 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.11, #running-req: 164, #queue-req: 185, 
1: [2025-10-29 20:11:49 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.11, #running-req: 142, #queue-req: 209, 
1: [2025-10-29 20:11:49 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 158, #queue-req: 173, 
1: [2025-10-29 20:11:49 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.11, #running-req: 165, #queue-req: 193, 
0: [2025-10-29 08:11:49 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 168, #queue-req: 173, 
0: [2025-10-29 08:11:49 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 10, token usage: 0.11, #running-req: 139, #queue-req: 191, 
0: [2025-10-29 08:11:49 DP0 TP0 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 13, token usage: 0.11, #running-req: 147, #queue-req: 205, 
0: [2025-10-29 08:11:49 DP1 TP1 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 9, token usage: 0.11, #running-req: 149, #queue-req: 180, 
1: [2025-10-29 20:11:49 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 10, token usage: 0.11, #running-req: 139, #queue-req: 191, 
1: [2025-10-29 20:11:49 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 168, #queue-req: 173, 
1: [2025-10-29 20:11:49 DP1 TP1 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 9, token usage: 0.11, #running-req: 149, #queue-req: 180, 
1: [2025-10-29 20:11:49 DP0 TP0 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 13, token usage: 0.11, #running-req: 147, #queue-req: 205, 
0: [2025-10-29 08:11:49 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 167, #queue-req: 191, 
0: [2025-10-29 08:11:49 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.11, #running-req: 165, #queue-req: 177, 
0: [2025-10-29 08:11:49 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 158, #queue-req: 173, 
0: [2025-10-29 08:11:49 DP0 TP0 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 11, token usage: 0.11, #running-req: 143, #queue-req: 200, 
1: [2025-10-29 20:11:49 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 167, #queue-req: 191, 
1: [2025-10-29 20:11:49 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.11, #running-req: 165, #queue-req: 177, 
1: [2025-10-29 20:11:49 DP0 TP0 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 11, token usage: 0.11, #running-req: 143, #queue-req: 200, 
1: [2025-10-29 20:11:49 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 158, #queue-req: 173, 
0: [2025-10-29 08:11:49 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.12, #running-req: 151, #queue-req: 199, 
0: [2025-10-29 08:11:49 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.11, #running-req: 154, #queue-req: 175, 
0: [2025-10-29 08:11:49 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.11, #running-req: 141, #queue-req: 188, 
0: [2025-10-29 08:11:49 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 168, #queue-req: 173, 
1: [2025-10-29 20:11:49 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.12, #running-req: 151, #queue-req: 199, 
1: [2025-10-29 20:11:49 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.11, #running-req: 154, #queue-req: 175, 
1: [2025-10-29 20:11:49 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.11, #running-req: 141, #queue-req: 188, 
1: [2025-10-29 20:11:49 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.11, #running-req: 168, #queue-req: 173, 
0: [2025-10-29 08:11:49 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 9, token usage: 0.12, #running-req: 167, #queue-req: 187, 
0: [2025-10-29 08:11:49 DP0 TP0 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 11, token usage: 0.12, #running-req: 148, #queue-req: 194, 
0: [2025-10-29 08:11:49 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 13, token usage: 0.12, #running-req: 168, #queue-req: 171, 
0: [2025-10-29 08:11:49 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.12, #running-req: 158, #queue-req: 172, 
1: [2025-10-29 20:11:49 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 9, token usage: 0.12, #running-req: 167, #queue-req: 187, 
1: [2025-10-29 20:11:49 DP0 TP0 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 11, token usage: 0.12, #running-req: 148, #queue-req: 194, 
1: [2025-10-29 20:11:49 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 13, token usage: 0.12, #running-req: 168, #queue-req: 171, 
1: [2025-10-29 20:11:49 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.12, #running-req: 158, #queue-req: 172, 
0: [2025-10-29 08:11:49 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 168, #queue-req: 172, 
0: [2025-10-29 08:11:49 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.12, #running-req: 152, #queue-req: 193, 
0: [2025-10-29 08:11:49 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 156, #queue-req: 171, 
0: [2025-10-29 08:11:49 DP3 TP3 PP0] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 13, token usage: 0.12, #running-req: 144, #queue-req: 181, 
1: [2025-10-29 20:11:49 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 156, #queue-req: 171, 
1: [2025-10-29 20:11:49 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 168, #queue-req: 172, 
1: [2025-10-29 20:11:49 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.12, #running-req: 152, #queue-req: 193, 
1: [2025-10-29 20:11:49 DP3 TP3 PP1] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 13, token usage: 0.12, #running-req: 144, #queue-req: 181, 
0: [2025-10-29 08:11:49 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 10, token usage: 0.12, #running-req: 153, #queue-req: 191, 
0: [2025-10-29 08:11:49 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 168, #queue-req: 181, 
0: [2025-10-29 08:11:49 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.12, #running-req: 159, #queue-req: 171, 
0: [2025-10-29 08:11:49 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.12, #running-req: 172, #queue-req: 169, 
1: [2025-10-29 20:11:49 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 10, token usage: 0.12, #running-req: 153, #queue-req: 191, 
1: [2025-10-29 20:11:49 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.12, #running-req: 159, #queue-req: 171, 
1: [2025-10-29 20:11:49 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 168, #queue-req: 181, 
1: [2025-10-29 20:11:49 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.12, #running-req: 172, #queue-req: 169, 
0: [2025-10-29 08:11:49 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.12, #running-req: 156, #queue-req: 167, 
0: [2025-10-29 08:11:49 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 179, token usage: 0.12, #running-req: 168, #queue-req: 168, 
0: [2025-10-29 08:11:49 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.12, #running-req: 150, #queue-req: 178, 
0: [2025-10-29 08:11:49 DP0 TP0 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 11, token usage: 0.12, #running-req: 153, #queue-req: 187, 
1: [2025-10-29 20:11:49 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 179, token usage: 0.12, #running-req: 168, #queue-req: 168, 
1: [2025-10-29 20:11:49 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.12, #running-req: 156, #queue-req: 167, 
1: [2025-10-29 20:11:49 DP0 TP0 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 11, token usage: 0.12, #running-req: 153, #queue-req: 187, 
1: [2025-10-29 20:11:49 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.12, #running-req: 150, #queue-req: 178, 
0: [2025-10-29 08:11:49 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.12, #running-req: 168, #queue-req: 177, 
0: [2025-10-29 08:11:49 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.12, #running-req: 155, #queue-req: 185, 
0: [2025-10-29 08:11:49 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.12, #running-req: 174, #queue-req: 166, 
0: [2025-10-29 08:11:49 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.12, #running-req: 160, #queue-req: 165, 
1: [2025-10-29 20:11:49 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.12, #running-req: 168, #queue-req: 177, 
1: [2025-10-29 20:11:49 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.12, #running-req: 174, #queue-req: 166, 
1: [2025-10-29 20:11:49 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.12, #running-req: 155, #queue-req: 185, 
1: [2025-10-29 20:11:49 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.12, #running-req: 160, #queue-req: 165, 
0: [2025-10-29 08:11:49 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.12, #running-req: 153, #queue-req: 176, 
0: [2025-10-29 08:11:49 DP0 TP0 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 6, token usage: 0.12, #running-req: 157, #queue-req: 181, 
0: [2025-10-29 08:11:49 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 11, token usage: 0.12, #running-req: 158, #queue-req: 163, 
0: [2025-10-29 08:11:49 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 171, #queue-req: 165, 
1: [2025-10-29 20:11:49 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 11, token usage: 0.12, #running-req: 158, #queue-req: 163, 
1: [2025-10-29 20:11:49 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.12, #running-req: 153, #queue-req: 176, 
1: [2025-10-29 20:11:49 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 171, #queue-req: 165, 
1: [2025-10-29 20:11:49 DP0 TP0 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 6, token usage: 0.12, #running-req: 157, #queue-req: 181, 
0: [2025-10-29 08:11:49 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.12, #running-req: 157, #queue-req: 180, 
0: [2025-10-29 08:11:49 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.12, #running-req: 169, #queue-req: 175, 
0: [2025-10-29 08:11:49 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.12, #running-req: 163, #queue-req: 164, 
0: [2025-10-29 08:11:49 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.12, #running-req: 175, #queue-req: 159, 
1: [2025-10-29 20:11:50 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.12, #running-req: 157, #queue-req: 180, 
1: [2025-10-29 20:11:50 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.12, #running-req: 163, #queue-req: 164, 
1: [2025-10-29 20:11:50 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.12, #running-req: 175, #queue-req: 159, 
1: [2025-10-29 20:11:50 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.12, #running-req: 169, #queue-req: 175, 
0: [2025-10-29 08:11:50 DP2 TP2 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 7, token usage: 0.12, #running-req: 171, #queue-req: 159, 
0: [2025-10-29 08:11:50 DP0 TP0 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 14, token usage: 0.12, #running-req: 161, #queue-req: 176, 
0: [2025-10-29 08:11:50 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.12, #running-req: 161, #queue-req: 157, 
0: [2025-10-29 08:11:50 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.12, #running-req: 154, #queue-req: 173, 
1: [2025-10-29 20:11:50 DP2 TP2 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 7, token usage: 0.12, #running-req: 171, #queue-req: 159, 
1: [2025-10-29 20:11:50 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.12, #running-req: 161, #queue-req: 157, 
1: [2025-10-29 20:11:50 DP0 TP0 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 14, token usage: 0.12, #running-req: 161, #queue-req: 176, 
1: [2025-10-29 20:11:50 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.12, #running-req: 154, #queue-req: 173, 
0: [2025-10-29 08:11:50 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.12, #running-req: 158, #queue-req: 174, 
0: [2025-10-29 08:11:50 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.12, #running-req: 179, #queue-req: 155, 
0: [2025-10-29 08:11:50 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 170, #queue-req: 173, 
0: [2025-10-29 08:11:50 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.12, #running-req: 164, #queue-req: 156, 
1: [2025-10-29 20:11:50 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.12, #running-req: 179, #queue-req: 155, 
1: [2025-10-29 20:11:50 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 170, #queue-req: 173, 
1: [2025-10-29 20:11:50 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.12, #running-req: 158, #queue-req: 174, 
1: [2025-10-29 20:11:50 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.12, #running-req: 164, #queue-req: 156, 
0: [2025-10-29 08:11:50 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 156, #queue-req: 173, 
0: [2025-10-29 08:11:50 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.12, #running-req: 165, #queue-req: 173, 
0: [2025-10-29 08:11:50 DP2 TP2 PP0] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 18, token usage: 0.12, #running-req: 176, #queue-req: 149, 
0: [2025-10-29 08:11:50 DP1 TP1 PP0] Prefill batch. #new-seq: 10, #new-token: 512, #cached-token: 28, token usage: 0.12, #running-req: 163, #queue-req: 146, 
1: [2025-10-29 20:11:50 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 156, #queue-req: 173, 
1: [2025-10-29 20:11:50 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.12, #running-req: 165, #queue-req: 173, 
1: [2025-10-29 20:11:50 DP1 TP1 PP1] Prefill batch. #new-seq: 10, #new-token: 512, #cached-token: 28, token usage: 0.12, #running-req: 163, #queue-req: 146, 
1: [2025-10-29 20:11:50 DP2 TP2 PP1] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 18, token usage: 0.12, #running-req: 176, #queue-req: 149, 
0: [2025-10-29 08:11:50 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 170, #queue-req: 173, 
0: [2025-10-29 08:11:50 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 160, #queue-req: 173, 
0: [2025-10-29 08:11:50 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 181, #queue-req: 146, 
0: [2025-10-29 08:11:50 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.12, #running-req: 167, #queue-req: 146, 
1: [2025-10-29 20:11:50 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 170, #queue-req: 173, 
1: [2025-10-29 20:11:50 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 181, #queue-req: 146, 
1: [2025-10-29 20:11:50 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 160, #queue-req: 173, 
1: [2025-10-29 20:11:50 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.12, #running-req: 167, #queue-req: 146, 
0: [2025-10-29 08:11:50 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.12, #running-req: 156, #queue-req: 171, 
0: [2025-10-29 08:11:50 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 166, #queue-req: 173, 
0: [2025-10-29 08:11:50 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 172, #queue-req: 146, 
0: [2025-10-29 08:11:50 DP2 TP2 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 15, token usage: 0.12, #running-req: 183, #queue-req: 142, 
1: [2025-10-29 20:11:50 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 172, #queue-req: 146, 
1: [2025-10-29 20:11:50 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.12, #running-req: 156, #queue-req: 171, 
1: [2025-10-29 20:11:50 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 166, #queue-req: 173, 
1: [2025-10-29 20:11:50 DP2 TP2 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 15, token usage: 0.12, #running-req: 183, #queue-req: 142, 
0: [2025-10-29 08:11:50 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 170, #queue-req: 171, 
0: [2025-10-29 08:11:50 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.12, #running-req: 181, #queue-req: 145, 
0: [2025-10-29 08:11:50 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.12, #running-req: 160, #queue-req: 170, 
0: [2025-10-29 08:11:50 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 170, #queue-req: 142, 
1: [2025-10-29 20:11:50 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 170, #queue-req: 171, 
1: [2025-10-29 20:11:50 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.12, #running-req: 181, #queue-req: 145, 
1: [2025-10-29 20:11:50 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.12, #running-req: 160, #queue-req: 170, 
1: [2025-10-29 20:11:50 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 170, #queue-req: 142, 
0: [2025-10-29 08:11:50 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.12, #running-req: 172, #queue-req: 144, 
0: [2025-10-29 08:11:50 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.12, #running-req: 166, #queue-req: 167, 
0: [2025-10-29 08:11:50 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 158, #queue-req: 171, 
0: [2025-10-29 08:11:50 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.12, #running-req: 187, #queue-req: 140, 
1: [2025-10-29 20:11:50 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.12, #running-req: 172, #queue-req: 144, 
1: [2025-10-29 20:11:50 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.12, #running-req: 166, #queue-req: 167, 
1: [2025-10-29 20:11:50 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 158, #queue-req: 171, 
1: [2025-10-29 20:11:50 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.12, #running-req: 187, #queue-req: 140, 
0: [2025-10-29 08:11:50 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 170, #queue-req: 171, 
0: [2025-10-29 08:11:50 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 170, #queue-req: 140, 
0: [2025-10-29 08:11:50 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.12, #running-req: 163, #queue-req: 166, 
0: [2025-10-29 08:11:50 DP1 TP1 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 11, token usage: 0.12, #running-req: 182, #queue-req: 139, 
1: [2025-10-29 20:11:50 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 170, #queue-req: 140, 
1: [2025-10-29 20:11:50 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 170, #queue-req: 171, 
1: [2025-10-29 20:11:50 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.12, #running-req: 163, #queue-req: 166, 
1: [2025-10-29 20:11:50 DP1 TP1 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 11, token usage: 0.12, #running-req: 182, #queue-req: 139, 
0: [2025-10-29 08:11:50 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.12, #running-req: 158, #queue-req: 169, 
0: [2025-10-29 08:11:50 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 173, #queue-req: 139, 
0: [2025-10-29 08:11:50 DP0 TP0 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.12, #running-req: 169, #queue-req: 162, 
0: [2025-10-29 08:11:50 DP2 TP2 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 9, token usage: 0.12, #running-req: 189, #queue-req: 135, 
1: [2025-10-29 20:11:50 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 173, #queue-req: 139, 
1: [2025-10-29 20:11:50 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.12, #running-req: 158, #queue-req: 169, 
1: [2025-10-29 20:11:50 DP2 TP2 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 9, token usage: 0.12, #running-req: 189, #queue-req: 135, 
1: [2025-10-29 20:11:50 DP0 TP0 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.12, #running-req: 169, #queue-req: 162, 
0: [2025-10-29 08:11:50 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.12, #running-req: 170, #queue-req: 168, 
0: [2025-10-29 08:11:50 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 170, #queue-req: 135, 
0: [2025-10-29 08:11:50 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 187, #queue-req: 139, 
0: [2025-10-29 08:11:50 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.13, #running-req: 164, #queue-req: 161, 
1: [2025-10-29 20:11:50 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 170, #queue-req: 135, 
1: [2025-10-29 20:11:50 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.12, #running-req: 170, #queue-req: 168, 
1: [2025-10-29 20:11:50 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.12, #running-req: 187, #queue-req: 139, 
1: [2025-10-29 20:11:50 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.13, #running-req: 164, #queue-req: 161, 
0: [2025-10-29 08:11:50 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 173, #queue-req: 139, 
0: [2025-10-29 08:11:50 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 173, #queue-req: 161, 
0: [2025-10-29 08:11:50 DP3 TP3 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 19, token usage: 0.13, #running-req: 160, #queue-req: 164, 
0: [2025-10-29 08:11:50 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 3, token usage: 0.13, #running-req: 194, #queue-req: 132, 
1: [2025-10-29 20:11:50 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 173, #queue-req: 139, 
1: [2025-10-29 20:11:50 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 173, #queue-req: 161, 
1: [2025-10-29 20:11:50 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 3, token usage: 0.13, #running-req: 194, #queue-req: 132, 
1: [2025-10-29 20:11:50 DP3 TP3 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 19, token usage: 0.13, #running-req: 160, #queue-req: 164, 
0: [2025-10-29 08:11:50 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.13, #running-req: 187, #queue-req: 137, 
0: [2025-10-29 08:11:50 DP2 TP2 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 7, token usage: 0.13, #running-req: 170, #queue-req: 127, 
0: [2025-10-29 08:11:50 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 165, #queue-req: 161, 
0: [2025-10-29 08:11:50 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.13, #running-req: 171, #queue-req: 163, 
1: [2025-10-29 20:11:50 DP2 TP2 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 7, token usage: 0.13, #running-req: 170, #queue-req: 127, 
1: [2025-10-29 20:11:50 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 165, #queue-req: 161, 
1: [2025-10-29 20:11:50 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.13, #running-req: 171, #queue-req: 163, 
1: [2025-10-29 20:11:50 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.13, #running-req: 187, #queue-req: 137, 
0: [2025-10-29 08:11:50 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.13, #running-req: 173, #queue-req: 134, 
0: [2025-10-29 08:11:50 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 173, #queue-req: 161, 
0: [2025-10-29 08:11:50 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.13, #running-req: 197, #queue-req: 126, 
0: [2025-10-29 08:11:50 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.13, #running-req: 164, #queue-req: 160, 
1: [2025-10-29 20:11:50 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.13, #running-req: 173, #queue-req: 134, 
1: [2025-10-29 20:11:50 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.13, #running-req: 164, #queue-req: 160, 
1: [2025-10-29 20:11:50 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 173, #queue-req: 161, 
1: [2025-10-29 20:11:50 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.13, #running-req: 197, #queue-req: 126, 
0: [2025-10-29 08:11:50 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 165, #queue-req: 161, 
0: [2025-10-29 08:11:50 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.13, #running-req: 189, #queue-req: 133, 
0: [2025-10-29 08:11:50 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.13, #running-req: 172, #queue-req: 159, 
0: [2025-10-29 08:11:50 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 15, token usage: 0.13, #running-req: 175, #queue-req: 123, 
1: [2025-10-29 20:11:50 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 165, #queue-req: 161, 
1: [2025-10-29 20:11:50 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 15, token usage: 0.13, #running-req: 175, #queue-req: 123, 
1: [2025-10-29 20:11:50 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.13, #running-req: 189, #queue-req: 133, 
1: [2025-10-29 20:11:50 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.13, #running-req: 172, #queue-req: 159, 
0: [2025-10-29 08:11:50 DP0 TP0 PP0] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 17, token usage: 0.13, #running-req: 173, #queue-req: 155, 
0: [2025-10-29 08:11:50 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 10, token usage: 0.13, #running-req: 198, #queue-req: 122, 
0: [2025-10-29 08:11:50 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.13, #running-req: 167, #queue-req: 158, 
0: [2025-10-29 08:11:50 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.13, #running-req: 176, #queue-req: 131, 
1: [2025-10-29 20:11:50 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.13, #running-req: 176, #queue-req: 131, 
1: [2025-10-29 20:11:50 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 10, token usage: 0.13, #running-req: 198, #queue-req: 122, 
1: [2025-10-29 20:11:50 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.13, #running-req: 167, #queue-req: 158, 
1: [2025-10-29 20:11:50 DP0 TP0 PP1] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 17, token usage: 0.13, #running-req: 173, #queue-req: 155, 
0: [2025-10-29 08:11:50 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.13, #running-req: 165, #queue-req: 152, 
0: [2025-10-29 08:11:50 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 173, #queue-req: 158, 
0: [2025-10-29 08:11:50 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 178, #queue-req: 122, 
0: [2025-10-29 08:11:50 DP1 TP1 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 13, token usage: 0.13, #running-req: 190, #queue-req: 126, 
1: [2025-10-29 20:11:51 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.13, #running-req: 165, #queue-req: 152, 
1: [2025-10-29 20:11:51 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 178, #queue-req: 122, 
1: [2025-10-29 20:11:51 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 173, #queue-req: 158, 
1: [2025-10-29 20:11:51 DP1 TP1 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 13, token usage: 0.13, #running-req: 190, #queue-req: 126, 
0: [2025-10-29 08:11:51 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.13, #running-req: 179, #queue-req: 151, 
0: [2025-10-29 08:11:51 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 168, #queue-req: 158, 
0: [2025-10-29 08:11:51 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.13, #running-req: 178, #queue-req: 124, 
0: [2025-10-29 08:11:51 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.13, #running-req: 199, #queue-req: 121, 
1: [2025-10-29 20:11:51 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.13, #running-req: 179, #queue-req: 151, 
1: [2025-10-29 20:11:51 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.13, #running-req: 178, #queue-req: 124, 
1: [2025-10-29 20:11:51 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 168, #queue-req: 158, 
1: [2025-10-29 20:11:51 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.13, #running-req: 199, #queue-req: 121, 
0: [2025-10-29 08:11:51 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 173, #queue-req: 158, 
0: [2025-10-29 08:11:51 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.13, #running-req: 178, #queue-req: 119, 
0: [2025-10-29 08:11:51 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.13, #running-req: 168, #queue-req: 149, 
0: [2025-10-29 08:11:51 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 195, #queue-req: 124, 
1: [2025-10-29 20:11:51 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.13, #running-req: 178, #queue-req: 119, 
1: [2025-10-29 20:11:51 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 173, #queue-req: 158, 
1: [2025-10-29 20:11:51 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 195, #queue-req: 124, 
1: [2025-10-29 20:11:51 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.13, #running-req: 168, #queue-req: 149, 
0: [2025-10-29 08:11:51 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 168, #queue-req: 158, 
0: [2025-10-29 08:11:51 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 180, #queue-req: 149, 
0: [2025-10-29 08:11:51 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 200, #queue-req: 119, 
0: [2025-10-29 08:11:51 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.13, #running-req: 180, #queue-req: 123, 
1: [2025-10-29 20:11:51 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 168, #queue-req: 158, 
1: [2025-10-29 20:11:51 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.13, #running-req: 180, #queue-req: 123, 
1: [2025-10-29 20:11:51 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 180, #queue-req: 149, 
1: [2025-10-29 20:11:51 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 200, #queue-req: 119, 
0: [2025-10-29 08:11:51 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 10, token usage: 0.13, #running-req: 195, #queue-req: 119, 
0: [2025-10-29 08:11:51 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 173, #queue-req: 158, 
0: [2025-10-29 08:11:51 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 180, #queue-req: 119, 
0: [2025-10-29 08:11:51 DP0 TP0 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 14, token usage: 0.13, #running-req: 170, #queue-req: 144, 
1: [2025-10-29 20:11:51 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 10, token usage: 0.13, #running-req: 195, #queue-req: 119, 
1: [2025-10-29 20:11:51 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 180, #queue-req: 119, 
1: [2025-10-29 20:11:51 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 173, #queue-req: 158, 
1: [2025-10-29 20:11:51 DP0 TP0 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 14, token usage: 0.13, #running-req: 170, #queue-req: 144, 
0: [2025-10-29 08:11:51 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.13, #running-req: 180, #queue-req: 143, 
0: [2025-10-29 08:11:51 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 200, #queue-req: 119, 
0: [2025-10-29 08:11:51 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 9, token usage: 0.13, #running-req: 168, #queue-req: 156, 
0: [2025-10-29 08:11:51 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 181, #queue-req: 119, 
1: [2025-10-29 20:11:51 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 200, #queue-req: 119, 
1: [2025-10-29 20:11:51 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.13, #running-req: 180, #queue-req: 143, 
1: [2025-10-29 20:11:51 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 181, #queue-req: 119, 
1: [2025-10-29 20:11:51 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 9, token usage: 0.13, #running-req: 168, #queue-req: 156, 
0: [2025-10-29 08:11:51 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.13, #running-req: 173, #queue-req: 155, 
0: [2025-10-29 08:11:51 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 180, #queue-req: 119, 
0: [2025-10-29 08:11:51 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 175, #queue-req: 143, 
0: [2025-10-29 08:11:51 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 11, token usage: 0.13, #running-req: 199, #queue-req: 115, 
1: [2025-10-29 20:11:51 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.13, #running-req: 173, #queue-req: 155, 
1: [2025-10-29 20:11:51 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 180, #queue-req: 119, 
1: [2025-10-29 20:11:51 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 175, #queue-req: 143, 
1: [2025-10-29 20:11:51 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 11, token usage: 0.13, #running-req: 199, #queue-req: 115, 
0: [2025-10-29 08:11:51 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 181, #queue-req: 115, 
0: [2025-10-29 08:11:51 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.13, #running-req: 200, #queue-req: 118, 
0: [2025-10-29 08:11:51 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 170, #queue-req: 155, 
0: [2025-10-29 08:11:51 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.13, #running-req: 181, #queue-req: 141, 
1: [2025-10-29 20:11:51 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.13, #running-req: 200, #queue-req: 118, 
1: [2025-10-29 20:11:51 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.13, #running-req: 181, #queue-req: 141, 
1: [2025-10-29 20:11:51 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 181, #queue-req: 115, 
1: [2025-10-29 20:11:51 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 170, #queue-req: 155, 
0: [2025-10-29 08:11:51 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.13, #running-req: 175, #queue-req: 139, 
0: [2025-10-29 08:11:51 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 20, token usage: 0.13, #running-req: 180, #queue-req: 115, 
0: [2025-10-29 08:11:51 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 203, #queue-req: 115, 
0: [2025-10-29 08:11:51 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.13, #running-req: 174, #queue-req: 153, 
1: [2025-10-29 20:11:51 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.13, #running-req: 175, #queue-req: 139, 
1: [2025-10-29 20:11:51 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 20, token usage: 0.13, #running-req: 180, #queue-req: 115, 
1: [2025-10-29 20:11:51 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 203, #queue-req: 115, 
1: [2025-10-29 20:11:51 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.13, #running-req: 174, #queue-req: 153, 
0: [2025-10-29 08:11:51 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.13, #running-req: 181, #queue-req: 114, 
0: [2025-10-29 08:11:51 DP3 TP3 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.13, #running-req: 170, #queue-req: 149, 
0: [2025-10-29 08:11:51 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.13, #running-req: 183, #queue-req: 138, 
0: [2025-10-29 08:11:51 DP2 TP2 PP0] Prefill batch. #new-seq: 11, #new-token: 512, #cached-token: 27, token usage: 0.13, #running-req: 201, #queue-req: 105, 
1: [2025-10-29 20:11:51 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.13, #running-req: 181, #queue-req: 114, 
1: [2025-10-29 20:11:51 DP3 TP3 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.13, #running-req: 170, #queue-req: 149, 
1: [2025-10-29 20:11:51 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.13, #running-req: 183, #queue-req: 138, 
1: [2025-10-29 20:11:51 DP2 TP2 PP1] Prefill batch. #new-seq: 11, #new-token: 512, #cached-token: 27, token usage: 0.13, #running-req: 201, #queue-req: 105, 
0: [2025-10-29 08:11:51 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 7, token usage: 0.13, #running-req: 203, #queue-req: 110, 
0: [2025-10-29 08:11:51 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.13, #running-req: 177, #queue-req: 135, 
0: [2025-10-29 08:11:51 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 183, #queue-req: 105, 
0: [2025-10-29 08:11:51 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.13, #running-req: 176, #queue-req: 146, 
1: [2025-10-29 20:11:51 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 7, token usage: 0.13, #running-req: 203, #queue-req: 110, 
1: [2025-10-29 20:11:51 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.13, #running-req: 176, #queue-req: 146, 
1: [2025-10-29 20:11:51 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.13, #running-req: 183, #queue-req: 105, 
1: [2025-10-29 20:11:51 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.13, #running-req: 177, #queue-req: 135, 
0: [2025-10-29 08:11:51 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.14, #running-req: 184, #queue-req: 133, 
0: [2025-10-29 08:11:51 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 12, token usage: 0.13, #running-req: 182, #queue-req: 107, 
0: [2025-10-29 08:11:51 DP3 TP3 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 892, token usage: 0.13, #running-req: 174, #queue-req: 141, 
0: [2025-10-29 08:11:51 DP2 TP2 PP0] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 11, token usage: 0.13, #running-req: 211, #queue-req: 99, 
1: [2025-10-29 20:11:51 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 12, token usage: 0.13, #running-req: 182, #queue-req: 107, 
1: [2025-10-29 20:11:51 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.14, #running-req: 184, #queue-req: 133, 
1: [2025-10-29 20:11:51 DP3 TP3 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 892, token usage: 0.13, #running-req: 174, #queue-req: 141, 
1: [2025-10-29 20:11:51 DP2 TP2 PP1] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 11, token usage: 0.13, #running-req: 211, #queue-req: 99, 
0: [2025-10-29 08:11:51 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 183, #queue-req: 99, 
0: [2025-10-29 08:11:51 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 179, #queue-req: 141, 
0: [2025-10-29 08:11:51 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.14, #running-req: 207, #queue-req: 105, 
0: [2025-10-29 08:11:51 DP0 TP0 PP0] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 15, token usage: 0.14, #running-req: 180, #queue-req: 127, 
1: [2025-10-29 20:11:51 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 183, #queue-req: 99, 
1: [2025-10-29 20:11:51 DP0 TP0 PP1] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 15, token usage: 0.14, #running-req: 180, #queue-req: 127, 
1: [2025-10-29 20:11:51 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 179, #queue-req: 141, 
1: [2025-10-29 20:11:51 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.14, #running-req: 207, #queue-req: 105, 
0: [2025-10-29 08:11:51 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.14, #running-req: 179, #queue-req: 140, 
0: [2025-10-29 08:11:51 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 13, token usage: 0.14, #running-req: 186, #queue-req: 124, 
0: [2025-10-29 08:11:51 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.14, #running-req: 185, #queue-req: 104, 
0: [2025-10-29 08:11:51 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.14, #running-req: 217, #queue-req: 96, 
1: [2025-10-29 20:11:51 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.14, #running-req: 185, #queue-req: 104, 
1: [2025-10-29 20:11:51 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.14, #running-req: 179, #queue-req: 140, 
1: [2025-10-29 20:11:51 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 13, token usage: 0.14, #running-req: 186, #queue-req: 124, 
1: [2025-10-29 20:11:51 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.14, #running-req: 217, #queue-req: 96, 
0: [2025-10-29 08:11:51 DP3 TP3 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 15, token usage: 0.14, #running-req: 179, #queue-req: 135, 
0: [2025-10-29 08:11:51 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.14, #running-req: 183, #queue-req: 95, 
0: [2025-10-29 08:11:51 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.14, #running-req: 186, #queue-req: 123, 
0: [2025-10-29 08:11:51 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.14, #running-req: 209, #queue-req: 101, 
1: [2025-10-29 20:11:51 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.14, #running-req: 183, #queue-req: 95, 
1: [2025-10-29 20:11:51 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.14, #running-req: 186, #queue-req: 123, 
1: [2025-10-29 20:11:51 DP3 TP3 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 15, token usage: 0.14, #running-req: 179, #queue-req: 135, 
1: [2025-10-29 20:11:51 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.14, #running-req: 209, #queue-req: 101, 
0: [2025-10-29 08:11:51 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 186, #queue-req: 101, 
0: [2025-10-29 08:11:51 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.14, #running-req: 220, #queue-req: 93, 
0: [2025-10-29 08:11:51 DP3 TP3 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 14, token usage: 0.14, #running-req: 180, #queue-req: 130, 
0: [2025-10-29 08:11:51 DP0 TP0 PP0] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 515, token usage: 0.14, #running-req: 189, #queue-req: 117, 
1: [2025-10-29 20:11:51 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.14, #running-req: 220, #queue-req: 93, 
1: [2025-10-29 20:11:51 DP0 TP0 PP1] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 515, token usage: 0.14, #running-req: 189, #queue-req: 117, 
1: [2025-10-29 20:11:51 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 186, #queue-req: 101, 
1: [2025-10-29 20:11:51 DP3 TP3 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 14, token usage: 0.14, #running-req: 180, #queue-req: 130, 
0: [2025-10-29 08:11:51 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.14, #running-req: 187, #queue-req: 114, 
0: [2025-10-29 08:11:51 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.14, #running-req: 184, #queue-req: 92, 
0: [2025-10-29 08:11:51 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 212, #queue-req: 101, 
0: [2025-10-29 08:11:51 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.14, #running-req: 184, #queue-req: 128, 
1: [2025-10-29 20:11:52 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.14, #running-req: 184, #queue-req: 92, 
1: [2025-10-29 20:11:52 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.14, #running-req: 187, #queue-req: 114, 
1: [2025-10-29 20:11:52 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 212, #queue-req: 101, 
1: [2025-10-29 20:11:52 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.14, #running-req: 184, #queue-req: 128, 
0: [2025-10-29 08:11:52 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 186, #queue-req: 101, 
0: [2025-10-29 08:11:52 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.14, #running-req: 195, #queue-req: 113, 
0: [2025-10-29 08:11:52 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 185, #queue-req: 128, 
0: [2025-10-29 08:11:52 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.14, #running-req: 222, #queue-req: 91, 
1: [2025-10-29 20:11:52 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 186, #queue-req: 101, 
1: [2025-10-29 20:11:52 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 185, #queue-req: 128, 
1: [2025-10-29 20:11:52 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.14, #running-req: 195, #queue-req: 113, 
1: [2025-10-29 20:11:52 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.14, #running-req: 222, #queue-req: 91, 
0: [2025-10-29 08:11:52 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 212, #queue-req: 101, 
0: [2025-10-29 08:11:52 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 190, #queue-req: 113, 
0: [2025-10-29 08:11:52 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 186, #queue-req: 128, 
0: [2025-10-29 08:11:52 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.14, #running-req: 185, #queue-req: 90, 
1: [2025-10-29 20:11:52 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.14, #running-req: 185, #queue-req: 90, 
1: [2025-10-29 20:11:52 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 212, #queue-req: 101, 
1: [2025-10-29 20:11:52 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 190, #queue-req: 113, 
1: [2025-10-29 20:11:52 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 186, #queue-req: 128, 
0: [2025-10-29 08:11:52 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 185, #queue-req: 128, 
0: [2025-10-29 08:11:52 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.14, #running-req: 186, #queue-req: 100, 
0: [2025-10-29 08:11:52 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 196, #queue-req: 113, 
0: [2025-10-29 08:11:52 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.14, #running-req: 223, #queue-req: 89, 
1: [2025-10-29 20:11:52 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 185, #queue-req: 128, 
1: [2025-10-29 20:11:52 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.14, #running-req: 186, #queue-req: 100, 
1: [2025-10-29 20:11:52 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.14, #running-req: 223, #queue-req: 89, 
1: [2025-10-29 20:11:52 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 196, #queue-req: 113, 
0: [2025-10-29 08:11:52 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 212, #queue-req: 100, 
0: [2025-10-29 08:11:52 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 190, #queue-req: 113, 
0: [2025-10-29 08:11:52 DP3 TP3 PP0] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 11, token usage: 0.14, #running-req: 186, #queue-req: 121, 
0: [2025-10-29 08:11:52 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.14, #running-req: 186, #queue-req: 88, 
1: [2025-10-29 20:11:52 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 212, #queue-req: 100, 
1: [2025-10-29 20:11:52 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.14, #running-req: 186, #queue-req: 88, 
1: [2025-10-29 20:11:52 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 190, #queue-req: 113, 
1: [2025-10-29 20:11:52 DP3 TP3 PP1] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 11, token usage: 0.14, #running-req: 186, #queue-req: 121, 
0: [2025-10-29 08:11:52 DP3 TP3 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 11, token usage: 0.14, #running-req: 185, #queue-req: 116, 
0: [2025-10-29 08:11:52 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.14, #running-req: 196, #queue-req: 110, 
0: [2025-10-29 08:11:52 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.14, #running-req: 187, #queue-req: 98, 
0: [2025-10-29 08:11:52 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.14, #running-req: 224, #queue-req: 86, 
1: [2025-10-29 20:11:52 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.14, #running-req: 224, #queue-req: 86, 
1: [2025-10-29 20:11:52 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.14, #running-req: 196, #queue-req: 110, 
1: [2025-10-29 20:11:52 DP3 TP3 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 11, token usage: 0.14, #running-req: 185, #queue-req: 116, 
1: [2025-10-29 20:11:52 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.14, #running-req: 187, #queue-req: 98, 
0: [2025-10-29 08:11:52 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 190, #queue-req: 110, 
0: [2025-10-29 08:11:52 DP1 TP1 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 14, token usage: 0.14, #running-req: 212, #queue-req: 93, 
0: [2025-10-29 08:11:52 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.14, #running-req: 187, #queue-req: 84, 
0: [2025-10-29 08:11:52 DP3 TP3 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 6, token usage: 0.14, #running-req: 193, #queue-req: 111, 
1: [2025-10-29 20:11:52 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 190, #queue-req: 110, 
1: [2025-10-29 20:11:52 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.14, #running-req: 187, #queue-req: 84, 
1: [2025-10-29 20:11:52 DP1 TP1 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 14, token usage: 0.14, #running-req: 212, #queue-req: 93, 
1: [2025-10-29 20:11:52 DP3 TP3 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 6, token usage: 0.14, #running-req: 193, #queue-req: 111, 
0: [2025-10-29 08:11:52 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 190, #queue-req: 111, 
0: [2025-10-29 08:11:52 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.14, #running-req: 226, #queue-req: 83, 
0: [2025-10-29 08:11:52 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.14, #running-req: 189, #queue-req: 90, 
0: [2025-10-29 08:11:52 DP0 TP0 PP0] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 415, token usage: 0.14, #running-req: 199, #queue-req: 104, 
1: [2025-10-29 20:11:52 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.14, #running-req: 226, #queue-req: 83, 
1: [2025-10-29 20:11:52 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 190, #queue-req: 111, 
1: [2025-10-29 20:11:52 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.14, #running-req: 189, #queue-req: 90, 
1: [2025-10-29 20:11:52 DP0 TP0 PP1] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 415, token usage: 0.14, #running-req: 199, #queue-req: 104, 
0: [2025-10-29 08:11:52 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.14, #running-req: 190, #queue-req: 103, 
0: [2025-10-29 08:11:52 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.14, #running-req: 189, #queue-req: 82, 
0: [2025-10-29 08:11:52 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 198, #queue-req: 111, 
0: [2025-10-29 08:11:52 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.14, #running-req: 217, #queue-req: 86, 
1: [2025-10-29 20:11:52 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.14, #running-req: 190, #queue-req: 103, 
1: [2025-10-29 20:11:52 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.14, #running-req: 189, #queue-req: 82, 
1: [2025-10-29 20:11:52 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 198, #queue-req: 111, 
1: [2025-10-29 20:11:52 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.14, #running-req: 217, #queue-req: 86, 
0: [2025-10-29 08:11:52 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 190, #queue-req: 111, 
0: [2025-10-29 08:11:52 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.14, #running-req: 205, #queue-req: 102, 
0: [2025-10-29 08:11:52 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 227, #queue-req: 82, 
0: [2025-10-29 08:11:52 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.14, #running-req: 192, #queue-req: 85, 
1: [2025-10-29 20:11:52 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 190, #queue-req: 111, 
1: [2025-10-29 20:11:52 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.14, #running-req: 205, #queue-req: 102, 
1: [2025-10-29 20:11:52 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.14, #running-req: 192, #queue-req: 85, 
1: [2025-10-29 20:11:52 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 227, #queue-req: 82, 
0: [2025-10-29 08:11:52 DP3 TP3 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 14, token usage: 0.14, #running-req: 198, #queue-req: 107, 
0: [2025-10-29 08:11:52 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 191, #queue-req: 102, 
0: [2025-10-29 08:11:52 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.14, #running-req: 190, #queue-req: 81, 
0: [2025-10-29 08:11:52 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.14, #running-req: 221, #queue-req: 84, 
1: [2025-10-29 20:11:52 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.14, #running-req: 190, #queue-req: 81, 
1: [2025-10-29 20:11:52 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.14, #running-req: 191, #queue-req: 102, 
1: [2025-10-29 20:11:52 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.14, #running-req: 221, #queue-req: 84, 
1: [2025-10-29 20:11:52 DP3 TP3 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 14, token usage: 0.14, #running-req: 198, #queue-req: 107, 
0: [2025-10-29 08:11:52 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.14, #running-req: 190, #queue-req: 105, 
0: [2025-10-29 08:11:52 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.14, #running-req: 227, #queue-req: 78, 
0: [2025-10-29 08:11:52 DP0 TP0 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 832, token usage: 0.15, #running-req: 206, #queue-req: 98, 
0: [2025-10-29 08:11:52 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.14, #running-req: 193, #queue-req: 81, 
1: [2025-10-29 20:11:52 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.14, #running-req: 227, #queue-req: 78, 
1: [2025-10-29 20:11:52 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.14, #running-req: 190, #queue-req: 105, 
1: [2025-10-29 20:11:52 DP0 TP0 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 832, token usage: 0.15, #running-req: 206, #queue-req: 98, 
1: [2025-10-29 20:11:52 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.14, #running-req: 193, #queue-req: 81, 
0: [2025-10-29 08:11:52 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.15, #running-req: 191, #queue-req: 96, 
0: [2025-10-29 08:11:52 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 191, #queue-req: 78, 
0: [2025-10-29 08:11:52 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 202, #queue-req: 105, 
0: [2025-10-29 08:11:52 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.15, #running-req: 222, #queue-req: 79, 
1: [2025-10-29 20:11:52 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.15, #running-req: 191, #queue-req: 96, 
1: [2025-10-29 20:11:52 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 191, #queue-req: 78, 
1: [2025-10-29 20:11:52 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 202, #queue-req: 105, 
1: [2025-10-29 20:11:52 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.15, #running-req: 222, #queue-req: 79, 
0: [2025-10-29 08:11:52 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.15, #running-req: 210, #queue-req: 95, 
0: [2025-10-29 08:11:52 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.15, #running-req: 196, #queue-req: 78, 
0: [2025-10-29 08:11:52 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 230, #queue-req: 78, 
0: [2025-10-29 08:11:52 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.15, #running-req: 192, #queue-req: 103, 
1: [2025-10-29 20:11:52 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.15, #running-req: 210, #queue-req: 95, 
1: [2025-10-29 20:11:52 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.15, #running-req: 196, #queue-req: 78, 
1: [2025-10-29 20:11:52 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 230, #queue-req: 78, 
1: [2025-10-29 20:11:52 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.15, #running-req: 192, #queue-req: 103, 
0: [2025-10-29 08:11:52 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 191, #queue-req: 78, 
0: [2025-10-29 08:11:52 DP3 TP3 PP0] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 14, token usage: 0.15, #running-req: 202, #queue-req: 97, 
0: [2025-10-29 08:11:52 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 12, token usage: 0.15, #running-req: 193, #queue-req: 93, 
0: [2025-10-29 08:11:52 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.15, #running-req: 224, #queue-req: 74, 
1: [2025-10-29 20:11:52 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 191, #queue-req: 78, 
1: [2025-10-29 20:11:52 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 12, token usage: 0.15, #running-req: 193, #queue-req: 93, 
1: [2025-10-29 20:11:52 DP3 TP3 PP1] Prefill batch. #new-seq: 7, #new-token: 512, #cached-token: 14, token usage: 0.15, #running-req: 202, #queue-req: 97, 
1: [2025-10-29 20:11:52 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.15, #running-req: 224, #queue-req: 74, 
0: [2025-10-29 08:11:52 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.15, #running-req: 230, #queue-req: 77, 
0: [2025-10-29 08:11:52 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 211, #queue-req: 93, 
0: [2025-10-29 08:11:52 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 194, #queue-req: 97, 
0: [2025-10-29 08:11:52 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.15, #running-req: 197, #queue-req: 73, 
1: [2025-10-29 20:11:52 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.15, #running-req: 230, #queue-req: 77, 
1: [2025-10-29 20:11:52 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 211, #queue-req: 93, 
1: [2025-10-29 20:11:52 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.15, #running-req: 197, #queue-req: 73, 
1: [2025-10-29 20:11:52 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 194, #queue-req: 97, 
0: [2025-10-29 08:11:52 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.15, #running-req: 191, #queue-req: 75, 
0: [2025-10-29 08:11:52 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.15, #running-req: 195, #queue-req: 92, 
0: [2025-10-29 08:11:52 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 208, #queue-req: 97, 
0: [2025-10-29 08:11:52 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.15, #running-req: 228, #queue-req: 70, 
1: [2025-10-29 20:11:53 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.15, #running-req: 191, #queue-req: 75, 
1: [2025-10-29 20:11:53 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.15, #running-req: 195, #queue-req: 92, 
1: [2025-10-29 20:11:53 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 208, #queue-req: 97, 
1: [2025-10-29 20:11:53 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.15, #running-req: 228, #queue-req: 70, 
0: [2025-10-29 08:11:53 DP0 TP0 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 9, token usage: 0.15, #running-req: 211, #queue-req: 87, 
0: [2025-10-29 08:11:53 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 9, token usage: 0.15, #running-req: 194, #queue-req: 95, 
0: [2025-10-29 08:11:53 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.15, #running-req: 198, #queue-req: 69, 
0: [2025-10-29 08:11:53 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 9, token usage: 0.15, #running-req: 231, #queue-req: 73, 
1: [2025-10-29 20:11:53 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.15, #running-req: 198, #queue-req: 69, 
1: [2025-10-29 20:11:53 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 9, token usage: 0.15, #running-req: 194, #queue-req: 95, 
1: [2025-10-29 20:11:53 DP0 TP0 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 9, token usage: 0.15, #running-req: 211, #queue-req: 87, 
1: [2025-10-29 20:11:53 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 9, token usage: 0.15, #running-req: 231, #queue-req: 73, 
0: [2025-10-29 08:11:53 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 208, #queue-req: 95, 
0: [2025-10-29 08:11:53 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 11, token usage: 0.15, #running-req: 196, #queue-req: 85, 
0: [2025-10-29 08:11:53 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.15, #running-req: 193, #queue-req: 72, 
0: [2025-10-29 08:11:53 DP1 TP1 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 9, token usage: 0.15, #running-req: 231, #queue-req: 64, 
1: [2025-10-29 20:11:53 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 208, #queue-req: 95, 
1: [2025-10-29 20:11:53 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.15, #running-req: 193, #queue-req: 72, 
1: [2025-10-29 20:11:53 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 11, token usage: 0.15, #running-req: 196, #queue-req: 85, 
1: [2025-10-29 20:11:53 DP1 TP1 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 9, token usage: 0.15, #running-req: 231, #queue-req: 64, 
0: [2025-10-29 08:11:53 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.15, #running-req: 216, #queue-req: 84, 
0: [2025-10-29 08:11:53 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.15, #running-req: 196, #queue-req: 94, 
0: [2025-10-29 08:11:53 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.15, #running-req: 233, #queue-req: 71, 
0: [2025-10-29 08:11:53 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.15, #running-req: 199, #queue-req: 63, 
1: [2025-10-29 20:11:53 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.15, #running-req: 216, #queue-req: 84, 
1: [2025-10-29 20:11:53 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.15, #running-req: 233, #queue-req: 71, 
1: [2025-10-29 20:11:53 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.15, #running-req: 199, #queue-req: 63, 
1: [2025-10-29 20:11:53 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.15, #running-req: 196, #queue-req: 94, 
0: [2025-10-29 08:11:53 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.15, #running-req: 208, #queue-req: 93, 
0: [2025-10-29 08:11:53 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 198, #queue-req: 84, 
0: [2025-10-29 08:11:53 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 236, #queue-req: 63, 
0: [2025-10-29 08:11:53 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.15, #running-req: 194, #queue-req: 70, 
1: [2025-10-29 20:11:53 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.15, #running-req: 208, #queue-req: 93, 
1: [2025-10-29 20:11:53 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.15, #running-req: 194, #queue-req: 70, 
1: [2025-10-29 20:11:53 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 198, #queue-req: 84, 
1: [2025-10-29 20:11:53 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 236, #queue-req: 63, 
0: [2025-10-29 08:11:53 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 217, #queue-req: 84, 
0: [2025-10-29 08:11:53 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.15, #running-req: 197, #queue-req: 92, 
0: [2025-10-29 08:11:53 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 200, #queue-req: 63, 
0: [2025-10-29 08:11:53 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 234, #queue-req: 70, 
1: [2025-10-29 20:11:53 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 234, #queue-req: 70, 
1: [2025-10-29 20:11:53 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 217, #queue-req: 84, 
1: [2025-10-29 20:11:53 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.15, #running-req: 197, #queue-req: 92, 
1: [2025-10-29 20:11:53 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 200, #queue-req: 63, 
0: [2025-10-29 08:11:53 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 198, #queue-req: 84, 
0: [2025-10-29 08:11:53 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 236, #queue-req: 63, 
0: [2025-10-29 08:11:53 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.15, #running-req: 195, #queue-req: 69, 
0: [2025-10-29 08:11:53 DP3 TP3 PP0] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 17, token usage: 0.15, #running-req: 209, #queue-req: 85, 
1: [2025-10-29 20:11:53 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 198, #queue-req: 84, 
1: [2025-10-29 20:11:53 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.15, #running-req: 195, #queue-req: 69, 
1: [2025-10-29 20:11:53 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 236, #queue-req: 63, 
1: [2025-10-29 20:11:53 DP3 TP3 PP1] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 17, token usage: 0.15, #running-req: 209, #queue-req: 85, 
0: [2025-10-29 08:11:53 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.15, #running-req: 234, #queue-req: 67, 
0: [2025-10-29 08:11:53 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 200, #queue-req: 63, 
0: [2025-10-29 08:11:53 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.15, #running-req: 217, #queue-req: 81, 
0: [2025-10-29 08:11:53 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.15, #running-req: 198, #queue-req: 82, 
1: [2025-10-29 20:11:53 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 2, token usage: 0.15, #running-req: 234, #queue-req: 67, 
1: [2025-10-29 20:11:53 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.15, #running-req: 217, #queue-req: 81, 
1: [2025-10-29 20:11:53 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 200, #queue-req: 63, 
1: [2025-10-29 20:11:53 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.15, #running-req: 198, #queue-req: 82, 
0: [2025-10-29 08:11:53 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.15, #running-req: 198, #queue-req: 79, 
0: [2025-10-29 08:11:53 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 236, #queue-req: 63, 
0: [2025-10-29 08:11:53 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 196, #queue-req: 67, 
0: [2025-10-29 08:11:53 DP3 TP3 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 14, token usage: 0.15, #running-req: 216, #queue-req: 77, 
1: [2025-10-29 20:11:53 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.15, #running-req: 198, #queue-req: 79, 
1: [2025-10-29 20:11:53 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 196, #queue-req: 67, 
1: [2025-10-29 20:11:53 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 236, #queue-req: 63, 
1: [2025-10-29 20:11:53 DP3 TP3 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 14, token usage: 0.15, #running-req: 216, #queue-req: 77, 
0: [2025-10-29 08:11:53 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.15, #running-req: 220, #queue-req: 78, 
0: [2025-10-29 08:11:53 DP1 TP1 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 15, token usage: 0.15, #running-req: 200, #queue-req: 58, 
0: [2025-10-29 08:11:53 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.15, #running-req: 201, #queue-req: 76, 
0: [2025-10-29 08:11:53 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 236, #queue-req: 67, 
1: [2025-10-29 20:11:53 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.15, #running-req: 220, #queue-req: 78, 
1: [2025-10-29 20:11:53 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 236, #queue-req: 67, 
1: [2025-10-29 20:11:53 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.15, #running-req: 201, #queue-req: 76, 
1: [2025-10-29 20:11:53 DP1 TP1 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 15, token usage: 0.15, #running-req: 200, #queue-req: 58, 
0: [2025-10-29 08:11:53 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 196, #queue-req: 67, 
0: [2025-10-29 08:11:53 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.15, #running-req: 236, #queue-req: 55, 
0: [2025-10-29 08:11:53 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 221, #queue-req: 76, 
0: [2025-10-29 08:11:53 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.15, #running-req: 200, #queue-req: 75, 
1: [2025-10-29 20:11:53 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 196, #queue-req: 67, 
1: [2025-10-29 20:11:53 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.15, #running-req: 236, #queue-req: 55, 
1: [2025-10-29 20:11:53 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 221, #queue-req: 76, 
1: [2025-10-29 20:11:53 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 4, token usage: 0.15, #running-req: 200, #queue-req: 75, 
0: [2025-10-29 08:11:53 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 236, #queue-req: 67, 
0: [2025-10-29 08:11:53 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 205, #queue-req: 55, 
0: [2025-10-29 08:11:53 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.15, #running-req: 202, #queue-req: 74, 
0: [2025-10-29 08:11:53 DP0 TP0 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.15, #running-req: 221, #queue-req: 71, 
1: [2025-10-29 20:11:53 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 236, #queue-req: 67, 
1: [2025-10-29 20:11:53 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 205, #queue-req: 55, 
1: [2025-10-29 20:11:53 DP0 TP0 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 8, token usage: 0.15, #running-req: 221, #queue-req: 71, 
1: [2025-10-29 20:11:53 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.15, #running-req: 202, #queue-req: 74, 
0: [2025-10-29 08:11:53 DP3 TP3 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 9, token usage: 0.15, #running-req: 221, #queue-req: 70, 
0: [2025-10-29 08:11:53 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 196, #queue-req: 67, 
0: [2025-10-29 08:11:53 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.15, #running-req: 239, #queue-req: 54, 
0: [2025-10-29 08:11:53 DP0 TP0 PP0] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 22, token usage: 0.16, #running-req: 203, #queue-req: 64, 
1: [2025-10-29 20:11:53 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.15, #running-req: 239, #queue-req: 54, 
1: [2025-10-29 20:11:53 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.15, #running-req: 196, #queue-req: 67, 
1: [2025-10-29 20:11:53 DP3 TP3 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 9, token usage: 0.15, #running-req: 221, #queue-req: 70, 
1: [2025-10-29 20:11:53 DP0 TP0 PP1] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 22, token usage: 0.16, #running-req: 203, #queue-req: 64, 
0: [2025-10-29 08:11:53 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.16, #running-req: 205, #queue-req: 52, 
0: [2025-10-29 08:11:53 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 236, #queue-req: 67, 
0: [2025-10-29 08:11:53 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 10, token usage: 0.16, #running-req: 225, #queue-req: 62, 
0: [2025-10-29 08:11:53 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 204, #queue-req: 70, 
1: [2025-10-29 20:11:53 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.16, #running-req: 205, #queue-req: 52, 
1: [2025-10-29 20:11:53 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 204, #queue-req: 70, 
1: [2025-10-29 20:11:53 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 10, token usage: 0.16, #running-req: 225, #queue-req: 62, 
1: [2025-10-29 20:11:53 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 236, #queue-req: 67, 
0: [2025-10-29 08:11:53 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.16, #running-req: 210, #queue-req: 60, 
0: [2025-10-29 08:11:53 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 225, #queue-req: 70, 
0: [2025-10-29 08:11:53 DP2 TP2 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 9, token usage: 0.16, #running-req: 196, #queue-req: 63, 
0: [2025-10-29 08:11:53 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 16, token usage: 0.16, #running-req: 240, #queue-req: 48, 
1: [2025-10-29 20:11:53 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.16, #running-req: 210, #queue-req: 60, 
1: [2025-10-29 20:11:53 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 225, #queue-req: 70, 
1: [2025-10-29 20:11:53 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 16, token usage: 0.16, #running-req: 240, #queue-req: 48, 
1: [2025-10-29 20:11:53 DP2 TP2 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 9, token usage: 0.16, #running-req: 196, #queue-req: 63, 
0: [2025-10-29 08:11:53 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.16, #running-req: 236, #queue-req: 62, 
0: [2025-10-29 08:11:53 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 204, #queue-req: 70, 
0: [2025-10-29 08:11:53 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.16, #running-req: 227, #queue-req: 58, 
0: [2025-10-29 08:11:53 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 207, #queue-req: 48, 
1: [2025-10-29 20:11:54 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 204, #queue-req: 70, 
1: [2025-10-29 20:11:54 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 207, #queue-req: 48, 
1: [2025-10-29 20:11:54 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.16, #running-req: 236, #queue-req: 62, 
1: [2025-10-29 20:11:54 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.16, #running-req: 227, #queue-req: 58, 
0: [2025-10-29 08:11:54 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 225, #queue-req: 70, 
0: [2025-10-29 08:11:54 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.16, #running-req: 212, #queue-req: 55, 
0: [2025-10-29 08:11:54 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.16, #running-req: 244, #queue-req: 47, 
0: [2025-10-29 08:11:54 DP2 TP2 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 13, token usage: 0.16, #running-req: 200, #queue-req: 58, 
1: [2025-10-29 20:11:54 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 225, #queue-req: 70, 
1: [2025-10-29 20:11:54 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.16, #running-req: 244, #queue-req: 47, 
1: [2025-10-29 20:11:54 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 8, token usage: 0.16, #running-req: 212, #queue-req: 55, 
1: [2025-10-29 20:11:54 DP2 TP2 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 13, token usage: 0.16, #running-req: 200, #queue-req: 58, 
0: [2025-10-29 08:11:54 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.16, #running-req: 207, #queue-req: 46, 
0: [2025-10-29 08:11:54 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 204, #queue-req: 70, 
0: [2025-10-29 08:11:54 DP0 TP0 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 16, token usage: 0.16, #running-req: 229, #queue-req: 51, 
0: [2025-10-29 08:11:54 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 237, #queue-req: 58, 
1: [2025-10-29 20:11:54 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 6, token usage: 0.16, #running-req: 207, #queue-req: 46, 
1: [2025-10-29 20:11:54 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 204, #queue-req: 70, 
1: [2025-10-29 20:11:54 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 237, #queue-req: 58, 
1: [2025-10-29 20:11:54 DP0 TP0 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 16, token usage: 0.16, #running-req: 229, #queue-req: 51, 
0: [2025-10-29 08:11:54 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.16, #running-req: 225, #queue-req: 69, 
0: [2025-10-29 08:11:54 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.16, #running-req: 215, #queue-req: 50, 
0: [2025-10-29 08:11:54 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.16, #running-req: 245, #queue-req: 45, 
0: [2025-10-29 08:11:54 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.16, #running-req: 204, #queue-req: 56, 
1: [2025-10-29 20:11:54 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.16, #running-req: 215, #queue-req: 50, 
1: [2025-10-29 20:11:54 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.16, #running-req: 245, #queue-req: 45, 
1: [2025-10-29 20:11:54 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.16, #running-req: 204, #queue-req: 56, 
1: [2025-10-29 20:11:54 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.16, #running-req: 225, #queue-req: 69, 
0: [2025-10-29 08:11:54 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.16, #running-req: 204, #queue-req: 68, 
0: [2025-10-29 08:11:54 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.16, #running-req: 237, #queue-req: 54, 
0: [2025-10-29 08:11:54 DP0 TP0 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 10, token usage: 0.16, #running-req: 233, #queue-req: 46, 
0: [2025-10-29 08:11:54 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.16, #running-req: 208, #queue-req: 43, 
1: [2025-10-29 20:11:54 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.16, #running-req: 204, #queue-req: 68, 
1: [2025-10-29 20:11:54 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.16, #running-req: 237, #queue-req: 54, 
1: [2025-10-29 20:11:54 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.16, #running-req: 208, #queue-req: 43, 
1: [2025-10-29 20:11:54 DP0 TP0 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 10, token usage: 0.16, #running-req: 233, #queue-req: 46, 
0: [2025-10-29 08:11:54 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.16, #running-req: 206, #queue-req: 53, 
0: [2025-10-29 08:11:54 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 9, token usage: 0.16, #running-req: 216, #queue-req: 44, 
0: [2025-10-29 08:11:54 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 226, #queue-req: 68, 
0: [2025-10-29 08:11:54 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.16, #running-req: 246, #queue-req: 42, 
1: [2025-10-29 20:11:54 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.16, #running-req: 206, #queue-req: 53, 
1: [2025-10-29 20:11:54 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 9, token usage: 0.16, #running-req: 216, #queue-req: 44, 
1: [2025-10-29 20:11:54 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.16, #running-req: 246, #queue-req: 42, 
1: [2025-10-29 20:11:54 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 226, #queue-req: 68, 
0: [2025-10-29 08:11:54 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.16, #running-req: 237, #queue-req: 42, 
0: [2025-10-29 08:11:54 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.16, #running-req: 239, #queue-req: 52, 
0: [2025-10-29 08:11:54 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.16, #running-req: 210, #queue-req: 40, 
0: [2025-10-29 08:11:54 DP3 TP3 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 9, token usage: 0.16, #running-req: 205, #queue-req: 64, 
1: [2025-10-29 20:11:54 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.16, #running-req: 210, #queue-req: 40, 
1: [2025-10-29 20:11:54 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.16, #running-req: 239, #queue-req: 52, 
1: [2025-10-29 20:11:54 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.16, #running-req: 237, #queue-req: 42, 
1: [2025-10-29 20:11:54 DP3 TP3 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 9, token usage: 0.16, #running-req: 205, #queue-req: 64, 
0: [2025-10-29 08:11:54 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 226, #queue-req: 64, 
0: [2025-10-29 08:11:54 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.16, #running-req: 218, #queue-req: 40, 
0: [2025-10-29 08:11:54 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.16, #running-req: 247, #queue-req: 38, 
0: [2025-10-29 08:11:54 DP2 TP2 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 9, token usage: 0.16, #running-req: 207, #queue-req: 48, 
1: [2025-10-29 20:11:54 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 226, #queue-req: 64, 
1: [2025-10-29 20:11:54 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.16, #running-req: 218, #queue-req: 40, 
1: [2025-10-29 20:11:54 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.16, #running-req: 247, #queue-req: 38, 
1: [2025-10-29 20:11:54 DP2 TP2 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 9, token usage: 0.16, #running-req: 207, #queue-req: 48, 
0: [2025-10-29 08:11:54 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 209, #queue-req: 64, 
0: [2025-10-29 08:11:54 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.16, #running-req: 212, #queue-req: 36, 
0: [2025-10-29 08:11:54 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.16, #running-req: 239, #queue-req: 37, 
0: [2025-10-29 08:11:54 DP2 TP2 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 12, token usage: 0.16, #running-req: 240, #queue-req: 43, 
1: [2025-10-29 20:11:54 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.16, #running-req: 212, #queue-req: 36, 
1: [2025-10-29 20:11:54 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 209, #queue-req: 64, 
1: [2025-10-29 20:11:54 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.16, #running-req: 239, #queue-req: 37, 
1: [2025-10-29 20:11:54 DP2 TP2 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 12, token usage: 0.16, #running-req: 240, #queue-req: 43, 
0: [2025-10-29 08:11:54 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 226, #queue-req: 64, 
0: [2025-10-29 08:11:54 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 220, #queue-req: 37, 
0: [2025-10-29 08:11:54 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.16, #running-req: 249, #queue-req: 35, 
0: [2025-10-29 08:11:54 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 211, #queue-req: 43, 
1: [2025-10-29 20:11:54 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 226, #queue-req: 64, 
1: [2025-10-29 20:11:54 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.16, #running-req: 249, #queue-req: 35, 
1: [2025-10-29 20:11:54 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 220, #queue-req: 37, 
1: [2025-10-29 20:11:54 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 211, #queue-req: 43, 
0: [2025-10-29 08:11:54 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.16, #running-req: 209, #queue-req: 62, 
0: [2025-10-29 08:11:54 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 242, #queue-req: 37, 
0: [2025-10-29 08:11:54 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.16, #running-req: 245, #queue-req: 42, 
0: [2025-10-29 08:11:54 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.16, #running-req: 214, #queue-req: 32, 
1: [2025-10-29 20:11:54 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.16, #running-req: 214, #queue-req: 32, 
1: [2025-10-29 20:11:54 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.16, #running-req: 209, #queue-req: 62, 
1: [2025-10-29 20:11:54 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 242, #queue-req: 37, 
1: [2025-10-29 20:11:54 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.16, #running-req: 245, #queue-req: 42, 
0: [2025-10-29 08:11:54 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.16, #running-req: 226, #queue-req: 59, 
0: [2025-10-29 08:11:54 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 220, #queue-req: 37, 
0: [2025-10-29 08:11:54 DP2 TP2 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 9, token usage: 0.16, #running-req: 211, #queue-req: 38, 
0: [2025-10-29 08:11:54 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.16, #running-req: 250, #queue-req: 31, 
1: [2025-10-29 20:11:54 DP2 TP2 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 9, token usage: 0.16, #running-req: 211, #queue-req: 38, 
1: [2025-10-29 20:11:54 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 220, #queue-req: 37, 
1: [2025-10-29 20:11:54 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.16, #running-req: 226, #queue-req: 59, 
1: [2025-10-29 20:11:54 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.16, #running-req: 250, #queue-req: 31, 
0: [2025-10-29 08:11:54 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 242, #queue-req: 37, 
0: [2025-10-29 08:11:54 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 246, #queue-req: 38, 
0: [2025-10-29 08:11:54 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.16, #running-req: 211, #queue-req: 57, 
0: [2025-10-29 08:11:54 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 217, #queue-req: 31, 
1: [2025-10-29 20:11:54 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 246, #queue-req: 38, 
1: [2025-10-29 20:11:54 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 242, #queue-req: 37, 
1: [2025-10-29 20:11:54 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.16, #running-req: 211, #queue-req: 57, 
1: [2025-10-29 20:11:54 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.16, #running-req: 217, #queue-req: 31, 
0: [2025-10-29 08:11:54 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.17, #running-req: 220, #queue-req: 35, 
0: [2025-10-29 08:11:54 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.16, #running-req: 215, #queue-req: 37, 
0: [2025-10-29 08:11:54 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.16, #running-req: 229, #queue-req: 55, 
0: [2025-10-29 08:11:54 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.16, #running-req: 251, #queue-req: 30, 
1: [2025-10-29 20:11:54 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.16, #running-req: 215, #queue-req: 37, 
1: [2025-10-29 20:11:54 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 5, token usage: 0.17, #running-req: 220, #queue-req: 35, 
1: [2025-10-29 20:11:54 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.16, #running-req: 229, #queue-req: 55, 
1: [2025-10-29 20:11:54 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.16, #running-req: 251, #queue-req: 30, 
0: [2025-10-29 08:11:54 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 246, #queue-req: 37, 
0: [2025-10-29 08:11:54 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 217, #queue-req: 30, 
0: [2025-10-29 08:11:54 DP0 TP0 PP0] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 16, token usage: 0.17, #running-req: 242, #queue-req: 28, 
0: [2025-10-29 08:11:54 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 213, #queue-req: 55, 
1: [2025-10-29 20:11:54 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 246, #queue-req: 37, 
1: [2025-10-29 20:11:54 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 217, #queue-req: 30, 
1: [2025-10-29 20:11:54 DP0 TP0 PP1] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 16, token usage: 0.17, #running-req: 242, #queue-req: 28, 
1: [2025-10-29 20:11:54 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 213, #queue-req: 55, 
0: [2025-10-29 08:11:54 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 231, #queue-req: 55, 
0: [2025-10-29 08:11:54 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 252, #queue-req: 30, 
0: [2025-10-29 08:11:54 DP0 TP0 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 10, token usage: 0.17, #running-req: 222, #queue-req: 24, 
0: [2025-10-29 08:11:54 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.17, #running-req: 216, #queue-req: 35, 
1: [2025-10-29 20:11:54 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.17, #running-req: 216, #queue-req: 35, 
1: [2025-10-29 20:11:54 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 252, #queue-req: 30, 
1: [2025-10-29 20:11:54 DP0 TP0 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 10, token usage: 0.17, #running-req: 222, #queue-req: 24, 
1: [2025-10-29 20:11:54 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 231, #queue-req: 55, 
0: [2025-10-29 08:11:54 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 213, #queue-req: 55, 
0: [2025-10-29 08:11:54 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 217, #queue-req: 30, 
0: [2025-10-29 08:11:54 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.17, #running-req: 247, #queue-req: 34, 
0: [2025-10-29 08:11:54 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.17, #running-req: 249, #queue-req: 21, 
1: [2025-10-29 20:11:55 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.17, #running-req: 247, #queue-req: 34, 
1: [2025-10-29 20:11:55 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 213, #queue-req: 55, 
1: [2025-10-29 20:11:55 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 217, #queue-req: 30, 
1: [2025-10-29 20:11:55 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 7, token usage: 0.17, #running-req: 249, #queue-req: 21, 
0: [2025-10-29 08:11:55 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 231, #queue-req: 55, 
0: [2025-10-29 08:11:55 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 252, #queue-req: 30, 
0: [2025-10-29 08:11:55 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.17, #running-req: 226, #queue-req: 20, 
0: [2025-10-29 08:11:55 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 217, #queue-req: 34, 
1: [2025-10-29 20:11:55 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 217, #queue-req: 34, 
1: [2025-10-29 20:11:55 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 231, #queue-req: 55, 
1: [2025-10-29 20:11:55 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 252, #queue-req: 30, 
1: [2025-10-29 20:11:55 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.17, #running-req: 226, #queue-req: 20, 
0: [2025-10-29 08:11:55 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 217, #queue-req: 30, 
0: [2025-10-29 08:11:55 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 12, token usage: 0.17, #running-req: 213, #queue-req: 53, 
0: [2025-10-29 08:11:55 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.17, #running-req: 252, #queue-req: 17, 
0: [2025-10-29 08:11:55 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.17, #running-req: 248, #queue-req: 33, 
1: [2025-10-29 20:11:55 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.17, #running-req: 248, #queue-req: 33, 
1: [2025-10-29 20:11:55 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 5, token usage: 0.17, #running-req: 252, #queue-req: 17, 
1: [2025-10-29 20:11:55 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 217, #queue-req: 30, 
1: [2025-10-29 20:11:55 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 12, token usage: 0.17, #running-req: 213, #queue-req: 53, 
0: [2025-10-29 08:11:55 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 231, #queue-req: 53, 
0: [2025-10-29 08:11:55 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.17, #running-req: 217, #queue-req: 32, 
0: [2025-10-29 08:11:55 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 252, #queue-req: 30, 
0: [2025-10-29 08:11:55 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.17, #running-req: 227, #queue-req: 15, 
1: [2025-10-29 20:11:55 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.17, #running-req: 217, #queue-req: 32, 
1: [2025-10-29 20:11:55 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 231, #queue-req: 53, 
1: [2025-10-29 20:11:55 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.17, #running-req: 227, #queue-req: 15, 
1: [2025-10-29 20:11:55 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 252, #queue-req: 30, 
0: [2025-10-29 08:11:55 DP0 TP0 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.17, #running-req: 255, #queue-req: 14, 
0: [2025-10-29 08:11:55 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.17, #running-req: 217, #queue-req: 28, 
0: [2025-10-29 08:11:55 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.17, #running-req: 249, #queue-req: 31, 
0: [2025-10-29 08:11:55 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.17, #running-req: 215, #queue-req: 51, 
1: [2025-10-29 20:11:55 DP0 TP0 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.17, #running-req: 255, #queue-req: 14, 
1: [2025-10-29 20:11:55 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.17, #running-req: 249, #queue-req: 31, 
1: [2025-10-29 20:11:55 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.17, #running-req: 215, #queue-req: 51, 
1: [2025-10-29 20:11:55 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.17, #running-req: 217, #queue-req: 28, 
0: [2025-10-29 08:11:55 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 252, #queue-req: 28, 
0: [2025-10-29 08:11:55 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.17, #running-req: 231, #queue-req: 50, 
0: [2025-10-29 08:11:55 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.17, #running-req: 229, #queue-req: 12, 
0: [2025-10-29 08:11:55 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.17, #running-req: 218, #queue-req: 30, 
1: [2025-10-29 20:11:55 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.17, #running-req: 218, #queue-req: 30, 
1: [2025-10-29 20:11:55 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 252, #queue-req: 28, 
1: [2025-10-29 20:11:55 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.17, #running-req: 231, #queue-req: 50, 
1: [2025-10-29 20:11:55 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.17, #running-req: 229, #queue-req: 12, 
0: [2025-10-29 08:11:55 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 219, #queue-req: 28, 
0: [2025-10-29 08:11:55 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 250, #queue-req: 30, 
0: [2025-10-29 08:11:55 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.17, #running-req: 217, #queue-req: 48, 
0: [2025-10-29 08:11:55 DP0 TP0 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 8, token usage: 0.17, #running-req: 256, #queue-req: 7, 
1: [2025-10-29 20:11:55 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 250, #queue-req: 30, 
1: [2025-10-29 20:11:55 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 219, #queue-req: 28, 
1: [2025-10-29 20:11:55 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 8, token usage: 0.17, #running-req: 217, #queue-req: 48, 
1: [2025-10-29 20:11:55 DP0 TP0 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 8, token usage: 0.17, #running-req: 256, #queue-req: 7, 
0: [2025-10-29 08:11:55 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.17, #running-req: 252, #queue-req: 26, 
0: [2025-10-29 08:11:55 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 14, token usage: 0.17, #running-req: 231, #queue-req: 5, 
0: [2025-10-29 08:11:55 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.17, #running-req: 232, #queue-req: 46, 
0: [2025-10-29 08:11:55 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.17, #running-req: 219, #queue-req: 27, 
1: [2025-10-29 20:11:55 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.17, #running-req: 252, #queue-req: 26, 
1: [2025-10-29 20:11:55 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 14, token usage: 0.17, #running-req: 231, #queue-req: 5, 
1: [2025-10-29 20:11:55 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 3, token usage: 0.17, #running-req: 232, #queue-req: 46, 
1: [2025-10-29 20:11:55 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.17, #running-req: 219, #queue-req: 27, 
0: [2025-10-29 08:11:55 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.17, #running-req: 219, #queue-req: 25, 
0: [2025-10-29 08:11:55 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.17, #running-req: 250, #queue-req: 25, 
0: [2025-10-29 08:11:55 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.17, #running-req: 219, #queue-req: 45, 
0: [2025-10-29 08:11:55 DP0 TP0 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 11, token usage: 0.17, #running-req: 261, #queue-req: 2, 
1: [2025-10-29 20:11:55 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.17, #running-req: 219, #queue-req: 25, 
1: [2025-10-29 20:11:55 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.17, #running-req: 250, #queue-req: 25, 
1: [2025-10-29 20:11:55 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.17, #running-req: 219, #queue-req: 45, 
1: [2025-10-29 20:11:55 DP0 TP0 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 11, token usage: 0.17, #running-req: 261, #queue-req: 2, 
0: [2025-10-29 08:11:55 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 233, #queue-req: 2, 
0: [2025-10-29 08:11:55 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.17, #running-req: 234, #queue-req: 43, 
0: [2025-10-29 08:11:55 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.17, #running-req: 254, #queue-req: 23, 
0: [2025-10-29 08:11:55 DP2 TP2 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.17, #running-req: 222, #queue-req: 22, 
1: [2025-10-29 20:11:55 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 233, #queue-req: 2, 
1: [2025-10-29 20:11:55 DP2 TP2 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 10, token usage: 0.17, #running-req: 222, #queue-req: 22, 
1: [2025-10-29 20:11:55 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.17, #running-req: 234, #queue-req: 43, 
1: [2025-10-29 20:11:55 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.17, #running-req: 254, #queue-req: 23, 
0: [2025-10-29 08:11:55 DP0 TP0 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.17, #running-req: 264, #queue-req: 0, 
0: [2025-10-29 08:11:55 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.17, #running-req: 220, #queue-req: 21, 
0: [2025-10-29 08:11:55 DP3 TP3 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 11, token usage: 0.17, #running-req: 220, #queue-req: 39, 
0: [2025-10-29 08:11:55 DP2 TP2 PP0] Prefill batch. #new-seq: 9, #new-token: 512, #cached-token: 16, token usage: 0.17, #running-req: 252, #queue-req: 14, 
1: [2025-10-29 20:11:55 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.17, #running-req: 220, #queue-req: 21, 
1: [2025-10-29 20:11:55 DP3 TP3 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 11, token usage: 0.17, #running-req: 220, #queue-req: 39, 
1: [2025-10-29 20:11:55 DP0 TP0 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.17, #running-req: 264, #queue-req: 0, 
1: [2025-10-29 20:11:55 DP2 TP2 PP1] Prefill batch. #new-seq: 9, #new-token: 512, #cached-token: 16, token usage: 0.17, #running-req: 252, #queue-req: 14, 
0: [2025-10-29 08:11:55 DP0 TP0 PP0] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 0, token usage: 0.17, #running-req: 233, #queue-req: 0, 
0: [2025-10-29 08:11:55 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.17, #running-req: 236, #queue-req: 38, 
0: [2025-10-29 08:11:55 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.17, #running-req: 256, #queue-req: 20, 
0: [2025-10-29 08:11:55 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 225, #queue-req: 14, 
1: [2025-10-29 20:11:55 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.17, #running-req: 256, #queue-req: 20, 
1: [2025-10-29 20:11:55 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.17, #running-req: 236, #queue-req: 38, 
1: [2025-10-29 20:11:55 DP0 TP0 PP1] Prefill batch. #new-seq: 1, #new-token: 28, #cached-token: 0, token usage: 0.17, #running-req: 233, #queue-req: 0, 
1: [2025-10-29 20:11:55 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 225, #queue-req: 14, 
0: [2025-10-29 08:11:55 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.17, #running-req: 224, #queue-req: 37, 
0: [2025-10-29 08:11:55 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 260, #queue-req: 14, 
0: [2025-10-29 08:11:55 DP1 TP1 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 14, token usage: 0.17, #running-req: 222, #queue-req: 16, 
1: [2025-10-29 20:11:55 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.17, #running-req: 224, #queue-req: 37, 
1: [2025-10-29 20:11:55 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 260, #queue-req: 14, 
1: [2025-10-29 20:11:55 DP1 TP1 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 14, token usage: 0.17, #running-req: 222, #queue-req: 16, 
0: [2025-10-29 08:11:55 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 225, #queue-req: 14, 
0: [2025-10-29 08:11:55 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.17, #running-req: 237, #queue-req: 36, 
0: [2025-10-29 08:11:55 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 10, token usage: 0.17, #running-req: 257, #queue-req: 14, 
1: [2025-10-29 20:11:55 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 225, #queue-req: 14, 
1: [2025-10-29 20:11:55 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.17, #running-req: 237, #queue-req: 36, 
1: [2025-10-29 20:11:55 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 10, token usage: 0.17, #running-req: 257, #queue-req: 14, 
0: [2025-10-29 08:11:55 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 260, #queue-req: 14, 
0: [2025-10-29 08:11:55 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.17, #running-req: 225, #queue-req: 35, 
0: [2025-10-29 08:11:55 DP1 TP1 PP0] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 16, token usage: 0.17, #running-req: 226, #queue-req: 9, 
1: [2025-10-29 20:11:55 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.17, #running-req: 260, #queue-req: 14, 
1: [2025-10-29 20:11:55 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 7, token usage: 0.17, #running-req: 225, #queue-req: 35, 
1: [2025-10-29 20:11:55 DP1 TP1 PP1] Prefill batch. #new-seq: 6, #new-token: 512, #cached-token: 16, token usage: 0.17, #running-req: 226, #queue-req: 9, 
0: [2025-10-29 08:11:55 DP2 TP2 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 13, token usage: 0.18, #running-req: 225, #queue-req: 10, 
0: [2025-10-29 08:11:55 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.18, #running-req: 238, #queue-req: 34, 
0: [2025-10-29 08:11:55 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 259, #queue-req: 9, 
1: [2025-10-29 20:11:55 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 259, #queue-req: 9, 
1: [2025-10-29 20:11:55 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.18, #running-req: 238, #queue-req: 34, 
1: [2025-10-29 20:11:55 DP2 TP2 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 13, token usage: 0.18, #running-req: 225, #queue-req: 10, 
0: [2025-10-29 08:11:55 DP2 TP2 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.18, #running-req: 260, #queue-req: 9, 
0: [2025-10-29 08:11:55 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 231, #queue-req: 9, 
0: [2025-10-29 08:11:55 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 10, token usage: 0.18, #running-req: 226, #queue-req: 32, 
1: [2025-10-29 20:11:56 DP2 TP2 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 5, token usage: 0.18, #running-req: 260, #queue-req: 9, 
1: [2025-10-29 20:11:56 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 231, #queue-req: 9, 
1: [2025-10-29 20:11:56 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 10, token usage: 0.18, #running-req: 226, #queue-req: 32, 
0: [2025-10-29 08:11:56 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 259, #queue-req: 9, 
0: [2025-10-29 08:11:56 DP2 TP2 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 229, #queue-req: 9, 
0: [2025-10-29 08:11:56 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 239, #queue-req: 32, 
1: [2025-10-29 20:11:56 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 259, #queue-req: 9, 
1: [2025-10-29 20:11:56 DP2 TP2 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 229, #queue-req: 9, 
1: [2025-10-29 20:11:56 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 239, #queue-req: 32, 
0: [2025-10-29 08:11:56 DP1 TP1 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.18, #running-req: 231, #queue-req: 7, 
0: [2025-10-29 08:11:56 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.18, #running-req: 228, #queue-req: 29, 
0: [2025-10-29 08:11:56 DP2 TP2 PP0] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 13, token usage: 0.18, #running-req: 261, #queue-req: 2, 
1: [2025-10-29 20:11:57 DP1 TP1 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.18, #running-req: 231, #queue-req: 7, 
1: [2025-10-29 20:11:57 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 6, token usage: 0.18, #running-req: 228, #queue-req: 29, 
1: [2025-10-29 20:11:57 DP2 TP2 PP1] Prefill batch. #new-seq: 8, #new-token: 512, #cached-token: 13, token usage: 0.18, #running-req: 261, #queue-req: 2, 
0: [2025-10-29 08:11:57 DP2 TP2 PP0] Prefill batch. #new-seq: 3, #new-token: 442, #cached-token: 5, token usage: 0.18, #running-req: 229, #queue-req: 0, 
0: [2025-10-29 08:11:57 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 239, #queue-req: 29, 
0: [2025-10-29 08:11:57 DP1 TP1 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.18, #running-req: 259, #queue-req: 6, 
1: [2025-10-29 20:11:57 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 239, #queue-req: 29, 
1: [2025-10-29 20:11:57 DP2 TP2 PP1] Prefill batch. #new-seq: 3, #new-token: 442, #cached-token: 5, token usage: 0.18, #running-req: 229, #queue-req: 0, 
1: [2025-10-29 20:11:57 DP1 TP1 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.18, #running-req: 259, #queue-req: 6, 
0: [2025-10-29 08:11:57 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 233, #queue-req: 6, 
0: [2025-10-29 08:11:57 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 231, #queue-req: 29, 
1: [2025-10-29 20:11:57 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 233, #queue-req: 6, 
1: [2025-10-29 20:11:57 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 231, #queue-req: 29, 
0: [2025-10-29 08:11:57 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 239, #queue-req: 29, 
0: [2025-10-29 08:11:57 DP1 TP1 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 260, #queue-req: 6, 
1: [2025-10-29 20:11:57 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 239, #queue-req: 29, 
1: [2025-10-29 20:11:57 DP1 TP1 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 260, #queue-req: 6, 
0: [2025-10-29 08:11:57 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 231, #queue-req: 29, 
0: [2025-10-29 08:11:57 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.18, #running-req: 233, #queue-req: 3, 
0: [2025-10-29 08:11:57 DP0 TP0 PP0] Decode batch. #running-req: 225, #token: 137616, token usage: 0.16, cuda graph: False, gen throughput (token/s): 66.43, #queue-req: 0, 
1: [2025-10-29 20:11:57 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 231, #queue-req: 29, 
1: [2025-10-29 20:11:57 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 9, token usage: 0.18, #running-req: 233, #queue-req: 3, 
0: [2025-10-29 08:11:57 DP1 TP1 PP0] Prefill batch. #new-seq: 4, #new-token: 404, #cached-token: 7, token usage: 0.18, #running-req: 260, #queue-req: 0, 
0: [2025-10-29 08:11:57 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 239, #queue-req: 29, 
1: [2025-10-29 20:11:57 DP0 TP0 PP1] Decode batch. #running-req: 225, #token: 137616, token usage: 0.16, cuda graph: False, gen throughput (token/s): 66.30, #queue-req: 0, 
1: [2025-10-29 20:11:57 DP1 TP1 PP1] Prefill batch. #new-seq: 4, #new-token: 404, #cached-token: 7, token usage: 0.18, #running-req: 260, #queue-req: 0, 
1: [2025-10-29 20:11:57 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 239, #queue-req: 29, 
0: [2025-10-29 08:11:57 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.18, #running-req: 231, #queue-req: 28, 
1: [2025-10-29 20:11:57 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.18, #running-req: 231, #queue-req: 28, 
0: [2025-10-29 08:11:57 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.18, #running-req: 239, #queue-req: 26, 
1: [2025-10-29 20:11:58 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.18, #running-req: 239, #queue-req: 26, 
0: [2025-10-29 08:11:58 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.18, #running-req: 232, #queue-req: 24, 
1: [2025-10-29 20:11:58 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 6, token usage: 0.18, #running-req: 232, #queue-req: 24, 
0: [2025-10-29 08:11:58 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.18, #running-req: 241, #queue-req: 23, 
1: [2025-10-29 20:11:58 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.18, #running-req: 241, #queue-req: 23, 
0: [2025-10-29 08:11:58 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 234, #queue-req: 23, 
1: [2025-10-29 20:11:58 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 234, #queue-req: 23, 
0: [2025-10-29 08:11:58 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 242, #queue-req: 23, 
1: [2025-10-29 20:11:58 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 242, #queue-req: 23, 
0: [2025-10-29 08:11:58 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 234, #queue-req: 23, 
0: [2025-10-29 08:11:58 DP2 TP2 PP0] Decode batch. #running-req: 220, #token: 138101, token usage: 0.16, cuda graph: False, gen throughput (token/s): 65.28, #queue-req: 0, 
1: [2025-10-29 20:11:58 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.18, #running-req: 234, #queue-req: 23, 
0: [2025-10-29 08:11:58 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.18, #running-req: 242, #queue-req: 22, 
1: [2025-10-29 20:11:58 DP2 TP2 PP1] Decode batch. #running-req: 220, #token: 138101, token usage: 0.16, cuda graph: False, gen throughput (token/s): 65.18, #queue-req: 0, 
1: [2025-10-29 20:11:58 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.18, #running-req: 242, #queue-req: 22, 
0: [2025-10-29 08:11:58 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.19, #running-req: 234, #queue-req: 21, 
1: [2025-10-29 20:11:58 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.19, #running-req: 234, #queue-req: 21, 
0: [2025-10-29 08:11:58 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.19, #running-req: 243, #queue-req: 21, 
1: [2025-10-29 20:11:58 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.19, #running-req: 243, #queue-req: 21, 
0: [2025-10-29 08:11:58 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.19, #running-req: 235, #queue-req: 20, 
0: [2025-10-29 08:11:58 DP1 TP1 PP0] Decode batch. #running-req: 251, #token: 139378, token usage: 0.16, cuda graph: False, gen throughput (token/s): 64.92, #queue-req: 0, 
1: [2025-10-29 20:11:58 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.19, #running-req: 235, #queue-req: 20, 
0: [2025-10-29 08:11:58 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.19, #running-req: 243, #queue-req: 19, 
1: [2025-10-29 20:11:58 DP1 TP1 PP1] Decode batch. #running-req: 251, #token: 139378, token usage: 0.16, cuda graph: False, gen throughput (token/s): 64.82, #queue-req: 0, 
1: [2025-10-29 20:11:58 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 3, token usage: 0.19, #running-req: 243, #queue-req: 19, 
0: [2025-10-29 08:11:58 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 12, token usage: 0.19, #running-req: 236, #queue-req: 16, 
1: [2025-10-29 20:11:58 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 12, token usage: 0.19, #running-req: 236, #queue-req: 16, 
0: [2025-10-29 08:11:58 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.19, #running-req: 244, #queue-req: 14, 
1: [2025-10-29 20:11:58 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 7, token usage: 0.19, #running-req: 244, #queue-req: 14, 
0: [2025-10-29 08:11:58 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.19, #running-req: 239, #queue-req: 13, 
1: [2025-10-29 20:11:58 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 1, token usage: 0.19, #running-req: 239, #queue-req: 13, 
0: [2025-10-29 08:11:58 DP3 TP3 PP0] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 13, token usage: 0.19, #running-req: 246, #queue-req: 10, 
1: [2025-10-29 20:11:58 DP3 TP3 PP1] Prefill batch. #new-seq: 4, #new-token: 512, #cached-token: 13, token usage: 0.19, #running-req: 246, #queue-req: 10, 
0: [2025-10-29 08:11:58 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.19, #running-req: 240, #queue-req: 10, 
1: [2025-10-29 20:11:58 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.19, #running-req: 240, #queue-req: 10, 
0: [2025-10-29 08:11:58 DP3 TP3 PP0] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 7, token usage: 0.19, #running-req: 249, #queue-req: 6, 
1: [2025-10-29 20:11:58 DP3 TP3 PP1] Prefill batch. #new-seq: 5, #new-token: 512, #cached-token: 7, token usage: 0.19, #running-req: 249, #queue-req: 6, 
0: [2025-10-29 08:11:58 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.19, #running-req: 240, #queue-req: 6, 
1: [2025-10-29 20:11:59 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.19, #running-req: 240, #queue-req: 6, 
0: [2025-10-29 08:11:59 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.19, #running-req: 253, #queue-req: 6, 
1: [2025-10-29 20:11:59 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.19, #running-req: 253, #queue-req: 6, 
0: [2025-10-29 08:11:59 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.19, #running-req: 240, #queue-req: 5, 
1: [2025-10-29 20:11:59 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 4, token usage: 0.19, #running-req: 240, #queue-req: 5, 
0: [2025-10-29 08:11:59 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.19, #running-req: 253, #queue-req: 3, 
1: [2025-10-29 20:11:59 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 512, #cached-token: 4, token usage: 0.19, #running-req: 253, #queue-req: 3, 
0: [2025-10-29 08:11:59 DP3 TP3 PP0] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.19, #running-req: 241, #queue-req: 2, 
1: [2025-10-29 20:11:59 DP3 TP3 PP1] Prefill batch. #new-seq: 2, #new-token: 512, #cached-token: 2, token usage: 0.19, #running-req: 241, #queue-req: 2, 
0: [2025-10-29 08:11:59 DP3 TP3 PP0] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.19, #running-req: 255, #queue-req: 2, 
1: [2025-10-29 20:11:59 DP3 TP3 PP1] Prefill batch. #new-seq: 1, #new-token: 512, #cached-token: 0, token usage: 0.19, #running-req: 255, #queue-req: 2, 
0: [2025-10-29 08:11:59 DP3 TP3 PP0] Prefill batch. #new-seq: 3, #new-token: 456, #cached-token: 6, token usage: 0.20, #running-req: 242, #queue-req: 0, 
1: [2025-10-29 20:11:59 DP3 TP3 PP1] Prefill batch. #new-seq: 3, #new-token: 456, #cached-token: 6, token usage: 0.20, #running-req: 242, #queue-req: 0, 
0: [2025-10-29 08:11:59 DP3 TP3 PP0] Decode batch. #running-req: 232, #token: 154165, token usage: 0.18, cuda graph: True, gen throughput (token/s): 62.70, #queue-req: 0, 
1: [2025-10-29 20:11:59 DP3 TP3 PP1] Decode batch. #running-req: 232, #token: 154165, token usage: 0.18, cuda graph: True, gen throughput (token/s): 62.64, #queue-req: 0, 
0: [2025-10-29 08:11:59 DP0 TP0 PP0] Decode batch. #running-req: 173, #token: 103471, token usage: 0.12, cuda graph: True, gen throughput (token/s): 3919.15, #queue-req: 0, 
1: [2025-10-29 20:11:59 DP0 TP0 PP1] Decode batch. #running-req: 173, #token: 103471, token usage: 0.12, cuda graph: True, gen throughput (token/s): 3988.07, #queue-req: 0, 
0: [2025-10-29 08:12:00 DP2 TP2 PP0] Decode batch. #running-req: 163, #token: 100535, token usage: 0.12, cuda graph: True, gen throughput (token/s): 4396.87, #queue-req: 0, 
1: [2025-10-29 20:12:00 DP2 TP2 PP1] Decode batch. #running-req: 163, #token: 100535, token usage: 0.12, cuda graph: True, gen throughput (token/s): 4461.03, #queue-req: 0, 
0: [2025-10-29 08:12:00 DP1 TP1 PP0] Decode batch. #running-req: 194, #token: 99991, token usage: 0.12, cuda graph: True, gen throughput (token/s): 4788.42, #queue-req: 0, 
1: [2025-10-29 20:12:00 DP1 TP1 PP1] Decode batch. #running-req: 194, #token: 99991, token usage: 0.12, cuda graph: True, gen throughput (token/s): 4861.85, #queue-req: 0, 
0: [2025-10-29 08:12:01 DP3 TP3 PP0] Decode batch. #running-req: 173, #token: 118284, token usage: 0.14, cuda graph: True, gen throughput (token/s): 6612.96, #queue-req: 0, 
1: [2025-10-29 20:12:01 DP3 TP3 PP1] Decode batch. #running-req: 173, #token: 118284, token usage: 0.14, cuda graph: True, gen throughput (token/s): 6638.64, #queue-req: 0, 
0: [2025-10-29 08:12:01 DP0 TP0 PP0] Decode batch. #running-req: 145, #token: 91216, token usage: 0.11, cuda graph: True, gen throughput (token/s): 5325.96, #queue-req: 0, 
1: [2025-10-29 20:12:01 DP0 TP0 PP1] Decode batch. #running-req: 145, #token: 91216, token usage: 0.11, cuda graph: True, gen throughput (token/s): 5348.25, #queue-req: 0, 
0: [2025-10-29 08:12:01 DP2 TP2 PP0] Decode batch. #running-req: 142, #token: 89371, token usage: 0.11, cuda graph: True, gen throughput (token/s): 5505.11, #queue-req: 0, 
1: [2025-10-29 20:12:01 DP2 TP2 PP1] Decode batch. #running-req: 142, #token: 89371, token usage: 0.11, cuda graph: True, gen throughput (token/s): 5518.02, #queue-req: 0, 
0: [2025-10-29 08:12:01 DP1 TP1 PP0] Decode batch. #running-req: 173, #token: 85666, token usage: 0.10, cuda graph: True, gen throughput (token/s): 5846.13, #queue-req: 0, 
1: [2025-10-29 20:12:01 DP1 TP1 PP1] Decode batch. #running-req: 173, #token: 85666, token usage: 0.10, cuda graph: True, gen throughput (token/s): 5861.61, #queue-req: 0, 
0: [2025-10-29 08:12:02 DP3 TP3 PP0] Decode batch. #running-req: 158, #token: 109935, token usage: 0.13, cuda graph: True, gen throughput (token/s): 6086.74, #queue-req: 0, 
1: [2025-10-29 20:12:02 DP3 TP3 PP1] Decode batch. #running-req: 158, #token: 109935, token usage: 0.13, cuda graph: True, gen throughput (token/s): 6093.37, #queue-req: 0, 
0: [2025-10-29 08:12:02 DP0 TP0 PP0] Decode batch. #running-req: 136, #token: 91235, token usage: 0.11, cuda graph: True, gen throughput (token/s): 5088.38, #queue-req: 0, 
1: [2025-10-29 20:12:02 DP0 TP0 PP1] Decode batch. #running-req: 136, #token: 91235, token usage: 0.11, cuda graph: True, gen throughput (token/s): 5098.15, #queue-req: 0, 
0: [2025-10-29 08:12:02 DP2 TP2 PP0] Decode batch. #running-req: 136, #token: 88703, token usage: 0.10, cuda graph: True, gen throughput (token/s): 5337.62, #queue-req: 0, 
1: [2025-10-29 20:12:02 DP2 TP2 PP1] Decode batch. #running-req: 136, #token: 88703, token usage: 0.10, cuda graph: True, gen throughput (token/s): 5351.75, #queue-req: 0, 
0: [2025-10-29 08:12:02 DP1 TP1 PP0] Decode batch. #running-req: 160, #token: 86166, token usage: 0.10, cuda graph: True, gen throughput (token/s): 5697.98, #queue-req: 0, 
1: [2025-10-29 20:12:02 DP1 TP1 PP1] Decode batch. #running-req: 160, #token: 86166, token usage: 0.10, cuda graph: True, gen throughput (token/s): 5707.74, #queue-req: 0, 
0: [2025-10-29 08:12:03 DP3 TP3 PP0] Decode batch. #running-req: 146, #token: 107971, token usage: 0.13, cuda graph: True, gen throughput (token/s): 5888.69, #queue-req: 0, 
1: [2025-10-29 20:12:03 DP3 TP3 PP1] Decode batch. #running-req: 146, #token: 107971, token usage: 0.13, cuda graph: True, gen throughput (token/s): 5898.78, #queue-req: 0, 
0: [2025-10-29 08:12:03 DP0 TP0 PP0] Decode batch. #running-req: 127, #token: 87089, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4948.19, #queue-req: 0, 
1: [2025-10-29 20:12:03 DP0 TP0 PP1] Decode batch. #running-req: 127, #token: 87089, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4951.09, #queue-req: 0, 
0: [2025-10-29 08:12:03 DP2 TP2 PP0] Decode batch. #running-req: 130, #token: 88449, token usage: 0.10, cuda graph: True, gen throughput (token/s): 5339.08, #queue-req: 0, 
1: [2025-10-29 20:12:03 DP2 TP2 PP1] Decode batch. #running-req: 130, #token: 88449, token usage: 0.10, cuda graph: True, gen throughput (token/s): 5338.66, #queue-req: 0, 
0: [2025-10-29 08:12:03 DP1 TP1 PP0] Decode batch. #running-req: 152, #token: 83760, token usage: 0.10, cuda graph: True, gen throughput (token/s): 5674.23, #queue-req: 0, 
1: [2025-10-29 20:12:03 DP1 TP1 PP1] Decode batch. #running-req: 152, #token: 83760, token usage: 0.10, cuda graph: True, gen throughput (token/s): 5673.82, #queue-req: 0, 
0: [2025-10-29 08:12:04 DP3 TP3 PP0] Decode batch. #running-req: 142, #token: 104762, token usage: 0.12, cuda graph: True, gen throughput (token/s): 5590.05, #queue-req: 0, 
1: [2025-10-29 20:12:04 DP3 TP3 PP1] Decode batch. #running-req: 142, #token: 104762, token usage: 0.12, cuda graph: True, gen throughput (token/s): 5592.12, #queue-req: 0, 
0: [2025-10-29 08:12:04 DP0 TP0 PP0] Decode batch. #running-req: 120, #token: 86119, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4799.60, #queue-req: 0, 
1: [2025-10-29 20:12:04 DP0 TP0 PP1] Decode batch. #running-req: 120, #token: 86119, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4796.40, #queue-req: 0, 
0: [2025-10-29 08:12:04 DP2 TP2 PP0] Decode batch. #running-req: 122, #token: 86833, token usage: 0.10, cuda graph: True, gen throughput (token/s): 5143.11, #queue-req: 0, 
1: [2025-10-29 20:12:04 DP2 TP2 PP1] Decode batch. #running-req: 122, #token: 86833, token usage: 0.10, cuda graph: True, gen throughput (token/s): 5145.70, #queue-req: 0, 
0: [2025-10-29 08:12:04 DP1 TP1 PP0] Decode batch. #running-req: 140, #token: 84443, token usage: 0.10, cuda graph: True, gen throughput (token/s): 5483.80, #queue-req: 0, 
1: [2025-10-29 20:12:04 DP1 TP1 PP1] Decode batch. #running-req: 140, #token: 84443, token usage: 0.10, cuda graph: True, gen throughput (token/s): 5487.03, #queue-req: 0, 
0: [2025-10-29 08:12:05 DP3 TP3 PP0] Decode batch. #running-req: 136, #token: 106047, token usage: 0.12, cuda graph: True, gen throughput (token/s): 5236.57, #queue-req: 0, 
1: [2025-10-29 20:12:05 DP3 TP3 PP1] Decode batch. #running-req: 136, #token: 106047, token usage: 0.12, cuda graph: True, gen throughput (token/s): 5241.63, #queue-req: 0, 
0: [2025-10-29 08:12:05 DP0 TP0 PP0] Decode batch. #running-req: 113, #token: 88181, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4681.26, #queue-req: 0, 
1: [2025-10-29 20:12:05 DP0 TP0 PP1] Decode batch. #running-req: 113, #token: 88181, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4686.71, #queue-req: 0, 
0: [2025-10-29 08:12:05 DP2 TP2 PP0] Decode batch. #running-req: 115, #token: 87723, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4936.11, #queue-req: 0, 
1: [2025-10-29 20:12:05 DP2 TP2 PP1] Decode batch. #running-req: 115, #token: 87723, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4937.60, #queue-req: 0, 
0: [2025-10-29 08:12:05 DP1 TP1 PP0] Decode batch. #running-req: 134, #token: 80708, token usage: 0.09, cuda graph: True, gen throughput (token/s): 5238.04, #queue-req: 0, 
1: [2025-10-29 20:12:05 DP1 TP1 PP1] Decode batch. #running-req: 134, #token: 80708, token usage: 0.09, cuda graph: True, gen throughput (token/s): 5240.77, #queue-req: 0, 
0: [2025-10-29 08:12:06 DP3 TP3 PP0] Decode batch. #running-req: 126, #token: 106883, token usage: 0.13, cuda graph: True, gen throughput (token/s): 5186.16, #queue-req: 0, 
1: [2025-10-29 20:12:06 DP3 TP3 PP1] Decode batch. #running-req: 126, #token: 106883, token usage: 0.13, cuda graph: True, gen throughput (token/s): 5197.66, #queue-req: 0, 
0: [2025-10-29 08:12:06 DP0 TP0 PP0] Decode batch. #running-req: 105, #token: 89567, token usage: 0.11, cuda graph: True, gen throughput (token/s): 4595.13, #queue-req: 0, 
1: [2025-10-29 20:12:06 DP0 TP0 PP1] Decode batch. #running-req: 105, #token: 89567, token usage: 0.11, cuda graph: True, gen throughput (token/s): 4607.61, #queue-req: 0, 
0: [2025-10-29 08:12:06 DP2 TP2 PP0] Decode batch. #running-req: 108, #token: 88546, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4913.94, #queue-req: 0, 
1: [2025-10-29 20:12:06 DP2 TP2 PP1] Decode batch. #running-req: 108, #token: 88546, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4924.04, #queue-req: 0, 
0: [2025-10-29 08:12:06 DP1 TP1 PP0] Decode batch. #running-req: 124, #token: 80267, token usage: 0.09, cuda graph: True, gen throughput (token/s): 5220.60, #queue-req: 0, 
1: [2025-10-29 20:12:06 DP1 TP1 PP1] Decode batch. #running-req: 124, #token: 80267, token usage: 0.09, cuda graph: True, gen throughput (token/s): 5234.79, #queue-req: 0, 
0: [2025-10-29 08:12:07 DP3 TP3 PP0] Decode batch. #running-req: 122, #token: 104884, token usage: 0.12, cuda graph: True, gen throughput (token/s): 5212.56, #queue-req: 0, 
1: [2025-10-29 20:12:07 DP3 TP3 PP1] Decode batch. #running-req: 122, #token: 104884, token usage: 0.12, cuda graph: True, gen throughput (token/s): 5213.24, #queue-req: 0, 
0: [2025-10-29 08:12:07 DP0 TP0 PP0] Decode batch. #running-req: 100, #token: 90950, token usage: 0.11, cuda graph: True, gen throughput (token/s): 4673.64, #queue-req: 0, 
1: [2025-10-29 20:12:07 DP0 TP0 PP1] Decode batch. #running-req: 100, #token: 90950, token usage: 0.11, cuda graph: True, gen throughput (token/s): 4673.45, #queue-req: 0, 
0: [2025-10-29 08:12:07 DP2 TP2 PP0] Decode batch. #running-req: 99, #token: 84549, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4864.72, #queue-req: 0, 
1: [2025-10-29 20:12:07 DP2 TP2 PP1] Decode batch. #running-req: 99, #token: 84549, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4869.66, #queue-req: 0, 
0: [2025-10-29 08:12:07 DP1 TP1 PP0] Decode batch. #running-req: 117, #token: 78964, token usage: 0.09, cuda graph: True, gen throughput (token/s): 5126.97, #queue-req: 0, 
1: [2025-10-29 20:12:07 DP1 TP1 PP1] Decode batch. #running-req: 117, #token: 78964, token usage: 0.09, cuda graph: True, gen throughput (token/s): 5128.19, #queue-req: 0, 
0: [2025-10-29 08:12:08 DP3 TP3 PP0] Decode batch. #running-req: 116, #token: 104624, token usage: 0.12, cuda graph: True, gen throughput (token/s): 5153.46, #queue-req: 0, 
1: [2025-10-29 20:12:08 DP3 TP3 PP1] Decode batch. #running-req: 116, #token: 104624, token usage: 0.12, cuda graph: True, gen throughput (token/s): 5155.55, #queue-req: 0, 
0: [2025-10-29 08:12:08 DP0 TP0 PP0] Decode batch. #running-req: 94, #token: 89092, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4479.04, #queue-req: 0, 
1: [2025-10-29 20:12:08 DP0 TP0 PP1] Decode batch. #running-req: 94, #token: 89092, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4482.23, #queue-req: 0, 
0: [2025-10-29 08:12:08 DP2 TP2 PP0] Decode batch. #running-req: 93, #token: 82921, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4732.96, #queue-req: 0, 
1: [2025-10-29 20:12:08 DP2 TP2 PP1] Decode batch. #running-req: 93, #token: 82921, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4733.52, #queue-req: 0, 
0: [2025-10-29 08:12:08 DP1 TP1 PP0] Decode batch. #running-req: 110, #token: 77920, token usage: 0.09, cuda graph: True, gen throughput (token/s): 4910.96, #queue-req: 0, 
1: [2025-10-29 20:12:08 DP1 TP1 PP1] Decode batch. #running-req: 110, #token: 77920, token usage: 0.09, cuda graph: True, gen throughput (token/s): 4911.48, #queue-req: 0, 
0: [2025-10-29 08:12:08 DP3 TP3 PP0] Decode batch. #running-req: 109, #token: 102829, token usage: 0.12, cuda graph: True, gen throughput (token/s): 5220.97, #queue-req: 0, 
1: [2025-10-29 20:12:08 DP3 TP3 PP1] Decode batch. #running-req: 109, #token: 102829, token usage: 0.12, cuda graph: True, gen throughput (token/s): 5230.45, #queue-req: 0, 
0: [2025-10-29 08:12:08 DP0 TP0 PP0] Decode batch. #running-req: 86, #token: 86917, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4481.55, #queue-req: 0, 
1: [2025-10-29 20:12:08 DP0 TP0 PP1] Decode batch. #running-req: 86, #token: 86917, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4485.78, #queue-req: 0, 
0: [2025-10-29 08:12:09 DP2 TP2 PP0] Decode batch. #running-req: 86, #token: 79973, token usage: 0.09, cuda graph: True, gen throughput (token/s): 4583.85, #queue-req: 0, 
1: [2025-10-29 20:12:09 DP2 TP2 PP1] Decode batch. #running-req: 86, #token: 79973, token usage: 0.09, cuda graph: True, gen throughput (token/s): 4592.15, #queue-req: 0, 
0: [2025-10-29 08:12:09 DP1 TP1 PP0] Decode batch. #running-req: 103, #token: 77674, token usage: 0.09, cuda graph: True, gen throughput (token/s): 4863.43, #queue-req: 0, 
1: [2025-10-29 20:12:09 DP1 TP1 PP1] Decode batch. #running-req: 103, #token: 77674, token usage: 0.09, cuda graph: True, gen throughput (token/s): 4873.45, #queue-req: 0, 
0: [2025-10-29 08:12:09 DP3 TP3 PP0] Decode batch. #running-req: 100, #token: 98836, token usage: 0.12, cuda graph: True, gen throughput (token/s): 5077.16, #queue-req: 0, 
1: [2025-10-29 20:12:09 DP3 TP3 PP1] Decode batch. #running-req: 100, #token: 98836, token usage: 0.12, cuda graph: True, gen throughput (token/s): 5080.65, #queue-req: 0, 
0: [2025-10-29 08:12:09 DP0 TP0 PP0] Decode batch. #running-req: 81, #token: 87858, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4367.02, #queue-req: 0, 
1: [2025-10-29 20:12:09 DP0 TP0 PP1] Decode batch. #running-req: 81, #token: 87858, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4372.60, #queue-req: 0, 
0: [2025-10-29 08:12:09 DP2 TP2 PP0] Decode batch. #running-req: 81, #token: 79431, token usage: 0.09, cuda graph: True, gen throughput (token/s): 4403.05, #queue-req: 0, 
1: [2025-10-29 20:12:09 DP2 TP2 PP1] Decode batch. #running-req: 81, #token: 79431, token usage: 0.09, cuda graph: True, gen throughput (token/s): 4405.14, #queue-req: 0, 
0: [2025-10-29 08:12:09 DP1 TP1 PP0] Decode batch. #running-req: 96, #token: 79154, token usage: 0.09, cuda graph: True, gen throughput (token/s): 4764.04, #queue-req: 0, 
1: [2025-10-29 20:12:09 DP1 TP1 PP1] Decode batch. #running-req: 96, #token: 79154, token usage: 0.09, cuda graph: True, gen throughput (token/s): 4765.11, #queue-req: 0, 
0: [2025-10-29 08:12:10 DP3 TP3 PP0] Decode batch. #running-req: 97, #token: 100258, token usage: 0.12, cuda graph: True, gen throughput (token/s): 4859.48, #queue-req: 0, 
1: [2025-10-29 20:12:10 DP3 TP3 PP1] Decode batch. #running-req: 97, #token: 100258, token usage: 0.12, cuda graph: True, gen throughput (token/s): 4863.16, #queue-req: 0, 
0: [2025-10-29 08:12:10 DP0 TP0 PP0] Decode batch. #running-req: 75, #token: 83719, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4212.51, #queue-req: 0, 
1: [2025-10-29 20:12:10 DP0 TP0 PP1] Decode batch. #running-req: 75, #token: 83719, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4214.32, #queue-req: 0, 
0: [2025-10-29 08:12:10 DP2 TP2 PP0] Decode batch. #running-req: 75, #token: 79237, token usage: 0.09, cuda graph: True, gen throughput (token/s): 4204.55, #queue-req: 0, 
1: [2025-10-29 20:12:10 DP2 TP2 PP1] Decode batch. #running-req: 75, #token: 79237, token usage: 0.09, cuda graph: True, gen throughput (token/s): 4204.72, #queue-req: 0, 
0: [2025-10-29 08:12:10 DP1 TP1 PP0] Decode batch. #running-req: 91, #token: 76152, token usage: 0.09, cuda graph: True, gen throughput (token/s): 4526.96, #queue-req: 0, 
1: [2025-10-29 20:12:10 DP1 TP1 PP1] Decode batch. #running-req: 91, #token: 76152, token usage: 0.09, cuda graph: True, gen throughput (token/s): 4530.25, #queue-req: 0, 
0: [2025-10-29 08:12:11 DP3 TP3 PP0] Decode batch. #running-req: 86, #token: 96164, token usage: 0.11, cuda graph: True, gen throughput (token/s): 4589.75, #queue-req: 0, 
1: [2025-10-29 20:12:11 DP3 TP3 PP1] Decode batch. #running-req: 86, #token: 96164, token usage: 0.11, cuda graph: True, gen throughput (token/s): 4589.57, #queue-req: 0, 
0: [2025-10-29 08:12:11 DP0 TP0 PP0] Decode batch. #running-req: 68, #token: 81175, token usage: 0.10, cuda graph: True, gen throughput (token/s): 3969.40, #queue-req: 0, 
1: [2025-10-29 20:12:11 DP0 TP0 PP1] Decode batch. #running-req: 68, #token: 81175, token usage: 0.10, cuda graph: True, gen throughput (token/s): 3969.75, #queue-req: 0, 
0: [2025-10-29 08:12:11 DP2 TP2 PP0] Decode batch. #running-req: 65, #token: 74747, token usage: 0.09, cuda graph: True, gen throughput (token/s): 3900.90, #queue-req: 0, 
1: [2025-10-29 20:12:11 DP2 TP2 PP1] Decode batch. #running-req: 65, #token: 74747, token usage: 0.09, cuda graph: True, gen throughput (token/s): 3905.07, #queue-req: 0, 
0: [2025-10-29 08:12:11 DP1 TP1 PP0] Decode batch. #running-req: 83, #token: 73772, token usage: 0.09, cuda graph: True, gen throughput (token/s): 4317.25, #queue-req: 0, 
1: [2025-10-29 20:12:11 DP1 TP1 PP1] Decode batch. #running-req: 83, #token: 73772, token usage: 0.09, cuda graph: True, gen throughput (token/s): 4316.84, #queue-req: 0, 
0: [2025-10-29 08:12:12 DP3 TP3 PP0] Decode batch. #running-req: 81, #token: 93439, token usage: 0.11, cuda graph: True, gen throughput (token/s): 4273.25, #queue-req: 0, 
1: [2025-10-29 20:12:12 DP3 TP3 PP1] Decode batch. #running-req: 81, #token: 93439, token usage: 0.11, cuda graph: True, gen throughput (token/s): 4277.45, #queue-req: 0, 
0: [2025-10-29 08:12:12 DP0 TP0 PP0] Decode batch. #running-req: 68, #token: 82244, token usage: 0.10, cuda graph: True, gen throughput (token/s): 3760.42, #queue-req: 0, 
1: [2025-10-29 20:12:12 DP0 TP0 PP1] Decode batch. #running-req: 68, #token: 82244, token usage: 0.10, cuda graph: True, gen throughput (token/s): 3764.68, #queue-req: 0, 
0: [2025-10-29 08:12:12 DP2 TP2 PP0] Decode batch. #running-req: 56, #token: 70418, token usage: 0.08, cuda graph: True, gen throughput (token/s): 3516.32, #queue-req: 0, 
1: [2025-10-29 20:12:12 DP2 TP2 PP1] Decode batch. #running-req: 56, #token: 70418, token usage: 0.08, cuda graph: True, gen throughput (token/s): 3518.62, #queue-req: 0, 
0: [2025-10-29 08:12:12 DP1 TP1 PP0] Decode batch. #running-req: 79, #token: 71146, token usage: 0.08, cuda graph: True, gen throughput (token/s): 4042.79, #queue-req: 0, 
1: [2025-10-29 20:12:12 DP1 TP1 PP1] Decode batch. #running-req: 79, #token: 71146, token usage: 0.08, cuda graph: True, gen throughput (token/s): 4047.63, #queue-req: 0, 
0: [2025-10-29 08:12:12 DP3 TP3 PP0] Decode batch. #running-req: 75, #token: 89059, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4060.59, #queue-req: 0, 
1: [2025-10-29 20:12:12 DP3 TP3 PP1] Decode batch. #running-req: 75, #token: 89059, token usage: 0.10, cuda graph: True, gen throughput (token/s): 4061.42, #queue-req: 0, 
0: [2025-10-29 08:12:12 DP0 TP0 PP0] Decode batch. #running-req: 66, #token: 82409, token usage: 0.10, cuda graph: True, gen throughput (token/s): 3645.41, #queue-req: 0, 
1: [2025-10-29 20:12:12 DP0 TP0 PP1] Decode batch. #running-req: 66, #token: 82409, token usage: 0.10, cuda graph: True, gen throughput (token/s): 3644.53, #queue-req: 0, 
0: [2025-10-29 08:12:12 DP2 TP2 PP0] Decode batch. #running-req: 50, #token: 65226, token usage: 0.08, cuda graph: True, gen throughput (token/s): 3122.65, #queue-req: 0, 
1: [2025-10-29 20:12:13 DP2 TP2 PP1] Decode batch. #running-req: 50, #token: 65226, token usage: 0.08, cuda graph: True, gen throughput (token/s): 3123.49, #queue-req: 0, 
0: [2025-10-29 08:12:13 DP1 TP1 PP0] Decode batch. #running-req: 66, #token: 65696, token usage: 0.08, cuda graph: True, gen throughput (token/s): 3708.99, #queue-req: 0, 
1: [2025-10-29 20:12:13 DP1 TP1 PP1] Decode batch. #running-req: 66, #token: 65696, token usage: 0.08, cuda graph: True, gen throughput (token/s): 3710.73, #queue-req: 0, 
0: [2025-10-29 08:12:13 DP3 TP3 PP0] Decode batch. #running-req: 68, #token: 82953, token usage: 0.10, cuda graph: True, gen throughput (token/s): 3744.10, #queue-req: 0, 
1: [2025-10-29 20:12:13 DP3 TP3 PP1] Decode batch. #running-req: 68, #token: 82953, token usage: 0.10, cuda graph: True, gen throughput (token/s): 3748.33, #queue-req: 0, 
0: [2025-10-29 08:12:13 DP0 TP0 PP0] Decode batch. #running-req: 61, #token: 79590, token usage: 0.09, cuda graph: True, gen throughput (token/s): 3450.09, #queue-req: 0, 
1: [2025-10-29 20:12:13 DP0 TP0 PP1] Decode batch. #running-req: 61, #token: 79590, token usage: 0.09, cuda graph: True, gen throughput (token/s): 3453.27, #queue-req: 0, 
0: [2025-10-29 08:12:13 DP2 TP2 PP0] Decode batch. #running-req: 44, #token: 63027, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2944.18, #queue-req: 0, 
1: [2025-10-29 20:12:13 DP2 TP2 PP1] Decode batch. #running-req: 44, #token: 63027, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2944.53, #queue-req: 0, 
0: [2025-10-29 08:12:13 DP1 TP1 PP0] Decode batch. #running-req: 56, #token: 58150, token usage: 0.07, cuda graph: True, gen throughput (token/s): 3289.16, #queue-req: 0, 
1: [2025-10-29 20:12:13 DP1 TP1 PP1] Decode batch. #running-req: 56, #token: 58150, token usage: 0.07, cuda graph: True, gen throughput (token/s): 3288.73, #queue-req: 0, 
0: [2025-10-29 08:12:14 DP3 TP3 PP0] Decode batch. #running-req: 60, #token: 78897, token usage: 0.09, cuda graph: True, gen throughput (token/s): 3523.19, #queue-req: 0, 
1: [2025-10-29 20:12:14 DP3 TP3 PP1] Decode batch. #running-req: 60, #token: 78897, token usage: 0.09, cuda graph: True, gen throughput (token/s): 3526.48, #queue-req: 0, 
0: [2025-10-29 08:12:14 DP0 TP0 PP0] Decode batch. #running-req: 55, #token: 76498, token usage: 0.09, cuda graph: True, gen throughput (token/s): 3347.88, #queue-req: 0, 
1: [2025-10-29 20:12:14 DP0 TP0 PP1] Decode batch. #running-req: 55, #token: 76498, token usage: 0.09, cuda graph: True, gen throughput (token/s): 3355.29, #queue-req: 0, 
0: [2025-10-29 08:12:14 DP2 TP2 PP0] Decode batch. #running-req: 41, #token: 61279, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2818.25, #queue-req: 0, 
1: [2025-10-29 20:12:14 DP2 TP2 PP1] Decode batch. #running-req: 41, #token: 61279, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2823.79, #queue-req: 0, 
0: [2025-10-29 08:12:14 DP1 TP1 PP0] Decode batch. #running-req: 47, #token: 55143, token usage: 0.06, cuda graph: True, gen throughput (token/s): 3086.79, #queue-req: 0, 
1: [2025-10-29 20:12:14 DP1 TP1 PP1] Decode batch. #running-req: 47, #token: 55143, token usage: 0.06, cuda graph: True, gen throughput (token/s): 3092.59, #queue-req: 0, 
0: [2025-10-29 08:12:14 DP3 TP3 PP0] Decode batch. #running-req: 56, #token: 75994, token usage: 0.09, cuda graph: True, gen throughput (token/s): 3342.12, #queue-req: 0, 
1: [2025-10-29 20:12:14 DP3 TP3 PP1] Decode batch. #running-req: 56, #token: 75994, token usage: 0.09, cuda graph: True, gen throughput (token/s): 3343.70, #queue-req: 0, 
0: [2025-10-29 08:12:14 DP0 TP0 PP0] Decode batch. #running-req: 51, #token: 73912, token usage: 0.09, cuda graph: True, gen throughput (token/s): 3179.92, #queue-req: 0, 
1: [2025-10-29 20:12:14 DP0 TP0 PP1] Decode batch. #running-req: 51, #token: 73912, token usage: 0.09, cuda graph: True, gen throughput (token/s): 3179.83, #queue-req: 0, 
0: [2025-10-29 08:12:15 DP2 TP2 PP0] Decode batch. #running-req: 37, #token: 55900, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2555.46, #queue-req: 0, 
1: [2025-10-29 20:12:15 DP2 TP2 PP1] Decode batch. #running-req: 37, #token: 55900, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2557.21, #queue-req: 0, 
0: [2025-10-29 08:12:15 DP1 TP1 PP0] Decode batch. #running-req: 43, #token: 52320, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2817.95, #queue-req: 0, 
1: [2025-10-29 20:12:15 DP1 TP1 PP1] Decode batch. #running-req: 43, #token: 52320, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2819.28, #queue-req: 0, 
0: [2025-10-29 08:12:15 DP3 TP3 PP0] Decode batch. #running-req: 48, #token: 71520, token usage: 0.08, cuda graph: True, gen throughput (token/s): 3154.26, #queue-req: 0, 
1: [2025-10-29 20:12:15 DP3 TP3 PP1] Decode batch. #running-req: 48, #token: 71520, token usage: 0.08, cuda graph: True, gen throughput (token/s): 3153.54, #queue-req: 0, 
0: [2025-10-29 08:12:15 DP0 TP0 PP0] Decode batch. #running-req: 47, #token: 72585, token usage: 0.09, cuda graph: True, gen throughput (token/s): 2930.81, #queue-req: 0, 
1: [2025-10-29 20:12:15 DP0 TP0 PP1] Decode batch. #running-req: 47, #token: 72585, token usage: 0.09, cuda graph: True, gen throughput (token/s): 2935.84, #queue-req: 0, 
0: [2025-10-29 08:12:15 DP2 TP2 PP0] Decode batch. #running-req: 34, #token: 51368, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2364.58, #queue-req: 0, 
1: [2025-10-29 20:12:15 DP2 TP2 PP1] Decode batch. #running-req: 34, #token: 51368, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2368.70, #queue-req: 0, 
0: [2025-10-29 08:12:15 DP1 TP1 PP0] Decode batch. #running-req: 37, #token: 49098, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2606.59, #queue-req: 0, 
1: [2025-10-29 20:12:15 DP1 TP1 PP1] Decode batch. #running-req: 37, #token: 49098, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2611.04, #queue-req: 0, 
0: [2025-10-29 08:12:16 DP3 TP3 PP0] Decode batch. #running-req: 47, #token: 65765, token usage: 0.08, cuda graph: True, gen throughput (token/s): 3098.00, #queue-req: 0, 
1: [2025-10-29 20:12:16 DP3 TP3 PP1] Decode batch. #running-req: 47, #token: 65765, token usage: 0.08, cuda graph: True, gen throughput (token/s): 3112.43, #queue-req: 0, 
0: [2025-10-29 08:12:16 DP0 TP0 PP0] Decode batch. #running-req: 40, #token: 62033, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2816.37, #queue-req: 0, 
1: [2025-10-29 20:12:16 DP0 TP0 PP1] Decode batch. #running-req: 40, #token: 62033, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2822.96, #queue-req: 0, 
0: [2025-10-29 08:12:16 DP2 TP2 PP0] Decode batch. #running-req: 30, #token: 47497, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2354.54, #queue-req: 0, 
1: [2025-10-29 20:12:16 DP2 TP2 PP1] Decode batch. #running-req: 30, #token: 47497, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2360.18, #queue-req: 0, 
0: [2025-10-29 08:12:16 DP1 TP1 PP0] Decode batch. #running-req: 34, #token: 46212, token usage: 0.05, cuda graph: True, gen throughput (token/s): 2545.85, #queue-req: 0, 
1: [2025-10-29 20:12:16 DP1 TP1 PP1] Decode batch. #running-req: 34, #token: 46212, token usage: 0.05, cuda graph: True, gen throughput (token/s): 2553.61, #queue-req: 0, 
0: [2025-10-29 08:12:16 DP3 TP3 PP0] Decode batch. #running-req: 44, #token: 63968, token usage: 0.08, cuda graph: True, gen throughput (token/s): 3161.79, #queue-req: 0, 
1: [2025-10-29 20:12:16 DP3 TP3 PP1] Decode batch. #running-req: 44, #token: 63968, token usage: 0.08, cuda graph: True, gen throughput (token/s): 3163.29, #queue-req: 0, 
0: [2025-10-29 08:12:16 DP0 TP0 PP0] Decode batch. #running-req: 36, #token: 54736, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2816.83, #queue-req: 0, 
1: [2025-10-29 20:12:16 DP0 TP0 PP1] Decode batch. #running-req: 36, #token: 54736, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2818.64, #queue-req: 0, 
0: [2025-10-29 08:12:16 DP2 TP2 PP0] Decode batch. #running-req: 24, #token: 45378, token usage: 0.05, cuda graph: True, gen throughput (token/s): 2310.41, #queue-req: 0, 
1: [2025-10-29 20:12:16 DP2 TP2 PP1] Decode batch. #running-req: 24, #token: 45378, token usage: 0.05, cuda graph: True, gen throughput (token/s): 2311.28, #queue-req: 0, 
0: [2025-10-29 08:12:16 DP1 TP1 PP0] Decode batch. #running-req: 29, #token: 43838, token usage: 0.05, cuda graph: True, gen throughput (token/s): 2468.08, #queue-req: 0, 
1: [2025-10-29 20:12:16 DP1 TP1 PP1] Decode batch. #running-req: 29, #token: 43838, token usage: 0.05, cuda graph: True, gen throughput (token/s): 2467.44, #queue-req: 0, 
0: [2025-10-29 08:12:17 DP3 TP3 PP0] Decode batch. #running-req: 41, #token: 63372, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2966.10, #queue-req: 0, 
1: [2025-10-29 20:12:17 DP3 TP3 PP1] Decode batch. #running-req: 41, #token: 63372, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2967.51, #queue-req: 0, 
0: [2025-10-29 08:12:17 DP0 TP0 PP0] Decode batch. #running-req: 36, #token: 54798, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2671.39, #queue-req: 0, 
1: [2025-10-29 20:12:17 DP0 TP0 PP1] Decode batch. #running-req: 36, #token: 54798, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2670.64, #queue-req: 0, 
0: [2025-10-29 08:12:17 DP2 TP2 PP0] Decode batch. #running-req: 21, #token: 40141, token usage: 0.05, cuda graph: True, gen throughput (token/s): 2102.94, #queue-req: 0, 
1: [2025-10-29 20:12:17 DP2 TP2 PP1] Decode batch. #running-req: 21, #token: 40141, token usage: 0.05, cuda graph: True, gen throughput (token/s): 2102.49, #queue-req: 0, 
0: [2025-10-29 08:12:17 DP1 TP1 PP0] Decode batch. #running-req: 27, #token: 40668, token usage: 0.05, cuda graph: True, gen throughput (token/s): 2297.61, #queue-req: 0, 
1: [2025-10-29 20:12:17 DP1 TP1 PP1] Decode batch. #running-req: 27, #token: 40668, token usage: 0.05, cuda graph: True, gen throughput (token/s): 2298.61, #queue-req: 0, 
0: [2025-10-29 08:12:17 DP3 TP3 PP0] Decode batch. #running-req: 38, #token: 61770, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2863.02, #queue-req: 0, 
1: [2025-10-29 20:12:17 DP3 TP3 PP1] Decode batch. #running-req: 38, #token: 61770, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2863.22, #queue-req: 0, 
0: [2025-10-29 08:12:17 DP0 TP0 PP0] Decode batch. #running-req: 33, #token: 52090, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2590.00, #queue-req: 0, 
1: [2025-10-29 20:12:17 DP0 TP0 PP1] Decode batch. #running-req: 33, #token: 52090, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2590.94, #queue-req: 0, 
0: [2025-10-29 08:12:18 DP2 TP2 PP0] Decode batch. #running-req: 21, #token: 40152, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1961.17, #queue-req: 0, 
1: [2025-10-29 20:12:18 DP2 TP2 PP1] Decode batch. #running-req: 21, #token: 40152, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1962.82, #queue-req: 0, 
0: [2025-10-29 08:12:18 DP1 TP1 PP0] Decode batch. #running-req: 24, #token: 38306, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1977.10, #queue-req: 0, 
1: [2025-10-29 20:12:18 DP1 TP1 PP1] Decode batch. #running-req: 24, #token: 38306, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1978.20, #queue-req: 0, 
0: [2025-10-29 08:12:18 DP3 TP3 PP0] Decode batch. #running-req: 37, #token: 60642, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2714.54, #queue-req: 0, 
1: [2025-10-29 20:12:18 DP3 TP3 PP1] Decode batch. #running-req: 37, #token: 60642, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2712.42, #queue-req: 0, 
0: [2025-10-29 08:12:18 DP0 TP0 PP0] Decode batch. #running-req: 29, #token: 49638, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2240.36, #queue-req: 0, 
1: [2025-10-29 20:12:18 DP0 TP0 PP1] Decode batch. #running-req: 29, #token: 49638, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2241.41, #queue-req: 0, 
0: [2025-10-29 08:12:18 DP2 TP2 PP0] Decode batch. #running-req: 20, #token: 37590, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1810.25, #queue-req: 0, 
1: [2025-10-29 20:12:18 DP2 TP2 PP1] Decode batch. #running-req: 20, #token: 37590, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1810.60, #queue-req: 0, 
0: [2025-10-29 08:12:18 DP1 TP1 PP0] Decode batch. #running-req: 22, #token: 37301, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1817.18, #queue-req: 0, 
1: [2025-10-29 20:12:18 DP1 TP1 PP1] Decode batch. #running-req: 22, #token: 37301, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1817.12, #queue-req: 0, 
0: [2025-10-29 08:12:18 DP3 TP3 PP0] Decode batch. #running-req: 32, #token: 58277, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2475.48, #queue-req: 0, 
1: [2025-10-29 20:12:18 DP3 TP3 PP1] Decode batch. #running-req: 32, #token: 58277, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2478.95, #queue-req: 0, 
0: [2025-10-29 08:12:18 DP0 TP0 PP0] Decode batch. #running-req: 27, #token: 48972, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2118.35, #queue-req: 0, 
1: [2025-10-29 20:12:19 DP0 TP0 PP1] Decode batch. #running-req: 27, #token: 48972, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2121.24, #queue-req: 0, 
0: [2025-10-29 08:12:19 DP2 TP2 PP0] Decode batch. #running-req: 19, #token: 35196, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1710.02, #queue-req: 0, 
1: [2025-10-29 20:12:19 DP2 TP2 PP1] Decode batch. #running-req: 19, #token: 35196, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1712.49, #queue-req: 0, 
0: [2025-10-29 08:12:19 DP1 TP1 PP0] Decode batch. #running-req: 19, #token: 35147, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1678.27, #queue-req: 0, 
1: [2025-10-29 20:12:19 DP1 TP1 PP1] Decode batch. #running-req: 19, #token: 35147, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1680.82, #queue-req: 0, 
0: [2025-10-29 08:12:19 DP3 TP3 PP0] Decode batch. #running-req: 31, #token: 56184, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2387.40, #queue-req: 0, 
1: [2025-10-29 20:12:19 DP3 TP3 PP1] Decode batch. #running-req: 31, #token: 56184, token usage: 0.07, cuda graph: True, gen throughput (token/s): 2388.14, #queue-req: 0, 
0: [2025-10-29 08:12:19 DP0 TP0 PP0] Decode batch. #running-req: 27, #token: 49325, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2111.85, #queue-req: 0, 
1: [2025-10-29 20:12:19 DP0 TP0 PP1] Decode batch. #running-req: 27, #token: 49325, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2112.59, #queue-req: 0, 
0: [2025-10-29 08:12:19 DP2 TP2 PP0] Decode batch. #running-req: 19, #token: 34778, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1605.80, #queue-req: 0, 
1: [2025-10-29 20:12:19 DP2 TP2 PP1] Decode batch. #running-req: 19, #token: 34778, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1606.45, #queue-req: 0, 
0: [2025-10-29 08:12:19 DP1 TP1 PP0] Decode batch. #running-req: 15, #token: 28879, token usage: 0.03, cuda graph: True, gen throughput (token/s): 1452.38, #queue-req: 0, 
1: [2025-10-29 20:12:19 DP1 TP1 PP1] Decode batch. #running-req: 15, #token: 28879, token usage: 0.03, cuda graph: True, gen throughput (token/s): 1452.76, #queue-req: 0, 
0: [2025-10-29 08:12:19 DP3 TP3 PP0] Decode batch. #running-req: 30, #token: 52721, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2263.07, #queue-req: 0, 
1: [2025-10-29 20:12:20 DP3 TP3 PP1] Decode batch. #running-req: 30, #token: 52721, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2262.64, #queue-req: 0, 
0: [2025-10-29 08:12:20 DP0 TP0 PP0] Decode batch. #running-req: 23, #token: 46881, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2021.43, #queue-req: 0, 
1: [2025-10-29 20:12:20 DP0 TP0 PP1] Decode batch. #running-req: 23, #token: 46881, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2022.88, #queue-req: 0, 
0: [2025-10-29 08:12:20 DP2 TP2 PP0] Decode batch. #running-req: 14, #token: 27630, token usage: 0.03, cuda graph: True, gen throughput (token/s): 1422.51, #queue-req: 0, 
1: [2025-10-29 20:12:20 DP2 TP2 PP1] Decode batch. #running-req: 14, #token: 27630, token usage: 0.03, cuda graph: True, gen throughput (token/s): 1422.28, #queue-req: 0, 
0: [2025-10-29 08:12:20 DP1 TP1 PP0] Decode batch. #running-req: 14, #token: 26926, token usage: 0.03, cuda graph: True, gen throughput (token/s): 1296.35, #queue-req: 0, 
1: [2025-10-29 20:12:20 DP1 TP1 PP1] Decode batch. #running-req: 14, #token: 26926, token usage: 0.03, cuda graph: True, gen throughput (token/s): 1297.15, #queue-req: 0, 
0: [2025-10-29 08:12:20 DP3 TP3 PP0] Decode batch. #running-req: 26, #token: 50635, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2108.50, #queue-req: 0, 
1: [2025-10-29 20:12:20 DP3 TP3 PP1] Decode batch. #running-req: 26, #token: 50635, token usage: 0.06, cuda graph: True, gen throughput (token/s): 2110.64, #queue-req: 0, 
0: [2025-10-29 08:12:20 DP0 TP0 PP0] Decode batch. #running-req: 20, #token: 42382, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1787.52, #queue-req: 0, 
1: [2025-10-29 20:12:20 DP0 TP0 PP1] Decode batch. #running-req: 20, #token: 42382, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1785.25, #queue-req: 0, 
0: [2025-10-29 08:12:20 DP2 TP2 PP0] Decode batch. #running-req: 13, #token: 25809, token usage: 0.03, cuda graph: True, gen throughput (token/s): 1103.72, #queue-req: 0, 
1: [2025-10-29 20:12:20 DP2 TP2 PP1] Decode batch. #running-req: 13, #token: 25809, token usage: 0.03, cuda graph: True, gen throughput (token/s): 1103.48, #queue-req: 0, 
0: [2025-10-29 08:12:20 DP1 TP1 PP0] Decode batch. #running-req: 14, #token: 27546, token usage: 0.03, cuda graph: True, gen throughput (token/s): 1198.91, #queue-req: 0, 
1: [2025-10-29 20:12:20 DP1 TP1 PP1] Decode batch. #running-req: 14, #token: 27546, token usage: 0.03, cuda graph: True, gen throughput (token/s): 1196.62, #queue-req: 0, 
0: [2025-10-29 08:12:21 DP3 TP3 PP0] Decode batch. #running-req: 26, #token: 47236, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1939.64, #queue-req: 0, 
1: [2025-10-29 20:12:21 DP3 TP3 PP1] Decode batch. #running-req: 26, #token: 47236, token usage: 0.06, cuda graph: True, gen throughput (token/s): 1940.41, #queue-req: 0, 
0: [2025-10-29 08:12:21 DP0 TP0 PP0] Decode batch. #running-req: 18, #token: 42634, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1623.16, #queue-req: 0, 
1: [2025-10-29 20:12:21 DP0 TP0 PP1] Decode batch. #running-req: 18, #token: 42634, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1623.40, #queue-req: 0, 
0: [2025-10-29 08:12:21 DP2 TP2 PP0] Decode batch. #running-req: 11, #token: 20779, token usage: 0.02, cuda graph: True, gen throughput (token/s): 984.10, #queue-req: 0, 
1: [2025-10-29 20:12:21 DP2 TP2 PP1] Decode batch. #running-req: 11, #token: 20779, token usage: 0.02, cuda graph: True, gen throughput (token/s): 984.70, #queue-req: 0, 
0: [2025-10-29 08:12:21 DP1 TP1 PP0] Decode batch. #running-req: 12, #token: 25414, token usage: 0.03, cuda graph: True, gen throughput (token/s): 1212.25, #queue-req: 0, 
1: [2025-10-29 20:12:21 DP1 TP1 PP1] Decode batch. #running-req: 12, #token: 25414, token usage: 0.03, cuda graph: True, gen throughput (token/s): 1213.64, #queue-req: 0, 
0: [2025-10-29 08:12:21 DP3 TP3 PP0] Decode batch. #running-req: 24, #token: 45068, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1783.06, #queue-req: 0, 
1: [2025-10-29 20:12:21 DP3 TP3 PP1] Decode batch. #running-req: 24, #token: 45068, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1783.81, #queue-req: 0, 
0: [2025-10-29 08:12:21 DP0 TP0 PP0] Decode batch. #running-req: 17, #token: 40280, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1556.92, #queue-req: 0, 
1: [2025-10-29 20:12:21 DP0 TP0 PP1] Decode batch. #running-req: 17, #token: 40280, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1557.49, #queue-req: 0, 
0: [2025-10-29 08:12:21 DP2 TP2 PP0] Decode batch. #running-req: 9, #token: 19315, token usage: 0.02, cuda graph: True, gen throughput (token/s): 895.27, #queue-req: 0, 
1: [2025-10-29 20:12:21 DP2 TP2 PP1] Decode batch. #running-req: 9, #token: 19315, token usage: 0.02, cuda graph: True, gen throughput (token/s): 895.41, #queue-req: 0, 
0: [2025-10-29 08:12:21 DP1 TP1 PP0] Decode batch. #running-req: 9, #token: 23481, token usage: 0.03, cuda graph: True, gen throughput (token/s): 1007.56, #queue-req: 0, 
1: [2025-10-29 20:12:21 DP1 TP1 PP1] Decode batch. #running-req: 9, #token: 23481, token usage: 0.03, cuda graph: True, gen throughput (token/s): 1007.71, #queue-req: 0, 
0: [2025-10-29 08:12:22 DP3 TP3 PP0] Decode batch. #running-req: 21, #token: 41967, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1653.59, #queue-req: 0, 
1: [2025-10-29 20:12:22 DP3 TP3 PP1] Decode batch. #running-req: 21, #token: 41967, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1653.63, #queue-req: 0, 
0: [2025-10-29 08:12:22 DP0 TP0 PP0] Decode batch. #running-req: 15, #token: 36168, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1452.84, #queue-req: 0, 
1: [2025-10-29 20:12:22 DP0 TP0 PP1] Decode batch. #running-req: 15, #token: 36168, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1453.83, #queue-req: 0, 
0: [2025-10-29 08:12:22 DP2 TP2 PP0] Decode batch. #running-req: 8, #token: 17007, token usage: 0.02, cuda graph: True, gen throughput (token/s): 761.80, #queue-req: 0, 
1: [2025-10-29 20:12:22 DP2 TP2 PP1] Decode batch. #running-req: 8, #token: 17007, token usage: 0.02, cuda graph: True, gen throughput (token/s): 761.89, #queue-req: 0, 
0: [2025-10-29 08:12:22 DP1 TP1 PP0] Decode batch. #running-req: 9, #token: 23330, token usage: 0.03, cuda graph: True, gen throughput (token/s): 928.44, #queue-req: 0, 
1: [2025-10-29 20:12:22 DP1 TP1 PP1] Decode batch. #running-req: 9, #token: 23330, token usage: 0.03, cuda graph: True, gen throughput (token/s): 928.93, #queue-req: 0, 
0: [2025-10-29 08:12:22 DP3 TP3 PP0] Decode batch. #running-req: 20, #token: 41016, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1551.30, #queue-req: 0, 
1: [2025-10-29 20:12:22 DP3 TP3 PP1] Decode batch. #running-req: 20, #token: 41016, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1551.40, #queue-req: 0, 
0: [2025-10-29 08:12:22 DP0 TP0 PP0] Decode batch. #running-req: 15, #token: 35045, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1344.76, #queue-req: 0, 
1: [2025-10-29 20:12:22 DP0 TP0 PP1] Decode batch. #running-req: 15, #token: 35045, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1345.43, #queue-req: 0, 
0: [2025-10-29 08:12:22 DP2 TP2 PP0] Decode batch. #running-req: 7, #token: 15819, token usage: 0.02, cuda graph: True, gen throughput (token/s): 665.01, #queue-req: 0, 
1: [2025-10-29 20:12:22 DP2 TP2 PP1] Decode batch. #running-req: 7, #token: 15819, token usage: 0.02, cuda graph: True, gen throughput (token/s): 665.25, #queue-req: 0, 
0: [2025-10-29 08:12:22 DP1 TP1 PP0] Decode batch. #running-req: 9, #token: 21105, token usage: 0.02, cuda graph: True, gen throughput (token/s): 860.84, #queue-req: 0, 
1: [2025-10-29 20:12:22 DP1 TP1 PP1] Decode batch. #running-req: 9, #token: 21105, token usage: 0.02, cuda graph: True, gen throughput (token/s): 861.08, #queue-req: 0, 
0: [2025-10-29 08:12:22 DP3 TP3 PP0] Decode batch. #running-req: 20, #token: 41756, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1512.63, #queue-req: 0, 
1: [2025-10-29 20:12:23 DP3 TP3 PP1] Decode batch. #running-req: 20, #token: 41756, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1512.84, #queue-req: 0, 
0: [2025-10-29 08:12:23 DP0 TP0 PP0] Decode batch. #running-req: 15, #token: 32246, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1254.13, #queue-req: 0, 
1: [2025-10-29 20:12:23 DP0 TP0 PP1] Decode batch. #running-req: 15, #token: 32246, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1254.10, #queue-req: 0, 
0: [2025-10-29 08:12:23 DP2 TP2 PP0] Decode batch. #running-req: 5, #token: 12144, token usage: 0.01, cuda graph: True, gen throughput (token/s): 568.43, #queue-req: 0, 
1: [2025-10-29 20:12:23 DP2 TP2 PP1] Decode batch. #running-req: 5, #token: 12144, token usage: 0.01, cuda graph: True, gen throughput (token/s): 568.53, #queue-req: 0, 
0: [2025-10-29 08:12:23 DP1 TP1 PP0] Decode batch. #running-req: 9, #token: 21505, token usage: 0.03, cuda graph: True, gen throughput (token/s): 819.67, #queue-req: 0, 
1: [2025-10-29 20:12:23 DP1 TP1 PP1] Decode batch. #running-req: 9, #token: 21505, token usage: 0.03, cuda graph: True, gen throughput (token/s): 819.85, #queue-req: 0, 
0: [2025-10-29 08:12:23 DP3 TP3 PP0] Decode batch. #running-req: 16, #token: 38627, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1445.32, #queue-req: 0, 
1: [2025-10-29 20:12:23 DP3 TP3 PP1] Decode batch. #running-req: 16, #token: 38627, token usage: 0.05, cuda graph: True, gen throughput (token/s): 1447.10, #queue-req: 0, 
0: [2025-10-29 08:12:23 DP0 TP0 PP0] Decode batch. #running-req: 13, #token: 31423, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1143.52, #queue-req: 0, 
1: [2025-10-29 20:12:23 DP0 TP0 PP1] Decode batch. #running-req: 13, #token: 31423, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1145.14, #queue-req: 0, 
0: [2025-10-29 08:12:23 DP2 TP2 PP0] Decode batch. #running-req: 4, #token: 11692, token usage: 0.01, cuda graph: True, gen throughput (token/s): 492.77, #queue-req: 0, 
1: [2025-10-29 20:12:23 DP2 TP2 PP1] Decode batch. #running-req: 4, #token: 11692, token usage: 0.01, cuda graph: True, gen throughput (token/s): 493.52, #queue-req: 0, 
0: [2025-10-29 08:12:23 DP1 TP1 PP0] Decode batch. #running-req: 8, #token: 21094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 803.15, #queue-req: 0, 
1: [2025-10-29 20:12:23 DP1 TP1 PP1] Decode batch. #running-req: 8, #token: 21094, token usage: 0.02, cuda graph: True, gen throughput (token/s): 804.46, #queue-req: 0, 
0: [2025-10-29 08:12:23 DP3 TP3 PP0] Decode batch. #running-req: 13, #token: 35106, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1268.61, #queue-req: 0, 
1: [2025-10-29 20:12:23 DP3 TP3 PP1] Decode batch. #running-req: 13, #token: 35106, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1268.67, #queue-req: 0, 
0: [2025-10-29 08:12:23 DP0 TP0 PP0] Decode batch. #running-req: 13, #token: 31963, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1170.87, #queue-req: 0, 
1: [2025-10-29 20:12:23 DP0 TP0 PP1] Decode batch. #running-req: 13, #token: 31963, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1171.03, #queue-req: 0, 
0: [2025-10-29 08:12:24 DP2 TP2 PP0] Decode batch. #running-req: 4, #token: 11912, token usage: 0.01, cuda graph: True, gen throughput (token/s): 476.99, #queue-req: 0, 
1: [2025-10-29 20:12:24 DP2 TP2 PP1] Decode batch. #running-req: 4, #token: 11912, token usage: 0.01, cuda graph: True, gen throughput (token/s): 476.78, #queue-req: 0, 
0: [2025-10-29 08:12:24 DP1 TP1 PP0] Decode batch. #running-req: 8, #token: 20613, token usage: 0.02, cuda graph: True, gen throughput (token/s): 803.23, #queue-req: 0, 
1: [2025-10-29 20:12:24 DP1 TP1 PP1] Decode batch. #running-req: 8, #token: 20613, token usage: 0.02, cuda graph: True, gen throughput (token/s): 803.35, #queue-req: 0, 
0: [2025-10-29 08:12:24 DP3 TP3 PP0] Decode batch. #running-req: 12, #token: 34098, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1106.61, #queue-req: 0, 
1: [2025-10-29 20:12:24 DP3 TP3 PP1] Decode batch. #running-req: 12, #token: 34098, token usage: 0.04, cuda graph: True, gen throughput (token/s): 1106.14, #queue-req: 0, 
0: [2025-10-29 08:12:24 DP0 TP0 PP0] Decode batch. #running-req: 10, #token: 24194, token usage: 0.03, cuda graph: True, gen throughput (token/s): 1099.43, #queue-req: 0, 
1: [2025-10-29 20:12:24 DP0 TP0 PP1] Decode batch. #running-req: 10, #token: 24194, token usage: 0.03, cuda graph: True, gen throughput (token/s): 1098.76, #queue-req: 0, 
0: [2025-10-29 08:12:24 DP2 TP2 PP0] Decode batch. #running-req: 3, #token: 10309, token usage: 0.01, cuda graph: True, gen throughput (token/s): 457.97, #queue-req: 0, 
1: [2025-10-29 20:12:24 DP2 TP2 PP1] Decode batch. #running-req: 3, #token: 10309, token usage: 0.01, cuda graph: True, gen throughput (token/s): 458.21, #queue-req: 0, 
0: [2025-10-29 08:12:24 DP1 TP1 PP0] Decode batch. #running-req: 8, #token: 20138, token usage: 0.02, cuda graph: True, gen throughput (token/s): 768.36, #queue-req: 0, 
1: [2025-10-29 20:12:24 DP1 TP1 PP1] Decode batch. #running-req: 8, #token: 20138, token usage: 0.02, cuda graph: True, gen throughput (token/s): 768.11, #queue-req: 0, 
0: [2025-10-29 08:12:24 DP3 TP3 PP0] Decode batch. #running-req: 8, #token: 25426, token usage: 0.03, cuda graph: True, gen throughput (token/s): 942.79, #queue-req: 0, 
1: [2025-10-29 20:12:24 DP3 TP3 PP1] Decode batch. #running-req: 8, #token: 25426, token usage: 0.03, cuda graph: True, gen throughput (token/s): 943.35, #queue-req: 0, 
0: [2025-10-29 08:12:24 DP0 TP0 PP0] Decode batch. #running-req: 8, #token: 20156, token usage: 0.02, cuda graph: True, gen throughput (token/s): 826.25, #queue-req: 0, 
1: [2025-10-29 20:12:24 DP0 TP0 PP1] Decode batch. #running-req: 8, #token: 20156, token usage: 0.02, cuda graph: True, gen throughput (token/s): 826.77, #queue-req: 0, 
0: [2025-10-29 08:12:24 DP2 TP2 PP0] Decode batch. #running-req: 3, #token: 9709, token usage: 0.01, cuda graph: True, gen throughput (token/s): 427.16, #queue-req: 0, 
1: [2025-10-29 20:12:24 DP2 TP2 PP1] Decode batch. #running-req: 3, #token: 9709, token usage: 0.01, cuda graph: True, gen throughput (token/s): 427.19, #queue-req: 0, 
0: [2025-10-29 08:12:25 DP1 TP1 PP0] Decode batch. #running-req: 8, #token: 20478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 741.24, #queue-req: 0, 
1: [2025-10-29 20:12:25 DP1 TP1 PP1] Decode batch. #running-req: 8, #token: 20478, token usage: 0.02, cuda graph: True, gen throughput (token/s): 741.60, #queue-req: 0, 
0: [2025-10-29 08:12:25 DP3 TP3 PP0] Decode batch. #running-req: 8, #token: 22873, token usage: 0.03, cuda graph: True, gen throughput (token/s): 718.02, #queue-req: 0, 
1: [2025-10-29 20:12:25 DP3 TP3 PP1] Decode batch. #running-req: 8, #token: 22873, token usage: 0.03, cuda graph: True, gen throughput (token/s): 718.52, #queue-req: 0, 
0: [2025-10-29 08:12:25 DP0 TP0 PP0] Decode batch. #running-req: 6, #token: 12793, token usage: 0.02, cuda graph: True, gen throughput (token/s): 653.59, #queue-req: 0, 
1: [2025-10-29 20:12:25 DP0 TP0 PP1] Decode batch. #running-req: 6, #token: 12793, token usage: 0.02, cuda graph: True, gen throughput (token/s): 653.95, #queue-req: 0, 
0: [2025-10-29 08:12:25 DP2 TP2 PP0] Decode batch. #running-req: 3, #token: 9088, token usage: 0.01, cuda graph: True, gen throughput (token/s): 389.84, #queue-req: 0, 
1: [2025-10-29 20:12:25 DP2 TP2 PP1] Decode batch. #running-req: 3, #token: 9088, token usage: 0.01, cuda graph: True, gen throughput (token/s): 390.15, #queue-req: 0, 
0: [2025-10-29 08:12:25 DP1 TP1 PP0] Decode batch. #running-req: 3, #token: 11036, token usage: 0.01, cuda graph: True, gen throughput (token/s): 584.41, #queue-req: 0, 
1: [2025-10-29 20:12:25 DP1 TP1 PP1] Decode batch. #running-req: 3, #token: 11036, token usage: 0.01, cuda graph: True, gen throughput (token/s): 584.45, #queue-req: 0, 
0: [2025-10-29 08:12:25 DP3 TP3 PP0] Decode batch. #running-req: 6, #token: 18678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 634.54, #queue-req: 0, 
1: [2025-10-29 20:12:25 DP3 TP3 PP1] Decode batch. #running-req: 6, #token: 18678, token usage: 0.02, cuda graph: True, gen throughput (token/s): 634.33, #queue-req: 0, 
0: [2025-10-29 08:12:25 DP0 TP0 PP0] Decode batch. #running-req: 3, #token: 6795, token usage: 0.01, cuda graph: True, gen throughput (token/s): 407.54, #queue-req: 0, 
1: [2025-10-29 20:12:25 DP0 TP0 PP1] Decode batch. #running-req: 3, #token: 6795, token usage: 0.01, cuda graph: True, gen throughput (token/s): 407.74, #queue-req: 0, 
0: [2025-10-29 08:12:25 DP2 TP2 PP0] Decode batch. #running-req: 3, #token: 6475, token usage: 0.01, cuda graph: True, gen throughput (token/s): 286.99, #queue-req: 0, 
1: [2025-10-29 20:12:25 DP2 TP2 PP1] Decode batch. #running-req: 3, #token: 6475, token usage: 0.01, cuda graph: True, gen throughput (token/s): 286.99, #queue-req: 0, 
0: [2025-10-29 08:12:25 DP1 TP1 PP0] Decode batch. #running-req: 3, #token: 10237, token usage: 0.01, cuda graph: True, gen throughput (token/s): 327.73, #queue-req: 0, 
1: [2025-10-29 20:12:25 DP1 TP1 PP1] Decode batch. #running-req: 3, #token: 10237, token usage: 0.01, cuda graph: True, gen throughput (token/s): 328.14, #queue-req: 0, 
0: [2025-10-29 08:12:26 DP3 TP3 PP0] Decode batch. #running-req: 3, #token: 14916, token usage: 0.02, cuda graph: True, gen throughput (token/s): 463.91, #queue-req: 0, 
1: [2025-10-29 20:12:26 DP3 TP3 PP1] Decode batch. #running-req: 3, #token: 14916, token usage: 0.02, cuda graph: True, gen throughput (token/s): 464.13, #queue-req: 0, 
0: [2025-10-29 08:12:26 DP0 TP0 PP0] Decode batch. #running-req: 3, #token: 6095, token usage: 0.01, cuda graph: True, gen throughput (token/s): 234.48, #queue-req: 0, 
1: [2025-10-29 20:12:26 DP0 TP0 PP1] Decode batch. #running-req: 3, #token: 6095, token usage: 0.01, cuda graph: True, gen throughput (token/s): 234.62, #queue-req: 0, 
0: [2025-10-29 08:12:26 DP2 TP2 PP0] Decode batch. #running-req: 2, #token: 4461, token usage: 0.01, cuda graph: True, gen throughput (token/s): 214.86, #queue-req: 0, 
1: [2025-10-29 20:12:26 DP2 TP2 PP1] Decode batch. #running-req: 2, #token: 4461, token usage: 0.01, cuda graph: True, gen throughput (token/s): 215.01, #queue-req: 0, 
0: [2025-10-29 08:12:26 DP1 TP1 PP0] Decode batch. #running-req: 3, #token: 6808, token usage: 0.01, cuda graph: True, gen throughput (token/s): 310.97, #queue-req: 0, 
1: [2025-10-29 20:12:26 DP1 TP1 PP1] Decode batch. #running-req: 3, #token: 6808, token usage: 0.01, cuda graph: True, gen throughput (token/s): 310.84, #queue-req: 0, 
0: [2025-10-29 08:12:26 DP3 TP3 PP0] Decode batch. #running-req: 2, #token: 7851, token usage: 0.01, cuda graph: True, gen throughput (token/s): 356.80, #queue-req: 0, 
1: [2025-10-29 20:12:26 DP3 TP3 PP1] Decode batch. #running-req: 2, #token: 7851, token usage: 0.01, cuda graph: True, gen throughput (token/s): 356.61, #queue-req: 0, 
0: [2025-10-29 08:12:26 DP0 TP0 PP0] Decode batch. #running-req: 3, #token: 3329, token usage: 0.00, cuda graph: True, gen throughput (token/s): 204.36, #queue-req: 0, 
1: [2025-10-29 20:12:26 DP0 TP0 PP1] Decode batch. #running-req: 3, #token: 3329, token usage: 0.00, cuda graph: True, gen throughput (token/s): 204.34, #queue-req: 0, 
0: [2025-10-29 08:12:26 DP1 TP1 PP0] Decode batch. #running-req: 2, #token: 3490, token usage: 0.00, cuda graph: True, gen throughput (token/s): 159.26, #queue-req: 0, 
0: [2025-10-29 08:12:26 DP2 TP2 PP0] Decode batch. #running-req: 2, #token: 2373, token usage: 0.00, cuda graph: True, gen throughput (token/s): 155.89, #queue-req: 0, 
1: [2025-10-29 20:12:26 DP1 TP1 PP1] Decode batch. #running-req: 2, #token: 3490, token usage: 0.00, cuda graph: True, gen throughput (token/s): 159.38, #queue-req: 0, 
1: [2025-10-29 20:12:26 DP2 TP2 PP1] Decode batch. #running-req: 2, #token: 2373, token usage: 0.00, cuda graph: True, gen throughput (token/s): 155.93, #queue-req: 0, 
0: [2025-10-29 08:12:27 DP3 TP3 PP0] Decode batch. #running-req: 1, #token: 2627, token usage: 0.00, cuda graph: True, gen throughput (token/s): 235.96, #queue-req: 0, 
1: [2025-10-29 20:12:27 DP3 TP3 PP1] Decode batch. #running-req: 1, #token: 2627, token usage: 0.00, cuda graph: True, gen throughput (token/s): 236.32, #queue-req: 0, 
0: [2025-10-29 08:12:27 DP0 TP0 PP0] Decode batch. #running-req: 2, #token: 3389, token usage: 0.00, cuda graph: True, gen throughput (token/s): 139.27, #queue-req: 0, 
1: [2025-10-29 20:12:27 DP0 TP0 PP1] Decode batch. #running-req: 2, #token: 3389, token usage: 0.00, cuda graph: True, gen throughput (token/s): 139.35, #queue-req: 0, 
0: [2025-10-29 08:12:27 DP3 TP3 PP0] Decode batch. #running-req: 1, #token: 1800, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.26, #queue-req: 0, 
1: [2025-10-29 20:12:27 DP3 TP3 PP1] Decode batch. #running-req: 1, #token: 1800, token usage: 0.00, cuda graph: True, gen throughput (token/s): 121.28, #queue-req: 0, 
0: [2025-10-29 08:12:27 DP0 TP0 PP0] Decode batch. #running-req: 2, #token: 3449, token usage: 0.00, cuda graph: True, gen throughput (token/s): 142.73, #queue-req: 0, 
1: [2025-10-29 20:12:27 DP0 TP0 PP1] Decode batch. #running-req: 2, #token: 3449, token usage: 0.00, cuda graph: True, gen throughput (token/s): 142.74, #queue-req: 0, 
0: [2025-10-29 08:12:27 DP1 TP1 PP0] Decode batch. #running-req: 1, #token: 983, token usage: 0.00, cuda graph: True, gen throughput (token/s): 74.70, #queue-req: 0, 
1: [2025-10-29 20:12:27 DP1 TP1 PP1] Decode batch. #running-req: 1, #token: 983, token usage: 0.00, cuda graph: True, gen throughput (token/s): 74.72, #queue-req: 0, 
0: [2025-10-29 08:12:27 DP2 TP2 PP0] Decode batch. #running-req: 2, #token: 2453, token usage: 0.00, cuda graph: True, gen throughput (token/s): 94.16, #queue-req: 0, 
1: [2025-10-29 20:12:27 DP2 TP2 PP1] Decode batch. #running-req: 2, #token: 2453, token usage: 0.00, cuda graph: True, gen throughput (token/s): 94.22, #queue-req: 0, 
0: [2025-10-29 08:12:27 DP0 TP0 PP0] Decode batch. #running-req: 1, #token: 2481, token usage: 0.00, cuda graph: True, gen throughput (token/s): 101.49, #queue-req: 0, 
1: [2025-10-29 20:12:27 DP0 TP0 PP1] Decode batch. #running-req: 1, #token: 2481, token usage: 0.00, cuda graph: True, gen throughput (token/s): 101.49, #queue-req: 0, 
0: [2025-10-29 08:12:28 DP3 TP3 PP0] Decode batch. #running-req: 1, #token: 978, token usage: 0.00, cuda graph: True, gen throughput (token/s): 53.64, #queue-req: 0, 
1: [2025-10-29 20:12:28 DP3 TP3 PP1] Decode batch. #running-req: 1, #token: 978, token usage: 0.00, cuda graph: True, gen throughput (token/s): 53.64, #queue-req: 0, 
0: [2025-10-29 08:12:28 DP0 TP0 PP0] Decode batch. #running-req: 1, #token: 2521, token usage: 0.00, cuda graph: True, gen throughput (token/s): 96.38, #queue-req: 0, 
1: [2025-10-29 20:12:28 DP0 TP0 PP1] Decode batch. #running-req: 1, #token: 2521, token usage: 0.00, cuda graph: True, gen throughput (token/s): 96.37, #queue-req: 0, 
0: [2025-10-29 08:12:28 DP1 TP1 PP0] Decode batch. #running-req: 1, #token: 1023, token usage: 0.00, cuda graph: True, gen throughput (token/s): 47.72, #queue-req: 0, 
1: [2025-10-29 20:12:28 DP1 TP1 PP1] Decode batch. #running-req: 1, #token: 1023, token usage: 0.00, cuda graph: True, gen throughput (token/s): 47.71, #queue-req: 0, 
0: [2025-10-29 08:12:28 DP2 TP2 PP0] Decode batch. #running-req: 2, #token: 2533, token usage: 0.00, cuda graph: True, gen throughput (token/s): 95.84, #queue-req: 0, 
1: [2025-10-29 20:12:28 DP2 TP2 PP1] Decode batch. #running-req: 2, #token: 2533, token usage: 0.00, cuda graph: True, gen throughput (token/s): 95.84, #queue-req: 0, 
0: [2025-10-29 08:12:28 DP0 TP0 PP0] Decode batch. #running-req: 1, #token: 2561, token usage: 0.00, cuda graph: True, gen throughput (token/s): 96.33, #queue-req: 0, 
1: [2025-10-29 20:12:28 DP0 TP0 PP1] Decode batch. #running-req: 1, #token: 2561, token usage: 0.00, cuda graph: True, gen throughput (token/s): 96.32, #queue-req: 0, 
0: [2025-10-29 08:12:29 DP3 TP3 PP0] Decode batch. #running-req: 1, #token: 1018, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.15, #queue-req: 0, 
1: [2025-10-29 20:12:29 DP3 TP3 PP1] Decode batch. #running-req: 1, #token: 1018, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.16, #queue-req: 0, 
0: [2025-10-29 08:12:29 DP1 TP1 PP0] Decode batch. #running-req: 1, #token: 1063, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.06, #queue-req: 0, 
1: [2025-10-29 20:12:29 DP1 TP1 PP1] Decode batch. #running-req: 1, #token: 1063, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.07, #queue-req: 0, 
0: [2025-10-29 08:12:29 DP0 TP0 PP0] Decode batch. #running-req: 1, #token: 1424, token usage: 0.00, cuda graph: True, gen throughput (token/s): 72.52, #queue-req: 0, 
0: [2025-10-29 08:12:29 DP2 TP2 PP0] Decode batch. #running-req: 2, #token: 2613, token usage: 0.00, cuda graph: True, gen throughput (token/s): 96.20, #queue-req: 0, 
1: [2025-10-29 20:12:29 DP0 TP0 PP1] Decode batch. #running-req: 1, #token: 1424, token usage: 0.00, cuda graph: True, gen throughput (token/s): 72.60, #queue-req: 0, 
1: [2025-10-29 20:12:29 DP2 TP2 PP1] Decode batch. #running-req: 2, #token: 2613, token usage: 0.00, cuda graph: True, gen throughput (token/s): 96.23, #queue-req: 0, 
0: [2025-10-29 08:12:30 DP1 TP1 PP0] Decode batch. #running-req: 1, #token: 1103, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.51, #queue-req: 0, 
1: [2025-10-29 20:12:30 DP1 TP1 PP1] Decode batch. #running-req: 1, #token: 1103, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.51, #queue-req: 0, 
0: [2025-10-29 08:12:30 DP0 TP0 PP0] Decode batch. #running-req: 1, #token: 1464, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.53, #queue-req: 0, 
0: [2025-10-29 08:12:30 DP2 TP2 PP0] Decode batch. #running-req: 2, #token: 2693, token usage: 0.00, cuda graph: True, gen throughput (token/s): 97.07, #queue-req: 0, 
1: [2025-10-29 20:12:30 DP0 TP0 PP1] Decode batch. #running-req: 1, #token: 1464, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.53, #queue-req: 0, 
1: [2025-10-29 20:12:30 DP2 TP2 PP1] Decode batch. #running-req: 2, #token: 2693, token usage: 0.00, cuda graph: True, gen throughput (token/s): 97.06, #queue-req: 0, 
0: [2025-10-29 08:12:30 DP1 TP1 PP0] Decode batch. #running-req: 1, #token: 1143, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.75, #queue-req: 0, 
1: [2025-10-29 20:12:30 DP1 TP1 PP1] Decode batch. #running-req: 1, #token: 1143, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.78, #queue-req: 0, 
0: [2025-10-29 08:12:30 DP0 TP0 PP0] Decode batch. #running-req: 1, #token: 1504, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.92, #queue-req: 0, 
0: [2025-10-29 08:12:30 DP2 TP2 PP0] Decode batch. #running-req: 1, #token: 1471, token usage: 0.00, cuda graph: True, gen throughput (token/s): 84.38, #queue-req: 0, 
1: [2025-10-29 20:12:30 DP0 TP0 PP1] Decode batch. #running-req: 1, #token: 1504, token usage: 0.00, cuda graph: True, gen throughput (token/s): 48.92, #queue-req: 0, 
1: [2025-10-29 20:12:30 DP2 TP2 PP1] Decode batch. #running-req: 1, #token: 1471, token usage: 0.00, cuda graph: True, gen throughput (token/s): 84.39, #queue-req: 0, 
0: [2025-10-29 08:12:31 DP1 TP1 PP0] Decode batch. #running-req: 1, #token: 1183, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.02, #queue-req: 0, 
1: [2025-10-29 20:12:31 DP1 TP1 PP1] Decode batch. #running-req: 1, #token: 1183, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.02, #queue-req: 0, 
0: [2025-10-29 08:12:31 DP0 TP0 PP0] Decode batch. #running-req: 1, #token: 1544, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.03, #queue-req: 0, 
1: [2025-10-29 20:12:31 DP0 TP0 PP1] Decode batch. #running-req: 1, #token: 1544, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.03, #queue-req: 0, 
0: [2025-10-29 08:12:32 DP1 TP1 PP0] Decode batch. #running-req: 1, #token: 1223, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.14, #queue-req: 0, 
1: [2025-10-29 20:12:32 DP1 TP1 PP1] Decode batch. #running-req: 1, #token: 1223, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.14, #queue-req: 0, 
0: [2025-10-29 08:12:32 DP0 TP0 PP0] Decode batch. #running-req: 1, #token: 1584, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.13, #queue-req: 0, 
1: [2025-10-29 20:12:32 DP0 TP0 PP1] Decode batch. #running-req: 1, #token: 1584, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.13, #queue-req: 0, 
0: [2025-10-29 08:12:33 DP1 TP1 PP0] Decode batch. #running-req: 1, #token: 1263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 49.98, #queue-req: 0, 
1: [2025-10-29 20:12:33 DP1 TP1 PP1] Decode batch. #running-req: 1, #token: 1263, token usage: 0.00, cuda graph: True, gen throughput (token/s): 49.98, #queue-req: 0, 
0: [2025-10-29 08:12:33 DP0 TP0 PP0] Decode batch. #running-req: 1, #token: 1624, token usage: 0.00, cuda graph: True, gen throughput (token/s): 49.97, #queue-req: 0, 
1: [2025-10-29 20:12:33 DP0 TP0 PP1] Decode batch. #running-req: 1, #token: 1624, token usage: 0.00, cuda graph: True, gen throughput (token/s): 49.96, #queue-req: 0, 
0: [2025-10-29 08:12:34 DP1 TP1 PP0] Decode batch. #running-req: 1, #token: 1303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.15, #queue-req: 0, 
1: [2025-10-29 20:12:34 DP1 TP1 PP1] Decode batch. #running-req: 1, #token: 1303, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.15, #queue-req: 0, 
0: [2025-10-29 08:12:34 DP0 TP0 PP0] Decode batch. #running-req: 1, #token: 1664, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.15, #queue-req: 0, 
1: [2025-10-29 20:12:34 DP0 TP0 PP1] Decode batch. #running-req: 1, #token: 1664, token usage: 0.00, cuda graph: True, gen throughput (token/s): 50.15, #queue-req: 0, 
0: [2025-10-29 08:12:34 DP0 TP0 PP0] Decode batch. #running-req: 1, #token: 1704, token usage: 0.00, cuda graph: True, gen throughput (token/s): 53.10, #queue-req: 0, 
1: [2025-10-29 20:12:34 DP0 TP0 PP1] Decode batch. #running-req: 1, #token: 1704, token usage: 0.00, cuda graph: True, gen throughput (token/s): 53.19, #queue-req: 0, 
0: [2025-10-29 08:12:35 DP0 TP0 PP0] Decode batch. #running-req: 1, #token: 1744, token usage: 0.00, cuda graph: True, gen throughput (token/s): 54.02, #queue-req: 0, 
1: [2025-10-29 20:12:35 DP0 TP0 PP1] Decode batch. #running-req: 1, #token: 1744, token usage: 0.00, cuda graph: True, gen throughput (token/s): 54.03, #queue-req: 0, 
0: [2025-10-29 08:12:36 DP0 TP0 PP0] Decode batch. #running-req: 1, #token: 1784, token usage: 0.00, cuda graph: True, gen throughput (token/s): 53.89, #queue-req: 0, 
1: [2025-10-29 20:12:36 DP0 TP0 PP1] Decode batch. #running-req: 1, #token: 1784, token usage: 0.00, cuda graph: True, gen throughput (token/s): 53.89, #queue-req: 0, 
1: [rank6]:[W1029 20:12:37.568954048 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
1: Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:682 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d6a8ed (0x7ff6b381e8ed in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b49a (0x7ff6b381f49a in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7ff6b381a1be in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:37.575029667 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
1: [rank5]:[W1029 20:12:37.664077537 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
1: Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:682 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d6a8ed (0x7fa91261e8ed in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b49a (0x7fa91261f49a in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7fa91261a1be in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:37.667867625 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
1: [rank4]:[W1029 20:12:37.743774533 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
1: Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:682 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d6a8ed (0x7f811181e8ed in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b49a (0x7f811181f49a in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7f811181a1be in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:37.747474158 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
1: [rank7]:[W1029 20:12:37.933517245 TCPStore.cpp:125] [c10d] recvValue failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
1: Exception raised from recvBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:682 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d6a8ed (0x7fa34061e8ed in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b49a (0x7fa34061f49a in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x31e (0x7fa34061a1be in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:37.937297968 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Failed to recv, got 0 bytes. Connection was likely closed. Did the remote server shutdown or crash?
1: [rank6]:[W1029 20:12:38.575116718 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:38.578851002 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:38.667958309 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:38.671459865 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:38.747555130 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:38.751053474 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:38.937377897 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:38.940955193 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:39.578929714 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:39.582452269 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:39.671541529 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:39.675125541 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:39.751132882 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:39.754602838 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:39.941027128 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:39.944624911 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:40.582526999 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:40.586083123 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:40.675205779 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:40.678774041 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:40.754677556 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:40.758223739 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:40.944695499 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:40.948256097 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:41.586156848 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:41.589962154 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:41.678854639 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:41.682552715 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:41.758297416 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:41.761921854 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:41.948324108 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:41.951843204 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:42.590034908 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:42.593774490 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:42.682634438 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:42.686192075 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:42.761994417 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:42.765696509 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:42.951913243 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:42.955499707 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:43.593845690 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:43.597317323 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:43.686271221 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:43.689824119 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:43.765772155 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:43.769256037 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:43.955570945 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:43.959115079 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:44.597387485 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:44.601183597 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:44.689904927 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:44.693856668 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:44.769329793 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:44.772943778 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:44.959188059 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:44.962799551 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:45.601253307 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:45.604962572 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:45.693934770 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:45.697500811 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:45.773020842 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:45.776603892 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:45.962869719 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:45.966343970 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:46.605032719 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:46.608715207 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:46.697579962 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:46.701122895 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:46.776677322 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:46.780209891 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:46.966415582 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:46.969971161 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:47.608787316 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:47.612343159 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:47.701204527 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:47.704837420 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:47.780285875 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:47.783857202 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:47.970050331 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:47.973721868 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:48.612414150 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:48.615959813 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:48.704917204 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:48.708665251 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:48.783930686 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:48.787308133 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:48.973797510 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:48.977527510 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:49.616030446 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:49.619684907 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:49.708744687 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:49.712468889 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:49.787380922 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:49.790858208 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:49.977599526 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:49.981162771 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:50.619753786 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:50.623452400 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:50.712547464 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:50.716125356 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:50.790930941 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:50.794422058 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:50.981234110 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:50.984741292 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:51.623521744 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:51.627157431 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:51.716205674 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:51.719882509 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:51.794496067 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:51.798033496 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:51.984812348 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:51.988398946 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:52.627226023 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:52.630840269 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:52.719960858 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:52.723636770 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:52.798105684 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:52.801688455 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:52.988465588 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:52.991939429 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:53.630910455 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:53.634546651 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:53.723716383 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:53.727305182 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:53.801761541 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:53.805229318 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:53.992012885 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:53.995560971 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:54.634617419 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:54.638332573 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:54.727382298 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:54.730928178 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:54.805302759 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:54.808797421 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:54.995634055 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:54.999186554 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:55.638403884 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:55.641933768 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:55.731010277 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:55.734599964 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:55.808870302 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:55.812286440 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:55.999255966 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:55.002712128 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:56.642005751 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:56.645675333 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:56.734678864 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:56.738116324 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:56.812359447 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:56.815781375 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:56.002780785 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:56.006230214 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:57.645743759 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:57.649282077 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:57.738195112 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:57.741730421 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:57.815860259 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:57.819266899 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:57.006299938 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:57.009777883 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:58.649352420 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:58.653075375 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:58.741808056 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:58.745282014 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:58.819340306 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:58.822725067 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:58.009850550 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:58.013532595 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:12:59.653146252 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:12:59.656798049 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:12:59.745363203 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:12:59.748830598 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:12:59.822796295 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:12:59.826288067 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:12:59.013603684 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:12:59.017120208 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:00.656868213 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:00.660519721 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:00.748909945 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:00.752356534 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:00.826361926 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:00.829790733 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:00.017194422 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:00.020799728 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:01.660594769 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:01.664220780 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:01.752436163 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:01.755959037 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:01.829865558 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:01.833387923 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:01.020872185 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:01.024370941 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:02.664293011 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:02.668005706 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:02.756038727 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:02.759680887 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:02.833460832 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:02.837021472 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:02.024441646 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:02.027909892 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:03.668077663 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:03.671787160 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:03.759761409 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:03.763392391 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:03.837096938 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:03.840576623 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:03.027978608 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:03.031700900 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:04.671859364 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:04.675386748 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:04.763472575 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:04.767057299 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:04.840649538 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:04.844116232 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:04.031771302 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:04.035454697 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:05.675457508 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:05.679121786 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:05.767138915 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:05.770861583 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:05.844188996 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:05.847735140 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:05.035525341 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:05.039034497 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:06.679191850 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:06.682842815 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:06.770945191 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:06.774477478 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:06.847807597 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:06.851396382 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:06.039103804 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:06.042730760 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:07.682918976 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:07.686597439 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:07.774561331 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:07.778145957 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:07.851473467 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:07.855018246 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:07.042801227 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:07.046263208 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:08.686671140 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:08.690213202 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:08.778229662 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:08.781796411 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:08.855092373 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:08.858739393 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:08.046334068 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:08.049857004 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:09.690284061 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:09.693842435 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:09.781879906 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:09.785574195 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:09.858811914 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:09.862274284 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:09.049926895 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:09.053576309 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:10.693913432 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:10.697463153 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:10.785657481 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:10.789293835 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:10.862347595 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:10.865893465 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:10.053644748 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:10.057128853 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:11.697535832 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:11.701148861 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:11.789376928 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:11.792985364 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:11.865965508 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:11.869435788 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:11.057199645 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:11.060764292 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:12.701220516 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:12.704892859 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:12.793068960 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:12.796671614 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:12.869508927 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:12.873010827 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:12.060833950 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:12.064446519 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:13.704964575 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:13.708697504 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:13.796753103 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:13.800443804 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:13.873082289 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:13.876768189 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:13.064515386 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:13.068023464 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:14.708767947 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:14.712297145 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:14.800525232 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:14.804019088 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:14.876839386 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:14.880263978 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:14.068095878 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:14.071709052 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:15.712368312 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:15.716036366 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:15.804100354 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:15.807765004 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:15.880334569 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:15.883827756 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:15.071780228 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:15.075277184 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:16.716106374 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:16.719831747 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:16.807843114 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:16.811708997 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:16.883898947 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:16.887378801 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:16.075346742 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:16.078854788 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:17.719901728 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:17.723402067 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:17.811791248 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:17.815411716 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:17.887450387 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:17.890870178 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:17.078928158 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:17.082699335 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:18.723471108 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:18.727040572 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:18.815493761 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:18.819141148 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:18.890941443 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:18.894488148 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:18.082770869 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:18.086297685 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:19.727112651 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:19.730755075 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:19.819236156 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:19.822717427 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:19.894558229 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:19.897962357 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:19.086369926 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:19.089951782 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:20.730825442 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:20.734492817 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:20.822793637 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:20.826471189 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:20.898033527 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:20.901568811 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:20.090023134 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:20.093643208 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:21.734562774 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:21.738182894 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:21.826543136 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:21.830306876 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:21.901639867 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:21.905188690 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:21.093713397 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:21.097351816 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:22.738253071 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:22.741797210 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:22.830378393 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:22.833877625 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:22.905258759 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:22.908730594 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:22.097422331 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:22.100888400 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:23.741867132 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:23.745435809 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:23.833947102 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:23.837586541 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:23.908802760 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:23.912290609 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:23.100956244 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:23.104607149 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:24.745508583 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:24.749095528 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:24.837655892 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:24.841213218 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:24.912361788 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:24.915981556 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:24.104681834 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:24.108242689 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:25.749165886 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:25.752930100 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:25.841282585 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:25.844779801 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:25.916052833 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:25.919600776 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:25.108320373 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:25.111968387 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:26.752999610 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:26.756709137 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:26.844849357 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:26.848469039 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:26.919672557 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:26.923210195 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:26.112039805 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:26.115620404 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:27.756778590 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:27.760293314 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:27.848538619 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:27.852033420 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:27.923282031 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:27.926710995 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:27.115691115 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:27.119251033 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:28.760368775 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:28.764107663 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:28.852103213 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:28.855620557 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:28.926792738 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:28.930244566 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:28.119331165 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:28.122810944 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:29.764182458 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:29.767881015 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:29.855689745 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:29.859101113 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:29.930319750 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:29.933657402 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:29.122886921 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:29.126420468 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:30.767955161 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:30.771627747 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:30.859171654 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:30.862672941 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:30.933730304 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:30.937096517 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:30.126492347 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:30.130174186 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:31.771699349 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:31.775282351 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:31.862747329 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:31.866156659 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:31.937170936 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:31.940594064 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:31.130244812 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:31.133806008 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:32.775356213 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:32.779037770 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:32.866229258 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:32.869866133 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:32.940666854 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:32.944195808 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:32.133878885 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:32.137493184 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:33.779107919 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:33.782894833 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:33.869936491 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:33.873399334 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:33.944269806 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:33.947650047 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:33.137563637 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:33.141025865 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:34.782967435 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:34.786640574 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:34.873471484 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:34.876928782 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:34.947722522 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:34.951133470 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:34.141106384 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:34.144640838 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:35.786713114 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:35.790275567 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:35.876999143 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:35.880397627 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:35.951207059 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:35.954639719 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:35.144716151 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:35.148394110 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:36.790345630 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:36.794018501 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:36.880467500 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:36.884105671 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:36.954712355 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:36.958203281 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:36.148466918 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:36.151974222 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:37.794090611 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:37.797887645 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:37.884176130 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:37.887778096 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:37.958275904 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:37.961825017 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:37.152047891 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:37.155665271 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:38.797959700 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:38.801594558 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:38.887847518 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:38.891222957 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:38.961896879 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:38.965303374 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:38.155738566 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:38.159236922 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:39.801665476 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:39.805269765 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:39.891291883 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:39.894732441 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:39.965374966 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:39.968797728 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:39.159310671 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:39.162778550 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:40.805338843 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:40.808893645 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:40.894802152 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:40.898214111 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:40.968869910 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:40.972334040 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:40.162858998 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:40.166450483 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:41.808962181 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:41.812583781 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:41.898283380 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:41.901689911 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:41.972405741 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:41.976093398 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:41.166520869 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:42.170057474 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:42.812656932 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:42.816344648 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:42.901759723 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:42.905195385 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:42.976165977 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:42.979710022 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:43.170136833 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:43.173750229 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:43.816415336 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:43.820023013 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:43.905264888 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:43.908798016 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:43.979794720 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:43.983330355 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:44.173825598 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:44.177388227 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:44.820093850 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:44.823753941 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:44.908867846 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:44.912303398 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:44.983407771 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:44.986965933 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:45.177463796 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:45.181044837 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:45.823823959 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:45.827405879 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:45.912372798 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:45.916047891 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:45.987042197 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:45.990708415 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:46.181116482 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:46.184738707 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:46.827476313 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:46.831036109 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:46.916116265 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:46.919649719 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:46.990785854 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:46.994268158 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:47.184808859 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:47.188312304 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:47.831107668 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:47.834754312 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:47.919718345 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:47.923228043 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:47.994344981 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:47.997823142 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:48.188383662 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:48.191778445 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:48.834827446 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:48.838559256 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:48.923296545 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:48.926881489 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:48.997905499 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:48.001392196 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:49.191854843 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:49.195465558 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:49.838629949 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:49.842140828 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:49.926951163 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:49.930520730 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:49.001469539 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:49.005009042 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:50.195538636 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:50.199051485 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:50.842210922 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:50.845742179 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:50.930589728 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:50.934115543 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:50.005086321 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:50.008701885 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:51.199122421 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:51.202807461 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:51.845812841 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:51.849475712 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:51.934184147 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:51.937847642 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:51.008778359 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:51.012395031 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:52.202876864 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:52.206420608 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:52.849544885 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:52.853066406 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:52.937916276 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:52.941452735 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:52.012472402 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:52.016082856 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:53.206492298 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:53.210027487 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:53.853136181 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:53.856767145 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:53.941521744 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:53.945087658 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:53.016161490 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:53.019798806 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:54.210097373 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:54.213680868 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:54.856862947 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:54.860476232 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:54.945156175 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:54.948562525 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:54.019882598 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:54.023553534 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:55.213755820 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:55.217270458 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:55.860563353 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:55.864129137 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:55.948631457 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:55.952237375 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:55.023636806 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:55.027218744 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:56.217342773 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:56.220886591 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:56.864214656 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:56.867883888 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:56.952306194 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:56.955891839 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:56.027302380 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:56.030776392 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:57.220958189 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:57.224433980 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:57.867969376 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:57.871614079 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:57.955960349 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:57.959424841 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:57.030860915 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:57.034571076 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:58.224504231 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:58.228039562 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:58.871699296 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:58.875458240 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:58.959494820 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:58.962965948 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:58.034656258 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:58.038419099 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:13:59.228123860 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:13:59.231862482 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:13:59.875538130 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:13:59.879195815 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:13:59.963034753 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:13:59.966617075 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:13:59.038497550 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:13:59.042173881 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank7]:[W1029 20:14:00.231938724 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50078, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa3576ceeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa34061d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa34061dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa34061f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa34061a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa3027340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7fa4d73dd253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7fa4da0c5ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7fa4da157850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank7]:[W1029 20:14:00.235669364 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 7] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank6]:[W1029 20:14:00.879274993 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50068, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7ff6ca8d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7ff6b381d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7ff6b381dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7ff6b381f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7ff6b381a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7ff6759340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7ff84a53d253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7ff84d225ac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7ff84d2b7850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank6]:[W1029 20:14:00.882902257 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 6] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank5]:[W1029 20:14:00.966685689 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50072, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7fa9296d9eb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7fa91261d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7fa91261dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7fa91261f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7fa91261a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7fa8d47340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7faaa9412253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7faaac0faac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7faaac18c850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank5]:[W1029 20:14:00.970210730 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 5] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
1: [rank4]:[W1029 20:14:00.042250041 TCPStore.cpp:106] [c10d] sendBytes failed on SocketImpl(fd=113, addr=[g4.hpcai2025.smc]:50076, remote=[g3.hpcai2025.smc]:5000): Broken pipe
1: Exception raised from sendBytes at /pytorch/torch/csrc/distributed/c10d/Utils.hpp:653 (most recent call first):
1: frame #0: c10::Error::Error(c10::SourceLocation, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >) + 0x80 (0x7f812897eeb0 in /usr/local/lib/python3.12/dist-packages/torch/lib/libc10.so)
1: frame #1: <unknown function> + 0x5d694f1 (0x7f811181d4f1 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #2: <unknown function> + 0x5d69d82 (0x7f811181dd82 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #3: <unknown function> + 0x5d6b88e (0x7f811181f88e in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #4: c10d::TCPStore::check(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> >, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char> > > > const&) + 0x30e (0x7f811181a1ae in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cpu.so)
1: frame #5: c10d::ProcessGroupNCCL::HeartbeatMonitor::runLoop() + 0x398 (0x7f80d39340c8 in /usr/local/lib/python3.12/dist-packages/torch/lib/libtorch_cuda.so)
1: frame #6: <unknown function> + 0xdc253 (0x7f82a8604253 in /lib/x86_64-linux-gnu/libstdc++.so.6)
1: frame #7: <unknown function> + 0x94ac3 (0x7f82ab2ecac3 in /lib/x86_64-linux-gnu/libc.so.6)
1: frame #8: <unknown function> + 0x126850 (0x7f82ab37e850 in /lib/x86_64-linux-gnu/libc.so.6)
1: 
1: [rank4]:[W1029 20:14:00.045878064 ProcessGroupNCCL.cpp:1783] [PG ID 0 PG GUID 0 Rank 4] Failed to check the "should dump" flag on TCPStore, (maybe TCPStore server has shut down too early), with error: Broken pipe
[2025-10-29T08:14:01.000] error: *** JOB 4651 ON g3 CANCELLED AT 2025-10-29T08:14:01 DUE TO TIME LIMIT ***
srun: Job step aborted: Waiting up to 5 seconds for job step to finish.
